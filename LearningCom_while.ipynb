{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from bptt import BPTT\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python import debug as tf_debug\n",
    "%load_ext autotime\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "def softmax_pooling(x):\n",
    "    coefs = tf.nn.softmax(x, dim = -1)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = -1)\n",
    "    return softmax_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 60.8 ms\n"
     ]
    }
   ],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, output_size, keep_prob = 0.9, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                #B = tf.Variable(tf.random_normal([self.layer_sizes[i], 1], stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                B = tf.get_variable(\"bias_\" + str(i), shape=[self.layer_sizes[i], 1],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): ## ADD THE DROPOUTS ## ADD THE SOFTMAX AT THE END ?\n",
    "            for i in range(self.nb_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (self.nb_layers - 1):\n",
    "                    x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "                else:\n",
    "                    x = tf.nn.elu(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 90.7 ms\n"
     ]
    }
   ],
   "source": [
    "class CommunicationNet: ## ADD THE MEMORY !! \n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, keep_prob = 0.9, memory_size = 32,\n",
    "                 stddev_epsilon = 0.35, output_size = 256, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.memory_size = memory_size\n",
    "        self.stddev_epsilon = stddev_epsilon\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.Variable(tf.random_normal([self.layer_sizes[(self.nb_layers-1)], self.memory_size]\n",
    "                                                            ,stddev = self.stddev))\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                #B = tf.Variable(tf.random_normal([self.layer_sizes[i], 1],stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                B = tf.Variable(tf.zeros([self.layer_sizes[i], 1]), name = \"com_net_bias_\" + str(i))\n",
    "                tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        #self.W_mem = tf.Variable(tf.random_normal(shape =[self.memory_size,self.output_size],stddev = self.stddev), name = \"weight_mem_com\")\n",
    "        self.W_mem = tf.get_variable(\"weight_mem_com\" , shape=[self.memory_size,self.output_size],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "        self.b_mem = tf.Variable(tf.zeros(shape = [self.memory_size, 1]), name = \"bias_mem_com\")\n",
    "\n",
    "        \n",
    "    def compute_output(self, x, memory):## ADD THE DROPOUTS AND SOFTMAX ?\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                x = tf.nn.elu(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = tf.add(tf.matmul(self.W_mem, x),self.b_mem)\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 93.5 ms\n"
     ]
    }
   ],
   "source": [
    "class LastNet: ## ADD THE MEMORY !! The memory initialization is random ==> set it 0\n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, keep_prob = 0.9, memory_size = 32, \n",
    "                 stddev_epsilon = 0.35, output_size = 24, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.memory_size = memory_size\n",
    "        self.stddev_epsilon = stddev_epsilon\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.Variable(tf.random_normal([self.output_size, self.memory_size],stddev = self.stddev))\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.get_variable(\"lastnet_weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"last_net_weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"last_net_weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i != (self.nb_layers - 1):\n",
    "                    #B = tf.Variable(tf.random_normal([self.layer_sizes[i+1], 1],stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                    B = tf.Variable(tf.zeros([self.layer_sizes[i], 1]), name = \"last_net_bias_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    #B = tf.Variable(tf.random_normal([self.output_size, 1], stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                    B = tf.Variable(tf.zeros([self.output_size, 1]), name = \"last_net_bias_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        #self.W_mem = tf.Variable(tf.random_normal(shape =[self.memory_size,self.output_size],stddev = self.stddev),\n",
    "        #                        name = \"weight_mem_last\")\n",
    "        self.W_mem = tf.get_variable(\"weight_mem_last\", shape=[self.memory_size,self.output_size],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "        self.b_mem = tf.Variable(tf.zeros(shape = [self.memory_size, 1]),\n",
    "                                name = \"bias_mem_last\")\n",
    "        \n",
    "    def compute_output(self, x, memory):## ADD THE DROPOUTS !!! REMOVE THE SOFTMAX OF THE LAST LAYER !!!\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                x = tf.nn.elu(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "               \n",
    "        delta_mem = tf.add(tf.matmul(self.W_mem, x),self.b_mem)\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.2 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Phys:\n",
    "    \n",
    "    def __init__(self, nb_agent, nb_landmark, hidden_layer_size = 256, env_dim = 2, \n",
    "                 batch_size = 1024, stddev_phys_output = 0.0001):\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.batch_size = batch_size\n",
    "        self.env_dim = env_dim\n",
    "        self.nb_agent = nb_agent\n",
    "        self.nb_landmark = nb_landmark\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.init_all()\n",
    "        \n",
    "    def init_phys_module(self):\n",
    "        self.network_phys = PhysicalNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                              self.env_dim, self.hidden_layer_size)\n",
    "\n",
    "\n",
    "    def compute_output(self, x_agent):\n",
    "        output = []\n",
    "        for x in x_agent:\n",
    "            output.append(tf.reshape(self.network_phys.compute_output(x), [256, -1, 1]))\n",
    "            \n",
    "        all_phys_output = tf.concat(output, axis = 2)\n",
    "        self.PhiX = softmax_pooling(all_phys_output)\n",
    "        return self.PhiX\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_phys_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 35.4 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Utterance:\n",
    "    \n",
    "    def __init__(self, nb_agent, goal_size, vocabulary_size = 20, \n",
    "                 hidden_layer_size = 256, memory_size = 32, temperature = 1, batch_size = 1024,\n",
    "                 stddev_phys_output = 0.0001):\n",
    "        self.size_goal = goal_size\n",
    "        self.nb_agent = nb_agent\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.memory_size = memory_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.goal = tf.placeholder(tf.float32, [self.size_goal, None])\n",
    "        \n",
    "        self.init_all()\n",
    "        \n",
    "\n",
    "    def init_com_module(self):## Les poids seront les mêmes pour tous les agents\n",
    "        self.network_com = CommunicationNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                             self.vocabulary_size)\n",
    "\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_com_module()\n",
    "\n",
    "    def compute_output(self, c_agent, mem_agent):\n",
    "        output = []\n",
    "        delta_mem = []\n",
    "        for c, mem in zip(c_agent, mem_agent):\n",
    "            o, m = self.network_com.compute_output(c, mem)\n",
    "            output.append(tf.reshape(o, [256, -1, 1]))\n",
    "            delta_mem.append(m)\n",
    "\n",
    "        all_comm_output = tf.concat(output, axis = 2)\n",
    "        PhiC = softmax_pooling(all_comm_output)\n",
    "        \n",
    "        return PhiC, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.7 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Last:\n",
    "    \n",
    "    def __init__(self, hidden_layer_size = 256, size_goal = 8, memory_size = 32, batch_size = 1024, \n",
    "                 stddev_phys_output = 0.0001, vocabulary_size = 20, env_dim = 2, temperature = 1):\n",
    "        self.temperature = temperature\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.env_dim = env_dim\n",
    "        self.vocabulary_size = vocabulary_size \n",
    "        self.batch_size = batch_size\n",
    "        self.memory_size = memory_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.size_goal = size_goal\n",
    "        self.init_all()\n",
    "\n",
    "    def init_last_module(self):\n",
    "        inp_size = (2*self.hidden_layer_size + self.size_goal)\n",
    "        out_size = self.vocabulary_size + 2*self.env_dim\n",
    "        self.last_net = LastNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                inp_size, output_size = out_size)\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_last_module()\n",
    "\n",
    "    def sample_utterance(self, output):## Vérifier qu'on prend un bon slice sur l'output\n",
    "        u = -tf.log(-tf.log(tf.random_uniform(shape = [self.vocabulary_size, self.batch_size],dtype=tf.float32)))\n",
    "        utterance_output = tf.slice(output, [2*self.env_dim, 0], [self.vocabulary_size, self.batch_size])\n",
    "        gumbel = tf.exp((utterance_output + u)/self.temperature)\n",
    "        denoms = tf.reduce_sum(gumbel, axis = 0)\n",
    "        utterance = gumbel/denoms\n",
    "        return utterance\n",
    "        \n",
    "    def sample_phys(self, output):\n",
    "        u = tf.random_normal(shape = [2*self.env_dim, self.batch_size],dtype=tf.float32, stddev = self.stddev_phys_output)\n",
    "        o = tf.add(tf.slice(output, [0, 0], [2*self.env_dim, self.batch_size]), u)\n",
    "        sample_move = tf.slice(o, [0, 0], [self.env_dim, self.batch_size])\n",
    "        sample_gaze  = tf.slice(o, [self.env_dim, 0], [self.env_dim, self.batch_size])\n",
    "        return sample_move, sample_gaze\n",
    "            \n",
    "    def compute_output(self, PhiX, PhiC, last_mem, goal):\n",
    "        Phi = tf.concat([PhiX, goal, PhiC], axis = 0)\n",
    "        output, memory = self.last_net.compute_output(Phi, last_mem)\n",
    "        utterance = self.sample_utterance(output)\n",
    "        move, gaze = self.sample_phys(output)\n",
    "        return move, gaze, utterance, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.3 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy:# Two memories per Agent: one for the communication module, the other one for the last module. Is it correct ?\n",
    "\n",
    "    def __init__(self,nb_agent, nb_landmark, goal_size, vocabulary_size = 20, hidden_layer_size = 256, \n",
    "                 memory_size = 32, temperature = 1, batch_size = 1024, stddev_phys_output = 0.0001, env_dim = 2):\n",
    "        self.nb_agent = nb_agent\n",
    "        self.goal_size = goal_size\n",
    "        self.nb_landmark = nb_landmark\n",
    "        \n",
    "        self.phys_module = Policy_Phys(self.nb_agent, self.nb_landmark)\n",
    "        self.utterance_module = Policy_Utterance(self.nb_agent, self.goal_size)\n",
    "        self.last_module = Policy_Last()\n",
    "        \n",
    "        self.list_PhiX = []\n",
    "        self.list_PhiC = []\n",
    "            \n",
    "    def compute_output(self, list_pos, list_utterances, list_goals, list_mem, list_last_mem):\n",
    "        list_moves = []\n",
    "        list_gazes = []\n",
    "        list_new_utterances = []\n",
    "        list_last_delta_mem = []\n",
    "        PhiX = self.phys_module.compute_output(list_pos)\n",
    "        PhiC, list_delta_mem = self.utterance_module.compute_output(list_utterances, list_mem)\n",
    "        self.list_PhiX.append(PhiX)\n",
    "        self.list_PhiC.append(PhiC)\n",
    "        for last_mem, goal in zip(list_last_mem, list_goals):\n",
    "            m, g, u, ldm = self.last_module.compute_output(PhiX, PhiC, last_mem, goal)\n",
    "            list_moves.append(m)\n",
    "            list_gazes.append(g)\n",
    "            list_new_utterances.append(u)\n",
    "            list_last_delta_mem.append(ldm)\n",
    "            \n",
    "        return list_moves, list_gazes, list_new_utterances, list_delta_mem, list_last_delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 119 ms\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, name, name_target, vocabulary_size = 20, batch_size = 1024, env_dim = 2, goal_size = 8, \n",
    "                 memory_size = 32, time_delta = 0.1, nb_actions = 3, damping_coeff = 0.5):\n",
    "        self.nb_actions = nb_actions\n",
    "        self.name_target = name_target\n",
    "        self.env_dim = env_dim\n",
    "        self.memory_size = memory_size\n",
    "        self.name = name\n",
    "        self.goal_size = goal_size\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        \n",
    "        with tf.variable_scope(\"agent\" + str(self.name)):\n",
    "            self.pos = tf.placeholder(tf.float32, [self.env_dim, self.batch_size]) \n",
    "            self.velocity = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.gaze = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.utterance = tf.placeholder(tf.float32, [self.vocabulary_size, self.batch_size])\n",
    "\n",
    "            self.memory = tf.placeholder(tf.float32, [self.memory_size,self.batch_size])\n",
    "\n",
    "            self.memory_last = tf.placeholder(tf.float32, [self.memory_size, self.batch_size])\n",
    "\n",
    "            self.tensor_goal_location = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.tensor_goal_type = tf.placeholder(tf.float32, [self.nb_actions, self.batch_size])\n",
    "            self.col = tf.placeholder(tf.float32, [3, 1])\n",
    "\n",
    "    def compute_reward_agent(self,goal_agent_pos, goal_agent_gaze, output_velocity, output_gaze, new_utterance): \n",
    "        ## Modifier la norme u, il s'agit de l'output\n",
    "        #du réseau, non pas de la position !\n",
    "        with tf.name_scope(\"reward_computation\"):\n",
    "            r1 = tf.reshape(tf.square(tf.norm(goal_agent_pos - self.tensor_goal_location, axis = 0)), [1, self.batch_size])\n",
    "            r2 = tf.reshape(tf.square(tf.norm(goal_agent_gaze - self.tensor_goal_location, axis = 0)), [1, self.batch_size])\n",
    "            utt_norm = tf.square(tf.norm(new_utterance, axis = 0))\n",
    "            u_norm = tf.square(tf.norm(tf.concat([output_velocity, output_gaze], axis = 0), axis = 0))\n",
    "            vec = tf.concat([r1, r2, tf.zeros([1,self.batch_size], tf.float32)], axis = 0)\n",
    "            v1 = tf.reduce_sum(tf.multiply(vec, self.tensor_goal_type), axis = 0)\n",
    "            r = -v1 #+ utt_norm + u_norm)\n",
    "        return r\n",
    "                                            \n",
    "    def get_position(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def get_velocity(self):\n",
    "        return self.velocity\n",
    "    \n",
    "    def get_gaze(self):\n",
    "        return self.gaze\n",
    "\n",
    "    def get_utterance(self):\n",
    "        return self.utterance\n",
    "                                        \n",
    "    def get_memory(self):\n",
    "        return self.memory\n",
    "    \n",
    "    def get_memory_last(self):\n",
    "        return self.memory_last\n",
    "    \n",
    "    def get_phys_state(self):\n",
    "        return (self.get_position(), self.get_velocity(), self.get_gaze(), self.get_col)\n",
    "    \n",
    "    def get_name_target(self):\n",
    "        return self.name_target\n",
    "    \n",
    "    def get_goal(self, other_ags):\n",
    "        other_agents = [other_ags[i].get_color() for i in self.name_target[0, :]]\n",
    "        colors = tf.concat(other_agents, axis = 1)\n",
    "        return tf.concat([self.tensor_goal_type, self.tensor_goal_location, colors], axis = 0)\n",
    "          \n",
    "    def get_all_iterations_variables(self):\n",
    "        return self.pos, self.velocity, self.gaze, self.utterance, self.memory, self.memory_last\n",
    "    \n",
    "    def get_color(self):\n",
    "        return self.col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 326 ms\n"
     ]
    }
   ],
   "source": [
    "class Environment:\n",
    "    # Use this class to instantiate an environment on N batches. All batches share the same structure, but not not the\n",
    "    # same goals.\n",
    "    def __init__(self, nb_agents = 3, nb_landmarks = 0, time_delta = 0.1, env_dim = 2, batch_size = 1024,\n",
    "                 goal_type_size = 3, damping_coef = 0.5, vocabulary_size = 20):\n",
    "        self.env_dim = env_dim\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.batch_size = batch_size\n",
    "        self.goal_type_size = goal_type_size\n",
    "        self.goal_size = self.goal_type_size + 3 + self.env_dim\n",
    "        self.nb_agents = nb_agents\n",
    "        self.nb_landmarks = nb_landmarks\n",
    "        self.time_delta = tf.constant([time_delta])\n",
    "        self.list_agents = []\n",
    "        self.list_phys_tensors = []\n",
    "        self.list_utter_tensors = []\n",
    "        self.list_mem_tensors = []\n",
    "        self.list_mem_last_tensors = []\n",
    "        self.list_goals_tensors = []\n",
    "        self.list_velocity_tensors = []\n",
    "        self.list_gaze_tensors = []\n",
    "        self.goal_type_tensors = []\n",
    "        self.col_tensors = []\n",
    "        self.goal_location_tensors = []\n",
    "        self.damping_coeff = damping_coef\n",
    "    \n",
    "        \n",
    "    def init_agents(self):\n",
    "        for i in range(self.nb_agents):\n",
    "            ag = Agent(name = i, name_target = self.name_of_targets[i])\n",
    "            self.list_agents.append(ag)\n",
    "            self.list_phys_tensors.append(ag.get_position())\n",
    "            self.list_utter_tensors.append(ag.get_utterance())\n",
    "            self.list_velocity_tensors.append(ag.velocity)\n",
    "            self.list_gaze_tensors.append(ag.velocity)\n",
    "            self.goal_location_tensors.append(ag.tensor_goal_location)\n",
    "            self.goal_type_tensors.append(ag.tensor_goal_type)\n",
    "            self.col_tensors.append(ag.col)\n",
    "            self.list_mem_tensors.append(ag.get_memory())\n",
    "            self.list_mem_last_tensors.append(ag.get_memory_last())\n",
    "            \n",
    "    def init_goals_tensors(self):\n",
    "        for ag in self.list_agents: \n",
    "            self.list_goals_tensors.append(ag.get_goal(self.list_agents))\n",
    "     \n",
    "    #def init_new_agents_states(self):\n",
    "    #    for i in range(self.nb_agents):\n",
    "    #        ag = self.list_agents[i]\n",
    "    #        tens_utterance = self.policy.list_utterance[i]\n",
    "    #        tens_velocity = self.policy.list_move[i]\n",
    "    #        tens_gaze = self.policy.list_gaze[i]\n",
    "    #        tens_mem_delta = self.policy.list_delta_mem_comm[i]\n",
    "    #        tens_mem_delta_last = self.policy.list_delta_mem_last[i]\n",
    "    #        ag.compute_new_state(tens_utterance, tens_velocity, tens_gaze, tens_mem_delta, tens_mem_delta_last)\n",
    "         \n",
    "\n",
    "    def compute_reward_agents(self, new_pos, new_gaze, list_move, new_utterance): \n",
    "        ## Check the shuffle for the pos of agent and gaze is OK !!\n",
    "        rewards = []\n",
    "        ag_positions = []\n",
    "        ag_gazes = []\n",
    "        ag_goal_on_agent = []\n",
    "        ag_velocities = []\n",
    "        ag_utterances = []\n",
    "        for i,agent in enumerate(self.list_agents):## Useless, take list directly\n",
    "            ag_positions.append(new_pos[i])\n",
    "            ag_gazes.append(new_gaze[i])\n",
    "            ag_velocities.append(list_move[i])\n",
    "            ag_utterances.append(new_utterance[i])\n",
    "            \n",
    "        agent_positions = tf.stack(ag_positions, axis = 2)\n",
    "        agent_gazes = tf.stack(ag_gazes, axis = 2)\n",
    "        agent_velocities = tf.stack(ag_velocities, axis = 2)\n",
    "        agent_utterances = tf.stack(ag_utterances, axis = 2)\n",
    "        \n",
    "        for i in range(self.nb_agents):\n",
    "            agent = self.list_agents[i]\n",
    "            name_target = agent.get_name_target()[0, :]\n",
    "            l1 = [[0, k, j] for k,j in enumerate(name_target)]\n",
    "            l2 = [[1, k, j] for k,j in enumerate(name_target)]\n",
    "            l3 = [l1, l2]\n",
    "\n",
    "            position_target = tf.gather_nd(agent_positions, l3)\n",
    "            gaze_target = tf.gather_nd(agent_gazes, l3)\n",
    "            \n",
    "            own_velocity = tf.reshape(tf.slice(agent_velocities, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                         [self.env_dim, self.batch_size])  \n",
    "            \n",
    "            own_gaze = tf.reshape(tf.slice(agent_gazes, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                         [self.env_dim, self.batch_size])\n",
    "            \n",
    "            own_utterance = tf.reshape(tf.slice(agent_utterances, [0, 0, i], [self.vocabulary_size, self.batch_size, 1]), \n",
    "                                         [self.vocabulary_size, self.batch_size])\n",
    "            \n",
    "            reward_agent = agent.compute_reward_agent(position_target, gaze_target, own_velocity, own_gaze, own_utterance)\n",
    "            rewards.append(reward_agent)\n",
    "          \n",
    "        #Concat on another axis\n",
    "        rewards_batch = tf.reduce_mean(tf.concat(rewards, axis = 0), axis = 0)\n",
    "        return rewards_batch\n",
    "    \n",
    "    def compute_new_state(self, tensor_new_utterance, tensor_new_velocity, tensor_new_gaze, tensor_memory_delta, \n",
    "                          tensor_memory_delta_last, tensor_pos, tensor_velocity, tensor_memory, tensor_memory_last):\n",
    "        ## ADD THE FORCES TO THE NEW VELOCITY !!\n",
    "        ## ADD GAUSSIAN NOISE TO THE MEMORY UPDATE !\n",
    "        new_pos = tensor_pos + tf.multiply(tensor_velocity,self.time_delta)\n",
    "        new_velocity = (tf.multiply(tensor_velocity, self.damping_coeff) + \n",
    "                                                  tf.multiply(tensor_new_velocity, self.time_delta))\n",
    "        new_gaze = tensor_new_gaze\n",
    "        new_memory = tensor_memory + tensor_memory_delta\n",
    "        new_memory_last = tensor_memory_last + tensor_memory_delta_last\n",
    "        new_utterance = tensor_new_utterance\n",
    "        \n",
    "        return new_pos, new_velocity, new_gaze, new_utterance, new_memory, new_memory_last\n",
    "\n",
    "    def random_env_init(self):\n",
    "        self.name_of_targets = []\n",
    "        self.p = []\n",
    "        self.v = []\n",
    "        self.g = []\n",
    "        self.go = []\n",
    "        self.co = []\n",
    "        self.gl = []\n",
    "        self.utter = []\n",
    "        self.memory = []\n",
    "        self.memory_last = []\n",
    "        for i in range(self.nb_agents):\n",
    "            self.name_of_targets.append(np.random.randint(0, self.nb_agents, (1, self.batch_size)))\n",
    "            #self.p.append(np.transpose(np.array([[0.0,0.0] for i in range(self.batch_size)])))\n",
    "            bound = 100\n",
    "            self.p.append(np.round(np.random.uniform(-bound, bound, [2, self.batch_size]), 2))\n",
    "            #self.gl.append(np.transpose(np.array([[1.0,1.0] for i in range(self.batch_size)])))\n",
    "            #Before [0, 10]\n",
    "            self.gl.append(np.round(np.random.uniform(-bound, bound, [2, self.batch_size]), 2))\n",
    "            self.v.append(np.zeros([self.env_dim, self.batch_size]))\n",
    "            self.g.append(np.zeros([self.env_dim, self.batch_size]))\n",
    "            self.go.append(np.transpose(np.array([[1,0, 0] for i in range(self.batch_size)])))\n",
    "            self.co.append(np.random.uniform(0, 255, [3, 1]))\n",
    "            \n",
    "            self.utter.append(np.zeros([20, self.batch_size]))\n",
    "            self.memory.append(np.zeros([32, self.batch_size]))\n",
    "            self.memory_last.append(np.zeros([32, self.batch_size]))\n",
    "            \n",
    "            \n",
    "        \n",
    "        self.init_agents()\n",
    "        self.init_goals_tensors()   \n",
    "        return self.p, self.gl, self.v, self.g, self.go, self.utter, self.co, self.memory, self.memory_last\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.list_agents, self.list_phys_tensors, self.list_utter_tensors,self.list_velocity_tensors, \n",
    "        self.list_gaze_tensors, self.goal_location_tensors, self.goal_type_tensors, self.col_tensors, \n",
    "        self.list_mem_tensors, self.list_mem_last_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 293 ms\n"
     ]
    }
   ],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self, nb_agents, nb_landmarks, time_horizon, batch_size = 1024, time_delta = 0.1):\n",
    "        #tf.reset_default_graph()\n",
    "        self.time_horizon = time_horizon\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_agents = nb_agents\n",
    "        self.nb_landmarks = nb_landmarks\n",
    "        self.time_delta = time_delta\n",
    "\n",
    "    def instantiate_environment(self):## ADD THE AUXILIARY REWARDS !!!!!\n",
    "        self.env = Environment(nb_agents = self.nb_agents)\n",
    "        self.policy = Policy(self.nb_agents, self.nb_landmarks, self.env.goal_size)\n",
    "     \n",
    "    def create_feed_dict(self, p, gl, v, g, go, utter, co, memory, memory_last, h_pos, h_utter, h_velocity, \n",
    "                         h_gaze, h_goal_location, h_goal_type, h_col, h_mem, h_last_mem):\n",
    "        init_values = p + gl + v + g + go + utter + co + memory + memory_last\n",
    "        placeholders_list = (h_pos + h_goal_location + h_velocity + h_gaze + h_goal_type + h_utter + h_col + h_mem + \n",
    "        h_last_mem)\n",
    "        feed_dict = {a:b for a,b in zip(placeholders_list, init_values)}\n",
    "        return feed_dict\n",
    "        \n",
    "    def train_batch(self, step_number, sess):\n",
    "        self.overall_res = []\n",
    "        p, gl, v, g, go, utter, co,  memory, memory_last = self.env.random_env_init()\n",
    "        list_ag, h_pos, h_utter, h_velocity, h_gaze, h_goal_location, h_goal_type, h_col, h_mem, h_last_mem = self.env.get_placeholders()\n",
    "        self.feed_dict = self.create_feed_dict(p, gl, v, g, go, utter, co, memory, memory_last, h_pos, h_utter, \n",
    "                        h_velocity, h_gaze, h_goal_location, h_goal_type, h_col, h_mem, h_last_mem)\n",
    "        \n",
    "        list_goals = self.env.list_goals_tensors\n",
    "        t = tf.constant(1)\n",
    "        return_sofar = tf.constant(0.0)\n",
    "        optimizer = tf.train.RMSPropOptimizer(0.00001)\n",
    "        self.suite_pos = []\n",
    "        arguments = [h_pos, h_utter, h_velocity, list_goals, h_mem, h_last_mem, return_sofar, t]\n",
    "        result = tf.while_loop(self.condition, self.body, loop_vars = arguments)\n",
    "        tf.summary.scalar('accuracy', result[-2])\n",
    "        #step = optimizer.minimize(-result[-2])\n",
    "        grads = optimizer.compute_gradients(-result[-2])\n",
    "        step = optimizer.apply_gradients(grads)\n",
    "        for index, grad in enumerate(grads):\n",
    "            tf.summary.histogram(\"{}-grad\".format(grads[index][1].name), grads[index])\n",
    "        \n",
    "        print(\"Initializing variables\")\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        merged = tf.summary.merge_all()\n",
    "        file_writer = tf.summary.FileWriter('Summary/train',sess.graph)\n",
    "        sess.run(init_op)\n",
    "        print(\"Start running\")\n",
    "        for j in range(step_number):\n",
    "            #return sess.run(self.env.list_agents[0].tensor_goal_location, self.feed_dict)\n",
    "            list_output = sess.run([merged, step] + result, self.feed_dict)\n",
    "            file_writer.add_summary(list_output[0], j)\n",
    "            self.overall_res.append(list_output)\n",
    "            if j%50 == 0:\n",
    "                final_pos = list_output[2]\n",
    "                final_dist = [np.mean(np.sqrt(np.sum((pos - gl[0])**2, axis = 0))) for pos in final_pos]\n",
    "                final_place = [np.mean(final_pos[0], axis = 1)]\n",
    "                min_x = [final_pos[0][0, :].min()]\n",
    "                min_y = [final_pos[0][1, :].min()]\n",
    "                max_x = [final_pos[0][0, :].max()]\n",
    "                max_y = [final_pos[0][1, :].max()]\n",
    "                self.overall_res.append(list_output)\n",
    "                print(list_output[-2])\n",
    "                print(final_dist)\n",
    "                print(final_place)\n",
    "                print(\"mean goals\")\n",
    "                print(np.mean(gl[0], axis = 1))\n",
    "                print(\"min\")\n",
    "                print(min_x, min_y)\n",
    "                print(\"max\")\n",
    "                print(max_x, max_y)\n",
    "                print(\"\\n\")\n",
    "        \n",
    "        return self.overall_res\n",
    "    \n",
    "    # Structure of args [h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t]\n",
    "    def body(self, h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t):\n",
    "        list_moves, list_gazes, list_utterances, list_delta_mem, list_last_delta_mem =self.policy.compute_output(\n",
    "                h_pos, h_utterance, list_goals, h_mem, h_mem_last)\n",
    "        new_pos_agents = []\n",
    "        new_utterance_agents = []\n",
    "        new_velocity_agents = []\n",
    "        new_gaze_agents = []\n",
    "        new_h_mem_agents = []\n",
    "        new_h_mem_last_agents = []\n",
    "        for i in range(self.env.nb_agents):\n",
    "            output_utterance = list_utterances[i]\n",
    "            output_velocity = list_moves[i]\n",
    "            output_gaze = list_gazes[i]\n",
    "            memory_delta = list_delta_mem[i]\n",
    "            memory_delta_last = list_last_delta_mem[i]\n",
    "            \n",
    "            new_pos, new_velocity, new_gaze, new_utterance, new_memory, new_memory_last = self.env.compute_new_state(\n",
    "                output_utterance, output_velocity, output_gaze, memory_delta, memory_delta_last, h_pos[i], \n",
    "                h_velocity[i], h_mem[i], h_mem_last[i])\n",
    "            \n",
    "            new_pos_agents.append(new_pos)\n",
    "            new_velocity_agents.append(new_velocity)\n",
    "            new_utterance_agents.append(new_utterance)\n",
    "            new_gaze_agents.append(new_gaze)\n",
    "            new_h_mem_agents.append(new_memory)\n",
    "            new_h_mem_last_agents.append(new_memory_last)\n",
    "\n",
    "        new_reward_batch = self.env.compute_reward_agents(new_pos_agents, new_gaze_agents, new_velocity_agents,\n",
    "                                              new_utterance_agents)\n",
    "        \n",
    "        #Reaadd\n",
    "        return_sofar = new_reward_batch\n",
    "        t += 1\n",
    "        \n",
    "        return [new_pos_agents, new_utterance_agents, new_velocity_agents, list_goals, new_h_mem_agents, new_h_mem_last_agents, \n",
    "        return_sofar, t]\n",
    "        \n",
    "    # Structure of args [h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t]\n",
    "    def condition(self, h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t):\n",
    "        return tf.less(t, self.time_horizon)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.49 ms\n"
     ]
    }
   ],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-528.6 ,  -88.26])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.76 ms\n"
     ]
    }
   ],
   "source": [
    "exp.env.gl[0][:, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.96 ms\n"
     ]
    }
   ],
   "source": [
    "x = [exp.overall_res[i][2][0][0,100] for i in range(len(exp.overall_res))]\n",
    "y = [exp.overall_res[i][2][0][1,100] for i in range(len(exp.overall_res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.25702148,   1.78474609])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.58 ms\n"
     ]
    }
   ],
   "source": [
    "np.mean(exp.env.gl[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name phys_variable/weight_0:0-grad is illegal; using phys_variable/weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_1:0-grad is illegal; using phys_variable/weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_2:0-grad is illegal; using phys_variable/weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_0:0-grad is illegal; using phys_variable/bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_1:0-grad is illegal; using phys_variable/bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_2:0-grad is illegal; using phys_variable/bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name Variable:0-grad is illegal; using Variable_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_0:0-grad is illegal; using com_variable/com_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_1:0-grad is illegal; using com_variable/com_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_2:0-grad is illegal; using com_variable/com_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable_1/com_net_bias_0:0-grad is illegal; using com_variable_1/com_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable_1/com_net_bias_1:0-grad is illegal; using com_variable_1/com_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable_1/com_net_bias_2:0-grad is illegal; using com_variable_1/com_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_com:0-grad is illegal; using weight_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_com:0-grad is illegal; using bias_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name Variable_1:0-grad is illegal; using Variable_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/lastnet_weight_0:0-grad is illegal; using last_variable/lastnet_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_1:0-grad is illegal; using last_variable/last_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_2:0-grad is illegal; using last_variable/last_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable_1/last_net_bias_0:0-grad is illegal; using last_variable_1/last_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable_1/last_net_bias_1:0-grad is illegal; using last_variable_1/last_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable_1/last_net_bias_2:0-grad is illegal; using last_variable_1/last_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_last:0-grad is illegal; using weight_mem_last_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_last:0-grad is illegal; using bias_mem_last_0-grad instead.\n",
      "Initializing variables\n",
      "Start running\n",
      "-13306.8\n",
      "[104.33355512468745]\n",
      "[array([ 0.00665671, -2.47256899], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-99.618141] [-100.04008]\n",
      "max\n",
      "[100.71101] [100.24728]\n",
      "\n",
      "\n",
      "-13211.6\n",
      "[103.94271064038313]\n",
      "[array([ 0.3096818 , -2.19016266], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-99.456879] [-100.01701]\n",
      "max\n",
      "[100.5881] [100.65359]\n",
      "\n",
      "\n",
      "-13109.2\n",
      "[103.51303692719884]\n",
      "[array([ 0.65905797, -1.81563711], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-99.421104] [-99.976311]\n",
      "max\n",
      "[100.81493] [101.28481]\n",
      "\n",
      "\n",
      "-12999.1\n",
      "[103.04192726492325]\n",
      "[array([ 1.08881915, -1.39760292], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-98.742844] [-98.990578]\n",
      "max\n",
      "[101.30878] [101.5702]\n",
      "\n",
      "\n",
      "-12882.0\n",
      "[102.52939445105552]\n",
      "[array([ 1.56425512, -0.94546616], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-98.772552] [-97.884956]\n",
      "max\n",
      "[101.52753] [101.96276]\n",
      "\n",
      "\n",
      "-12754.9\n",
      "[101.97650401193947]\n",
      "[array([ 2.12570763, -0.47143009], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-97.70314] [-97.187248]\n",
      "max\n",
      "[101.91893] [102.38192]\n",
      "\n",
      "\n",
      "-12609.9\n",
      "[101.33974653988011]\n",
      "[array([ 2.75113487,  0.0817    ], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-97.627487] [-95.709663]\n",
      "max\n",
      "[101.9944] [102.66238]\n",
      "\n",
      "\n",
      "-12451.1\n",
      "[100.63199839680371]\n",
      "[array([ 3.47462749,  0.69983476], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-95.650017] [-94.505859]\n",
      "max\n",
      "[102.01328] [102.28572]\n",
      "\n",
      "\n",
      "-12266.2\n",
      "[99.80890681612307]\n",
      "[array([ 4.33108044,  1.44676447], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-94.421227] [-91.933128]\n",
      "max\n",
      "[102.48494] [103.30249]\n",
      "\n",
      "\n",
      "-12060.0\n",
      "[98.878996771094691]\n",
      "[array([ 5.35001278,  2.29217982], dtype=float32)]\n",
      "mean goals\n",
      "[ 1.04342773 -0.39195313]\n",
      "min\n",
      "[-92.676102] [-89.971695]\n",
      "max\n",
      "[102.20539] [103.0554]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: bias_mem_last_0-grad\n\t [[Node: bias_mem_last_0-grad = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](bias_mem_last_0-grad/tag, bias_mem_last_0-grad/values)]]\n\nCaused by op 'bias_mem_last_0-grad', defined at:\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-213-7d95598408fb>\", line 5, in <module>\n    l = exp.train_batch(5000, sess)\n  File \"<ipython-input-208-080dbab844c3>\", line 42, in train_batch\n    tf.summary.histogram(\"{}-grad\".format(grads[index][1].name), grads[index])\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/summary/summary.py\", line 192, in histogram\n    tag=tag, values=values, name=scope)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 129, in _histogram_summary\n    name=name)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: bias_mem_last_0-grad\n\t [[Node: bias_mem_last_0-grad = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](bias_mem_last_0-grad/tag, bias_mem_last_0-grad/values)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: bias_mem_last_0-grad\n\t [[Node: bias_mem_last_0-grad = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](bias_mem_last_0-grad/tag, bias_mem_last_0-grad/values)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-7d95598408fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstantiate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-208-080dbab844c3>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, step_number, sess)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m#return sess.run(self.env.list_agents[0].tensor_goal_location, self.feed_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mlist_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverall_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: bias_mem_last_0-grad\n\t [[Node: bias_mem_last_0-grad = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](bias_mem_last_0-grad/tag, bias_mem_last_0-grad/values)]]\n\nCaused by op 'bias_mem_last_0-grad', defined at:\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-213-7d95598408fb>\", line 5, in <module>\n    l = exp.train_batch(5000, sess)\n  File \"<ipython-input-208-080dbab844c3>\", line 42, in train_batch\n    tf.summary.histogram(\"{}-grad\".format(grads[index][1].name), grads[index])\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/summary/summary.py\", line 192, in histogram\n    tag=tag, values=values, name=scope)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 129, in _histogram_summary\n    name=name)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: bias_mem_last_0-grad\n\t [[Node: bias_mem_last_0-grad = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](bias_mem_last_0-grad/tag, bias_mem_last_0-grad/values)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11min 58s\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "exp = Experiment(1, 0, 10)\n",
    "exp.instantiate_environment()\n",
    "l = exp.train_batch(5000, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.sum((exp.overall_res[-1][2][0] - exp.env.gl[0])**2, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.64 ms\n"
     ]
    }
   ],
   "source": [
    "k = 2000\n",
    "x = exp.overall_res[k][2][0][0, :]\n",
    "y = exp.overall_res[k][2][0][1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x180cf66d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "plt.plot(x, y, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.32 ms\n"
     ]
    }
   ],
   "source": [
    "gap = np.random.uniform(0, 100, [2, 1024])\n",
    "gag = np.zeros([2, 1024])\n",
    "ov = np.zeros([2, 1024])\n",
    "og = np.zeros([2, 1024])\n",
    "nu = np.zeros([20, 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.292438000965172"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.65 ms\n"
     ]
    }
   ],
   "source": [
    "np.sqrt((np.sum((l[1][2][0] - exp.env.gl[0])**2, axis = 0)))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'reward_computation_13/Neg:0' shape=(1024,) dtype=float32>]\n",
      "Tensor(\"Mean_4:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-6680.5977"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "gap_tensor = tf.constant(gap, tf.float32)\n",
    "gag_tensor = tf.constant(gag, tf.float32)\n",
    "ov_tensor = tf.constant(ov, tf.float32)\n",
    "og_tensor = tf.constant(og, tf.float32)\n",
    "nu_tensor = tf.constant(nu, tf.float32)\n",
    "feed_dict = {exp.env.list_agents[0].tensor_goal_location: exp.env.gl[0], \n",
    "             exp.env.list_agents[0].tensor_goal_type:np.transpose(np.array([[1, 0, 0] for i in range(1024)]))}\n",
    "res = exp.env.compute_reward_agents([gap_tensor], [gag_tensor], [ov_tensor], [nu_tensor])\n",
    "sess.run(res, feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6680.5959703852477"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.91 ms\n"
     ]
    }
   ],
   "source": [
    "-np.mean(np.sum((gap - exp.env.gl[0])**2, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<tf.Tensor 'agent0/Placeholder_6:0' shape=(2, 1024) dtype=float32>: array([[-2.25,  0.58, -3.4 , ...,  4.96, -3.08,  3.95],\n",
       "        [ 4.77,  0.9 , -2.87, ..., -1.09, -1.8 , -4.69]]),\n",
       " <tf.Tensor 'agent0/Placeholder_1:0' shape=(2, 1024) dtype=float32>: array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " <tf.Tensor 'agent0/Placeholder_7:0' shape=(3, 1024) dtype=float32>: array([[1, 1, 1, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " <tf.Tensor 'agent0/Placeholder:0' shape=(2, 1024) dtype=float32>: array([[-4.17,  4.98, -2.81, ..., -4.68,  1.16,  4.49],\n",
       "        [-2.15, -3.83, -2.22, ...,  1.45, -2.69, -1.2 ]]),\n",
       " <tf.Tensor 'agent0/Placeholder_3:0' shape=(20, 1024) dtype=float32>: array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " <tf.Tensor 'agent0/Placeholder_5:0' shape=(32, 1024) dtype=float32>: array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " <tf.Tensor 'agent0/Placeholder_4:0' shape=(32, 1024) dtype=float32>: array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " <tf.Tensor 'agent0/Placeholder_8:0' shape=(3, 1) dtype=float32>: array([[ 226.2819439 ],\n",
       "        [ 142.15859791],\n",
       "        [  46.3687557 ]])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "exp.feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.5       ,   17.68958282,   24.84115028,  193.07865906], dtype=float32)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.77 ms\n"
     ]
    }
   ],
   "source": [
    "e[2][0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1.        ,    0.        ,    0.        ,    0.5       ,\n",
       "          0.        ,   17.68958282,   24.84115028,  193.07865906], dtype=float32)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.5 ms\n"
     ]
    }
   ],
   "source": [
    "e[6][0][:, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument must be a dense tensor: [array([[ 3.59053731,  8.21302223,  3.32342291, ...,  5.74585104,\n         4.84798861,  1.30313444],\n       [ 8.06056118,  3.05529952,  4.10966778, ...,  0.43250307,\n         0.17211625,  2.81950474]], dtype=float32)] - got shape [1, 2, 1024], but wanted [1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-396-f3c69dc306aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    383\u001b[0m                          \"\"\" - got shape %s, but wanted %s.\"\"\" % (\n\u001b[1;32m    384\u001b[0m                              \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                              _GetDenseDimensions(values)))\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;31m# python/numpy default float type is float64. We prefer float32 instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument must be a dense tensor: [array([[ 3.59053731,  8.21302223,  3.32342291, ...,  5.74585104,\n         4.84798861,  1.30313444],\n       [ 8.06056118,  3.05529952,  4.10966778, ...,  0.43250307,\n         0.17211625,  2.81950474]], dtype=float32)] - got shape [1, 2, 1024], but wanted [1]."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.3 ms\n"
     ]
    }
   ],
   "source": [
    "e = tf.constant(l[0][1][0])\n",
    "ee = tf.gather_nd(e, exp.env.l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-394-8b1328fcbeae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ee' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.79 ms\n"
     ]
    }
   ],
   "source": [
    "uu = sess.run(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.329129751505288"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.87 ms\n"
     ]
    }
   ],
   "source": [
    "np.mean(np.sqrt(np.sum((l[-1][1][0] - np.ones((2, 1024)))**2, axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.94038602, -0.94031342, -0.94031677, ..., -0.94016784,\n",
       "         -0.94046345, -0.94030191],\n",
       "        [-0.93938235, -0.93933402, -0.93932448, ..., -0.93918149,\n",
       "         -0.93951934, -0.93923045]]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.33 ms\n"
     ]
    }
   ],
   "source": [
    "l[-1][1] - np.ones((2, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.6 ms\n"
     ]
    }
   ],
   "source": [
    "phys_net = PhysicalNet([2, 2], 2, output_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00048801]\n",
      " [ 0.00045316]]\n",
      "time: 50.4 ms\n"
     ]
    }
   ],
   "source": [
    "phys_net = PhysicalNet([2], 2, output_size = 1)\n",
    "c = tf.constant([[1.0], [1.0]])\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        print(sess.run(phys_net.compute_output(c)))\n",
    "        W = sess.run(phys_net.Weights[0])\n",
    "        b = sess.run(phys_net.Biases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00048801],\n",
       "       [ 0.00045316]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.09 ms\n"
     ]
    }
   ],
   "source": [
    "np.dot(W, np.array([[1.0], [1.0]])) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.73 ms\n"
     ]
    }
   ],
   "source": [
    "np.array([[1.0], [1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00065883],\n",
       "       [ 0.00069445]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.35 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "2 5\n",
      "3 6\n",
      "time: 41.8 ms\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip([1, 2, 3], [4, 5, 6]):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.6 ms\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "d[\"a\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 3}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 86.5 ms\n"
     ]
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1, 4)\n",
      "1 (2, 5)\n",
      "2 (3, 6)\n",
      "time: 4.08 ms\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(zip([1, 2, 3], [4, 5, 6])):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.8 ms\n"
     ]
    }
   ],
   "source": [
    "(1, 2, 3)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.9 ms\n"
     ]
    }
   ],
   "source": [
    "i0 = tf.constant(0)\n",
    "m0 = tf.ones([2, 2])\n",
    "c = lambda i, m: i < 10\n",
    "b = lambda i, m: [i+1, tf.concat([m, m], axis=0)]\n",
    "r = tf.while_loop(\n",
    "    c, b, loop_vars=[i0, m0],\n",
    "    shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, array([[ 1.,  1.],\n",
      "       [ 1.,  1.],\n",
      "       [ 1.,  1.],\n",
      "       ..., \n",
      "       [ 1.,  1.],\n",
      "       [ 1.,  1.],\n",
      "       [ 1.,  1.]], dtype=float32)]\n",
      "time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.ones((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-407-2066483bd6fe>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-407-2066483bd6fe>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [1 for i in range(5) if i < 3 else 5]\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[1 for i in range(5) if i < 3 else 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n",
      "time: 4.79 ms\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print([i for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.8 ms\n"
     ]
    }
   ],
   "source": [
    "u = tf.Variable([[-0.5, -1.0], [-1.0, -1.0]])\n",
    "output = tf.nn.elu(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Elu_4:0' shape=(2, 2) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.36 ms\n"
     ]
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39346933, -0.63212055],\n",
       "       [-0.63212055, -0.63212055]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 45.4 ms\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "sess.run(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "l = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.22 ms\n"
     ]
    }
   ],
   "source": [
    "l[0] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 3]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.05 ms\n"
     ]
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1024)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.64 ms\n"
     ]
    }
   ],
   "source": [
    "np.transpose(np.array([[1, 0, 0] for i in range(1024)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
