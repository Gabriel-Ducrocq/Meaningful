{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python import debug as tf_debug\n",
    "%load_ext autotime\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.2 ms\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.78 ms\n"
     ]
    }
   ],
   "source": [
    "def softmax_pooling(x):\n",
    "    coefs = tf.nn.softmax(x, dim = -1)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = -1)\n",
    "    return softmax_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 59.8 ms\n"
     ]
    }
   ],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, output_size, keep_prob = 0.9, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                #B = tf.Variable(tf.random_normal([self.layer_sizes[i], 1], stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                B = tf.get_variable(\"bias_\" + str(i), shape=[self.layer_sizes[i], 1],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): ## ADD THE DROPOUTS ## ADD THE SOFTMAX AT THE END ?\n",
    "            for i in range(self.nb_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (self.nb_layers - 1):\n",
    "                    x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "                else:\n",
    "                    x = tf.nn.elu(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 89.4 ms\n"
     ]
    }
   ],
   "source": [
    "class CommunicationNet: ## ADD THE MEMORY !! \n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, keep_prob = 0.9, memory_size = 32,\n",
    "                 stddev_epsilon = 0.35, output_size = 256, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.memory_size = memory_size\n",
    "        self.stddev_epsilon = stddev_epsilon\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.Variable(tf.random_normal([self.layer_sizes[(self.nb_layers-1)], self.memory_size]\n",
    "                                                            ,stddev = self.stddev))\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                #B = tf.Variable(tf.random_normal([self.layer_sizes[i], 1],stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                B = tf.Variable(tf.zeros([self.layer_sizes[i], 1]), name = \"com_net_bias_\" + str(i))\n",
    "                tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        #self.W_mem = tf.Variable(tf.random_normal(shape =[self.memory_size,self.output_size],stddev = self.stddev), name = \"weight_mem_com\")\n",
    "        self.W_mem = tf.get_variable(\"weight_mem_com\" , shape=[self.memory_size,self.output_size],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "        self.b_mem = tf.Variable(tf.zeros(shape = [self.memory_size, 1]), name = \"bias_mem_com\")\n",
    "\n",
    "        \n",
    "    def compute_output(self, x, memory):## ADD THE DROPOUTS AND SOFTMAX ?\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                x = tf.nn.elu(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = tf.add(tf.matmul(self.W_mem, x),self.b_mem)\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "class LastNet: ## ADD THE MEMORY !! The memory initialization is random ==> set it 0\n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, keep_prob = 0.9, memory_size = 32, \n",
    "                 stddev_epsilon = 0.35, output_size = 24, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.memory_size = memory_size\n",
    "        self.stddev_epsilon = stddev_epsilon\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.Variable(tf.random_normal([self.output_size, self.memory_size],stddev = self.stddev))\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.get_variable(\"lastnet_weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"last_net_weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"last_net_weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i != (self.nb_layers - 1):\n",
    "                    #B = tf.Variable(tf.random_normal([self.layer_sizes[i+1], 1],stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                    B = tf.Variable(tf.zeros([self.layer_sizes[i], 1]), name = \"last_net_bias_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    #B = tf.Variable(tf.random_normal([self.output_size, 1], stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                    B = tf.Variable(tf.zeros([self.output_size, 1]), name = \"last_net_bias_\" + str(i))\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        #self.W_mem = tf.Variable(tf.random_normal(shape =[self.memory_size,self.output_size],stddev = self.stddev),\n",
    "        #                        name = \"weight_mem_last\")\n",
    "        self.W_mem = tf.get_variable(\"weight_mem_last\", shape=[self.memory_size,self.output_size],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "        self.b_mem = tf.Variable(tf.zeros(shape = [self.memory_size, 1]),\n",
    "                                name = \"bias_mem_last\")\n",
    "        \n",
    "    def compute_output(self, x, memory):## ADD THE DROPOUTS !!! REMOVE THE SOFTMAX OF THE LAST LAYER !!!\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                x = tf.nn.elu(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "               \n",
    "        delta_mem = tf.add(tf.matmul(self.W_mem, x),self.b_mem)\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.7 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Phys:\n",
    "    \n",
    "    def __init__(self, nb_agent, nb_landmark, hidden_layer_size = 256, env_dim = 2, \n",
    "                 batch_size = 1024, stddev_phys_output = 0.0001):\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.batch_size = batch_size\n",
    "        self.env_dim = env_dim\n",
    "        self.nb_agent = nb_agent\n",
    "        self.nb_landmark = nb_landmark\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.init_all()\n",
    "        \n",
    "    def init_phys_module(self):\n",
    "        self.network_phys = PhysicalNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                              self.env_dim, self.hidden_layer_size)\n",
    "\n",
    "\n",
    "    def compute_output(self, x_agent):\n",
    "        output = []\n",
    "        for x in x_agent:\n",
    "            output.append(tf.reshape(self.network_phys.compute_output(x), [256, -1, 1]))\n",
    "            \n",
    "        all_phys_output = tf.concat(output, axis = 2)\n",
    "        self.PhiX = softmax_pooling(all_phys_output)\n",
    "        return self.PhiX\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_phys_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Utterance:\n",
    "    \n",
    "    def __init__(self, nb_agent, goal_size, vocabulary_size = 20, \n",
    "                 hidden_layer_size = 256, memory_size = 32, temperature = 1, batch_size = 1024,\n",
    "                 stddev_phys_output = 0.0001):\n",
    "        self.size_goal = goal_size\n",
    "        self.nb_agent = nb_agent\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.memory_size = memory_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.goal = tf.placeholder(tf.float32, [self.size_goal, None])\n",
    "        \n",
    "        self.init_all()\n",
    "        \n",
    "\n",
    "    def init_com_module(self):## Les poids seront les mêmes pour tous les agents\n",
    "        self.network_com = CommunicationNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                             self.vocabulary_size)\n",
    "\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_com_module()\n",
    "\n",
    "    def compute_output(self, c_agent, mem_agent):\n",
    "        output = []\n",
    "        delta_mem = []\n",
    "        for c, mem in zip(c_agent, mem_agent):\n",
    "            o, m = self.network_com.compute_output(c, mem)\n",
    "            output.append(tf.reshape(o, [256, -1, 1]))\n",
    "            delta_mem.append(m)\n",
    "\n",
    "        all_comm_output = tf.concat(output, axis = 2)\n",
    "        PhiC = softmax_pooling(all_comm_output)\n",
    "        \n",
    "        return PhiC, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 53.6 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Last:\n",
    "    \n",
    "    def __init__(self, hidden_layer_size = 256, size_goal = 8, memory_size = 32, batch_size = 1024, \n",
    "                 stddev_phys_output = 0.0001, vocabulary_size = 20, env_dim = 2, temperature = 1):\n",
    "        self.temperature = temperature\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.env_dim = env_dim\n",
    "        self.vocabulary_size = vocabulary_size \n",
    "        self.batch_size = batch_size\n",
    "        self.memory_size = memory_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.size_goal = size_goal\n",
    "        self.init_all()\n",
    "\n",
    "    def init_last_module(self):\n",
    "        inp_size = (2*self.hidden_layer_size + self.size_goal)\n",
    "        out_size = self.vocabulary_size + 2*self.env_dim\n",
    "        self.last_net = LastNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                inp_size, output_size = out_size)\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_last_module()\n",
    "\n",
    "    def sample_utterance(self, output):## Vérifier qu'on prend un bon slice sur l'output\n",
    "        u = -tf.log(-tf.log(tf.random_uniform(shape = [self.vocabulary_size, self.batch_size],dtype=tf.float32)))\n",
    "        utterance_output = tf.slice(output, [2*self.env_dim, 0], [self.vocabulary_size, self.batch_size])\n",
    "        gumbel = tf.exp((utterance_output + u)/self.temperature)\n",
    "        denoms = tf.reduce_sum(gumbel, axis = 0)\n",
    "        utterance = gumbel/denoms\n",
    "        return utterance\n",
    "        \n",
    "    def sample_phys(self, output):\n",
    "        u = tf.random_normal(shape = [2*self.env_dim, self.batch_size],dtype=tf.float32, stddev = self.stddev_phys_output)\n",
    "        o = tf.add(tf.slice(output, [0, 0], [2*self.env_dim, self.batch_size]), u)\n",
    "        sample_move = tf.slice(o, [0, 0], [self.env_dim, self.batch_size])\n",
    "        sample_gaze  = tf.slice(o, [self.env_dim, 0], [self.env_dim, self.batch_size])\n",
    "        return sample_move, sample_gaze\n",
    "            \n",
    "    def compute_output(self, PhiX, PhiC, last_mem, goal):\n",
    "        Phi = tf.concat([PhiX, goal, PhiC], axis = 0)\n",
    "        output, memory = self.last_net.compute_output(Phi, last_mem)\n",
    "        utterance = self.sample_utterance(output)\n",
    "        move, gaze = self.sample_phys(output)\n",
    "        return move, gaze, utterance, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 577 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy:# Two memories per Agent: one for the communication module, the other one for the last module. Is it correct ?\n",
    "\n",
    "    def __init__(self,nb_agent, nb_landmark, goal_size, vocabulary_size = 20, hidden_layer_size = 256,\n",
    "                 memory_size = 32, temperature = 1, batch_size = 1024, stddev_phys_output = 0.0001, env_dim = 2,\n",
    "                 goal_type_size = 3, time_delta = 0.1, damping_coeff = 0.5):\n",
    "        self.nb_agent = nb_agent\n",
    "        self.goal_size = goal_size\n",
    "        self.nb_landmark = nb_landmark\n",
    "        self.env_dim = env_dim\n",
    "        self.goal_type_size = goal_type_size\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.memory_size = memory_size\n",
    "        self.time_delta = time_delta\n",
    "        self.damping_coeff = damping_coeff\n",
    "        \n",
    "        self.phys_module = Policy_Phys(self.nb_agent, self.nb_landmark)\n",
    "        self.utterance_module = Policy_Utterance(self.nb_agent, self.goal_size)\n",
    "        self.last_module = Policy_Last()\n",
    "        \n",
    "        self.list_PhiX = []\n",
    "        self.list_PhiC = []\n",
    "        \n",
    "        self.init_placeholders()\n",
    "         \n",
    "    #h_pos, h_utter, h_velocity, h_gaze, h_goal_location, h_goal_type, h_col, h_mem, h_last_mem \n",
    "    def init_placeholders(self):\n",
    "        self.h_pos = [tf.placeholder(tf.float32, shape = [self.env_dim, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        self.h_utterance = [tf.placeholder(tf.float32, shape = [self.vocabulary_size, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        self.h_velocity = [tf.placeholder(tf.float32, shape = [self.env_dim, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        self.h_gaze = [tf.placeholder(tf.float32, shape = [self.env_dim, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        self.h_goal_location = [tf.placeholder(tf.float32, shape = [self.env_dim, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        self.h_goal_type = [tf.placeholder(tf.float32, shape = [self.goal_type_size, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        self.h_col = [tf.placeholder(tf.float32, shape = [3, 1]) for i in range(self.nb_agent)]\n",
    "        self.h_mem = [tf.placeholder(tf.float32, shape = [self.memory_size, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        self.h_mem_last = [tf.placeholder(tf.float32, shape = [self.memory_size, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        self.h_name_targets = [tf.placeholder(tf.int32, shape = [1, self.batch_size]) for i in range(self.nb_agent)]\n",
    "        \n",
    "        \n",
    "    def get_placeholders(self):\n",
    "        return [self.h_pos, self.h_utterance, self.h_velocity, self.h_gaze, self.h_goal_location, self.h_goal_type,\n",
    "        self.h_col, self.h_mem, self.h_mem_last, self.h_name_targets]\n",
    "    \n",
    "    def get_list_goals(self, list_name_targets):\n",
    "        list_goals = []\n",
    "        for i in range(self.nb_agent):\n",
    "            list_goals.append(self.init_goal_agent(i))\n",
    "            \n",
    "        return list_goals\n",
    "\n",
    "    def init_goal_agent(self, agent_number):\n",
    "        other_agents = tf.gather(self.h_col, self.h_name_targets[agent_number])\n",
    "        colors = tf.reshape(tf.concat(other_agents, axis = 1), [3, self.batch_size])\n",
    "        return tf.concat([self.h_goal_type[agent_number], self.h_goal_location[agent_number], colors], axis = 0)\n",
    "        \n",
    "    def compute_output(self, list_pos, list_utterances, list_goals, list_mem, list_last_mem):\n",
    "        list_moves = []\n",
    "        list_gazes = []\n",
    "        list_new_utterances = []\n",
    "        list_last_delta_mem = []\n",
    "        PhiX = self.phys_module.compute_output(list_pos)\n",
    "        PhiC, list_delta_mem = self.utterance_module.compute_output(list_utterances, list_mem)\n",
    "        self.list_PhiX.append(PhiX)\n",
    "        self.list_PhiC.append(PhiC)\n",
    "        for last_mem, goal in zip(list_last_mem, list_goals):\n",
    "            m, g, u, ldm = self.last_module.compute_output(PhiX, PhiC, last_mem, goal)\n",
    "            list_moves.append(m)\n",
    "            list_gazes.append(g)\n",
    "            list_new_utterances.append(u)\n",
    "            list_last_delta_mem.append(ldm)\n",
    "            \n",
    "        return list_moves, list_gazes, list_new_utterances, list_delta_mem, list_last_delta_mem\n",
    "    \n",
    "    def compute_reward_agents(self, new_pos, new_gaze, list_move, new_utterance, goal_locations, list_targets, goal_type): \n",
    "        ## Check the shuffle for the pos of agent and gaze is OK !!\n",
    "        rewards = []\n",
    "        ag_positions = []\n",
    "        ag_gazes = []\n",
    "        ag_goal_on_agent = []\n",
    "        ag_velocities = []\n",
    "        ag_utterances = []\n",
    "        ag_goal_locations = []\n",
    "        ag_goal_type = []\n",
    "        for i in range(self.nb_agent):## Useless, take list directly\n",
    "            ag_positions.append(new_pos[i])\n",
    "            ag_gazes.append(new_gaze[i])\n",
    "            ag_velocities.append(list_move[i])\n",
    "            ag_utterances.append(new_utterance[i])\n",
    "            ag_goal_locations.append(goal_locations[i])\n",
    "            ag_goal_type.append(goal_type[i])\n",
    "            \n",
    "        agent_positions = tf.stack(ag_positions, axis = 2)\n",
    "        agent_gazes = tf.stack(ag_gazes, axis = 2)\n",
    "        agent_velocities = tf.stack(ag_velocities, axis = 2)\n",
    "        agent_utterances = tf.stack(ag_utterances, axis = 2)\n",
    "        agent_goal_locations = tf.stack(ag_goal_locations, axis = 2)\n",
    "        agent_goal_type = tf.stack(ag_goal_type, axis = 2)\n",
    "        \n",
    "        for i in range(self.nb_agent):\n",
    "            name_target = tf.reshape(tf.gather_nd(list_targets[i], [[0,k] for k in range(self.batch_size)]), [self.batch_size, 1])\n",
    "            #l1 = [[0, k, j] for k,j in enumerate(name_target)]\n",
    "            print(name_target)\n",
    "            l1 = tf.concat([tf.constant([[0] for i in range(self.batch_size)]), tf.constant([[i] for i in range(self.batch_size)]),\n",
    "                           name_target], axis = 1) \n",
    "            #l2 = [[1, k, j] for k,j in enumerate(name_target)]\n",
    "            l2 = tf.concat([tf.constant([[1] for i in range(self.batch_size)]), tf.constant([[i] for i in range(self.batch_size)]),\n",
    "                           name_target], axis = 1)            \n",
    "            l3 = [l1, l2]\n",
    "\n",
    "            position_target = tf.gather_nd(agent_positions, l3)\n",
    "            gaze_target = tf.gather_nd(agent_gazes, l3)\n",
    "            \n",
    "            own_velocity = tf.reshape(tf.slice(agent_velocities, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                         [self.env_dim, self.batch_size])  \n",
    "            \n",
    "            own_gaze = tf.reshape(tf.slice(agent_gazes, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                         [self.env_dim, self.batch_size])\n",
    "            \n",
    "            own_goal_location = tf.reshape(tf.slice(agent_goal_locations, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                          [self.env_dim, self.batch_size])\n",
    "            \n",
    "            own_utterance = tf.reshape(tf.slice(agent_utterances, [0, 0, i], [self.vocabulary_size, self.batch_size, 1]), \n",
    "                                         [self.vocabulary_size, self.batch_size])\n",
    "            \n",
    "            own_goal_type = tf.reshape(tf.slice(agent_goal_type, [0, 0, i], [3, self.batch_size, 1]), \n",
    "                                          [3, self.batch_size])\n",
    "            \n",
    "            reward_agent = self.compute_reward_agent(position_target, gaze_target, own_velocity, own_gaze,\n",
    "                                                      own_utterance, own_goal_location, own_goal_type)\n",
    "            rewards.append(reward_agent)\n",
    "          \n",
    "        #Concat on another axis\n",
    "        rewards_batch = tf.reduce_mean(tf.concat(rewards, axis = 0), axis = 0)\n",
    "        return rewards_batch\n",
    "    \n",
    "    \n",
    "    def compute_reward_agent(self,goal_agent_pos, goal_agent_gaze, output_velocity, output_gaze, new_utterance, \n",
    "                             goal_location, goal_type): \n",
    "        ## Modifier la norme u, il s'agit de l'output\n",
    "        #du réseau, non pas de la position !\n",
    "        with tf.name_scope(\"reward_computation\"):\n",
    "            r1 = tf.reshape(tf.square(tf.norm(goal_agent_pos - goal_location, axis = 0)), [1, self.batch_size])\n",
    "            r2 = tf.reshape(tf.square(tf.norm(goal_agent_gaze - goal_location, axis = 0)), [1, self.batch_size])\n",
    "            utt_norm = tf.square(tf.norm(new_utterance, axis = 0))\n",
    "            u_norm = tf.square(tf.norm(tf.concat([output_velocity, output_gaze], axis = 0), axis = 0))\n",
    "            vec = tf.concat([r1, r2, tf.zeros([1,self.batch_size], tf.float32)], axis = 0)\n",
    "            v1 = tf.reduce_sum(tf.multiply(vec, goal_type), axis = 0)\n",
    "            r = -(v1 + utt_norm + u_norm)\n",
    "        return r\n",
    "    \n",
    "    def compute_new_state(self, tensor_new_utterance, tensor_new_velocity, tensor_new_gaze, tensor_memory_delta, \n",
    "                          tensor_memory_delta_last, tensor_pos, tensor_velocity, tensor_memory, tensor_memory_last):\n",
    "        ## ADD THE FORCES TO THE NEW VELOCITY !!\n",
    "        ## ADD GAUSSIAN NOISE TO THE MEMORY UPDATE !\n",
    "        new_pos = tensor_pos + tf.multiply(tensor_velocity,self.time_delta)\n",
    "        new_velocity = (tf.multiply(tensor_velocity, self.damping_coeff) + \n",
    "                                                  tf.multiply(tensor_new_velocity, self.time_delta))\n",
    "        new_gaze = tensor_new_gaze\n",
    "        new_memory = tensor_memory + tensor_memory_delta\n",
    "        new_memory_last = tensor_memory_last + tensor_memory_delta_last\n",
    "        new_utterance = tensor_new_utterance\n",
    "        \n",
    "        return new_pos, new_velocity, new_gaze, new_utterance, new_memory, new_memory_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 83.3 ms\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, name, name_target, vocabulary_size = 20, batch_size = 1024, env_dim = 2, goal_size = 8, \n",
    "                 memory_size = 32, time_delta = 0.1, nb_actions = 3, damping_coeff = 0.5):\n",
    "        self.nb_actions = nb_actions\n",
    "        self.name_target = name_target\n",
    "        self.env_dim = env_dim\n",
    "        self.memory_size = memory_size\n",
    "        self.name = name\n",
    "        self.goal_size = goal_size\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        \n",
    "        with tf.variable_scope(\"agent\" + str(self.name)):\n",
    "            self.pos = tf.placeholder(tf.float32, [self.env_dim, self.batch_size]) \n",
    "            self.velocity = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.gaze = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.utterance = tf.placeholder(tf.float32, [self.vocabulary_size, self.batch_size])\n",
    "\n",
    "            self.memory = tf.placeholder(tf.float32, [self.memory_size,self.batch_size])\n",
    "\n",
    "            self.memory_last = tf.placeholder(tf.float32, [self.memory_size, self.batch_size])\n",
    "\n",
    "            self.tensor_goal_location = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.tensor_goal_type = tf.placeholder(tf.float32, [self.nb_actions, self.batch_size])\n",
    "            self.col = tf.placeholder(tf.float32, [3, 1])\n",
    "                                            \n",
    "    def get_position(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def get_velocity(self):\n",
    "        return self.velocity\n",
    "    \n",
    "    def get_gaze(self):\n",
    "        return self.gaze\n",
    "\n",
    "    def get_utterance(self):\n",
    "        return self.utterance\n",
    "                                        \n",
    "    def get_memory(self):\n",
    "        return self.memory\n",
    "    \n",
    "    def get_memory_last(self):\n",
    "        return self.memory_last\n",
    "    \n",
    "    def get_phys_state(self):\n",
    "        return (self.get_position(), self.get_velocity(), self.get_gaze(), self.get_col)\n",
    "    \n",
    "    def get_name_target(self):\n",
    "        return self.name_target\n",
    "    \n",
    "    def get_goal(self, other_ags):\n",
    "        other_agents = [other_ags[i].get_color() for i in self.name_target[0, :]]\n",
    "        colors = tf.concat(other_agents, axis = 1)\n",
    "        return tf.concat([self.tensor_goal_type, self.tensor_goal_location, colors], axis = 0)\n",
    "          \n",
    "    def get_all_iterations_variables(self):\n",
    "        return self.pos, self.velocity, self.gaze, self.utterance, self.memory, self.memory_last\n",
    "    \n",
    "    def get_color(self):\n",
    "        return self.col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "class Environment:\n",
    "    # Use this class to instantiate an environment on N batches. All batches share the same structure, but not not the\n",
    "    # same goals.\n",
    "    def __init__(self, nb_agents = 3, nb_landmarks = 0, time_delta = 0.1, env_dim = 2, batch_size = 1024,\n",
    "                 goal_type_size = 3, damping_coef = 0.5, vocabulary_size = 20):\n",
    "        self.env_dim = env_dim\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.batch_size = batch_size\n",
    "        self.goal_type_size = goal_type_size\n",
    "        self.goal_size = self.goal_type_size + 3 + self.env_dim\n",
    "        self.nb_agents = nb_agents\n",
    "        self.nb_landmarks = nb_landmarks\n",
    "        self.time_delta = tf.constant([time_delta])\n",
    "        self.list_agents = []\n",
    "        self.list_phys_tensors = []\n",
    "        self.list_utter_tensors = []\n",
    "        self.list_mem_tensors = []\n",
    "        self.list_mem_last_tensors = []\n",
    "        self.list_goals_tensors = []\n",
    "        self.list_velocity_tensors = []\n",
    "        self.list_gaze_tensors = []\n",
    "        self.goal_type_tensors = []\n",
    "        self.col_tensors = []\n",
    "        self.goal_location_tensors = []\n",
    "        self.damping_coeff = damping_coef\n",
    "        self.enc = OneHotEncoder(n_values=self.goal_type_size, sparse=False)\n",
    "    \n",
    "        \n",
    "    def init_agents(self):\n",
    "        for i in range(self.nb_agents):\n",
    "            ag = Agent(name = i, name_target = self.name_of_targets[i])\n",
    "            self.list_agents.append(ag)\n",
    "            self.list_phys_tensors.append(ag.get_position())\n",
    "            self.list_utter_tensors.append(ag.get_utterance())\n",
    "            self.list_velocity_tensors.append(ag.velocity)\n",
    "            self.list_gaze_tensors.append(ag.velocity)\n",
    "            self.goal_location_tensors.append(ag.tensor_goal_location)\n",
    "            self.goal_type_tensors.append(ag.tensor_goal_type)\n",
    "            self.col_tensors.append(ag.col)\n",
    "            self.list_mem_tensors.append(ag.get_memory())\n",
    "            self.list_mem_last_tensors.append(ag.get_memory_last())\n",
    "            \n",
    "    def init_goals_tensors(self):\n",
    "        for ag in self.list_agents: \n",
    "            self.list_goals_tensors.append(ag.get_goal(self.list_agents))\n",
    "\n",
    "    def random_env_init(self):\n",
    "        self.name_of_targets = []\n",
    "        self.p = []\n",
    "        self.v = []\n",
    "        self.g = []\n",
    "        self.go = []\n",
    "        self.co = []\n",
    "        self.gl = []\n",
    "        self.utter = []\n",
    "        self.memory = []\n",
    "        self.memory_last = []\n",
    "        for i in range(self.nb_agents):\n",
    "            self.name_of_targets.append(np.random.randint(0, self.nb_agents, (1, self.batch_size)))\n",
    "            #self.p.append(np.transpose(np.array([[0.0,0.0] for i in range(self.batch_size)])))\n",
    "            bound = 5\n",
    "            self.p.append(np.round(np.random.uniform(-bound, bound, [2, self.batch_size]), 2))\n",
    "            #self.gl.append(np.transpose(np.array([[1.0,1.0] for i in range(self.batch_size)])))\n",
    "            #Before [0, 10]\n",
    "            self.gl.append(np.round(np.random.uniform(-bound, bound, [2, self.batch_size]), 2))\n",
    "            self.v.append(np.zeros([self.env_dim, self.batch_size]))\n",
    "            self.g.append(np.zeros([self.env_dim, self.batch_size]))\n",
    "            J = np.random.choice(self.goal_type_size, self.batch_size)\n",
    "            self.go.append(np.transpose(self.enc.fit_transform(J.reshape(-1,1))))\n",
    "            #self.go.append(np.transpose(np.array([[1,0, 0] for i in range(self.batch_size)])))\n",
    "            self.co.append(np.random.uniform(0, 255, [3, 1]))\n",
    "            \n",
    "            self.utter.append(np.zeros([20, self.batch_size]))\n",
    "            self.memory.append(np.zeros([32, self.batch_size]))\n",
    "            self.memory_last.append(np.zeros([32, self.batch_size]))\n",
    "            \n",
    "            \n",
    "        \n",
    "        self.init_agents()\n",
    "        self.init_goals_tensors()   \n",
    "        return self.p, self.gl, self.v, self.g, self.go, self.utter, self.co, self.memory, self.memory_last, self.name_of_targets\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.list_agents, self.list_phys_tensors, self.list_utter_tensors,self.list_velocity_tensors, \n",
    "        self.list_gaze_tensors, self.goal_location_tensors, self.goal_type_tensors, self.col_tensors, \n",
    "        self.list_mem_tensors, self.list_mem_last_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 659 ms\n"
     ]
    }
   ],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self, nb_agents, nb_landmarks, time_horizon, batch_size = 1024, time_delta = 0.1):\n",
    "        #tf.reset_default_graph()\n",
    "        self.time_horizon = time_horizon\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_agents = nb_agents\n",
    "        self.nb_landmarks = nb_landmarks\n",
    "        self.time_delta = time_delta\n",
    "        \n",
    "        self.instantiate_environment()\n",
    "        self.define_placeholders()\n",
    "        \n",
    "    def instantiate_environment(self):## ADD THE AUXILIARY REWARDS !!!!!\n",
    "        self.env = Environment(nb_agents = self.nb_agents)\n",
    "        self.policy = Policy(self.nb_agents, self.nb_landmarks, self.env.goal_size)\n",
    "     \n",
    "    def define_placeholders(self):\n",
    "        (self.h_pos, self.h_utter, self.h_velocity, self.h_gaze, self.h_goal_location, self.h_goal_type, \n",
    "         self.h_col, self.h_mem, self.h_last_mem, self.h_name_targets) = self.policy.get_placeholders()\n",
    "        self.list_goals = self.policy.get_list_goals(self.h_name_targets)\n",
    "        \n",
    "    def create_feed_dict(self, p, gl, v, g, go, utter, co, memory, memory_last, name_targets):\n",
    "        init_values = p + gl + v + g + go + utter + co + memory + memory_last + name_targets\n",
    "        placeholders_list = (self.h_pos + self.h_goal_location + self.h_velocity + self.h_gaze + self.h_goal_type + \n",
    "                             self.h_utter + self.h_col + self.h_mem + self.h_last_mem + self.h_name_targets)\n",
    "        feed_dict = {a:b for a,b in zip(placeholders_list, init_values)}\n",
    "        return feed_dict\n",
    "        \n",
    "    def train_batch(self, step_number, sess):\n",
    "        self.overall_res = []\n",
    "        t = tf.constant(1)\n",
    "        return_sofar = tf.constant(0.0)\n",
    "        optimizer = tf.train.RMSPropOptimizer(0.000009)\n",
    "        self.suite_pos = []\n",
    "        arguments = [self.h_pos, self.h_gaze, self.h_utter, self.h_velocity, self.list_goals, self.h_mem, self.h_last_mem, \n",
    "                     self.h_goal_location, self.h_name_targets, self.h_goal_type, return_sofar, t]\n",
    "        result = tf.while_loop(self.condition, self.body, loop_vars = arguments)\n",
    "        tf.summary.scalar('accuracy', result[-2])\n",
    "        tf.summary.scalar('learning rate', optimizer._learning_rate)\n",
    "        #step = optimizer.minimize(-result[-2])\n",
    "        grads = optimizer.compute_gradients(-result[-2])\n",
    "        step = optimizer.apply_gradients(grads)\n",
    "        for index, grad in enumerate(grads):\n",
    "            tf.summary.histogram(\"{}-grad\".format(grads[index][1].name), grads[index])\n",
    "        \n",
    "        print(\"Initializing variables\")\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        merged = tf.summary.merge_all()\n",
    "        file_writer = tf.summary.FileWriter('Summary/train',sess.graph)\n",
    "        sess.run(init_op)\n",
    "        print(\"Start running\")\n",
    "        for j in range(step_number):\n",
    "            p, gl, v, g, go, utter, co,  memory, memory_last, name_targets = self.env.random_env_init()\n",
    "            self.feed_dict = self.create_feed_dict(p, gl, v, g, go, utter, co, memory, memory_last, name_targets)\n",
    "            list_output = sess.run([step] + result, self.feed_dict)\n",
    "            #file_writer.add_summary(list_output[1], j)\n",
    "            self.overall_res.append(list_output)\n",
    "            if j%10 == 0:\n",
    "                final_pos = list_output[1]\n",
    "                final_gaze = list_output[2]\n",
    "                final_dist = [np.sqrt(np.sum((pos - gl[0])**2, axis = 0)) for pos in final_pos]\n",
    "                final_gaze = [np.sqrt(np.sum((gaze - gl[0])**2, axis = 0)) for gaze in final_gaze]\n",
    "                zeros = np.zeros(self.batch_size)\n",
    "                r = np.stack([final_dist[0], final_gaze[0], zeros], axis = 0)\n",
    "                dist_obj = np.sum(np.multiply(r, go[0]), axis = 0)\n",
    "                final_dist_mean = np.mean(dist_obj)\n",
    "                final_dist_median = np.median(dist_obj)\n",
    "                self.overall_res.append(list_output)\n",
    "                print(\"iteration \" + str(j))\n",
    "                print(list_output[-2])\n",
    "                print(\"final distance mean:\")\n",
    "                print(final_dist_mean)\n",
    "                print(\"final distance median:\")\n",
    "                print(final_dist_median)\n",
    "        \n",
    "        return self.overall_res\n",
    "    \n",
    "    # Structure of args [h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t]\n",
    "    def body(self, h_pos, h_gaze, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, h_goal_locations, h_name_targets, \n",
    "             h_goal_type, return_sofar, t):\n",
    "        list_moves, list_gazes, list_utterances, list_delta_mem, list_last_delta_mem =self.policy.compute_output(\n",
    "                h_pos, h_utterance, list_goals, h_mem, h_mem_last)\n",
    "        new_pos_agents = []\n",
    "        new_utterance_agents = []\n",
    "        new_velocity_agents = []\n",
    "        new_gaze_agents = []\n",
    "        new_h_mem_agents = []\n",
    "        new_h_mem_last_agents = []\n",
    "        for i in range(self.env.nb_agents):\n",
    "            output_utterance = list_utterances[i]\n",
    "            output_velocity = list_moves[i]\n",
    "            output_gaze = list_gazes[i]\n",
    "            memory_delta = list_delta_mem[i]\n",
    "            memory_delta_last = list_last_delta_mem[i]\n",
    "            \n",
    "            new_pos, new_velocity, new_gaze, new_utterance, new_memory, new_memory_last = self.policy.compute_new_state(\n",
    "                output_utterance, output_velocity, output_gaze, memory_delta, memory_delta_last, h_pos[i], \n",
    "                h_velocity[i], h_mem[i], h_mem_last[i])\n",
    "            \n",
    "            new_pos_agents.append(new_pos)\n",
    "            new_velocity_agents.append(new_velocity)\n",
    "            new_utterance_agents.append(new_utterance)\n",
    "            new_gaze_agents.append(new_gaze)\n",
    "            new_h_mem_agents.append(new_memory)\n",
    "            new_h_mem_last_agents.append(new_memory_last)\n",
    "\n",
    "        new_reward_batch = self.policy.compute_reward_agents(new_pos_agents, new_gaze_agents, new_velocity_agents,\n",
    "                                              new_utterance_agents, h_goal_locations, h_name_targets, h_goal_type)\n",
    "        \n",
    "\n",
    "        return_sofar += new_reward_batch\n",
    "        t += 1\n",
    "        \n",
    "        return [new_pos_agents, new_gaze_agents, new_utterance_agents, new_velocity_agents, list_goals, new_h_mem_agents, new_h_mem_last_agents, \n",
    "        h_goal_locations, h_name_targets, h_goal_type, return_sofar, t]\n",
    "        \n",
    "    # Structure of args [h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t]\n",
    "    def condition(self, h_pos, h_gaze, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, h_goal_locations, \n",
    "                  h_name_targets, h_goal_type, return_sofar, t):\n",
    "        return tf.less(t, self.time_horizon)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"while/Reshape_6:0\", shape=(1024, 1), dtype=int32)\n",
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_0:0-grad is illegal; using phys_variable/weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_1:0-grad is illegal; using phys_variable/weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_2:0-grad is illegal; using phys_variable/weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_0:0-grad is illegal; using phys_variable/bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_1:0-grad is illegal; using phys_variable/bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_2:0-grad is illegal; using phys_variable/bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name Variable:0-grad is illegal; using Variable_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_0:0-grad is illegal; using com_variable/com_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_1:0-grad is illegal; using com_variable/com_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_2:0-grad is illegal; using com_variable/com_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable_1/com_net_bias_0:0-grad is illegal; using com_variable_1/com_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable_1/com_net_bias_1:0-grad is illegal; using com_variable_1/com_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable_1/com_net_bias_2:0-grad is illegal; using com_variable_1/com_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_com:0-grad is illegal; using weight_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_com:0-grad is illegal; using bias_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name Variable_1:0-grad is illegal; using Variable_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/lastnet_weight_0:0-grad is illegal; using last_variable/lastnet_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_1:0-grad is illegal; using last_variable/last_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_2:0-grad is illegal; using last_variable/last_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable_1/last_net_bias_0:0-grad is illegal; using last_variable_1/last_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable_1/last_net_bias_1:0-grad is illegal; using last_variable_1/last_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable_1/last_net_bias_2:0-grad is illegal; using last_variable_1/last_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_last:0-grad is illegal; using weight_mem_last_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_last:0-grad is illegal; using bias_mem_last_0-grad instead.\n",
      "Initializing variables\n",
      "Start running\n",
      "iteration 0\n",
      "-182937.0\n",
      "final distance mean:\n",
      "20.2093151156\n",
      "final distance median:\n",
      "4.30110694645\n",
      "iteration 10\n",
      "-46303.7\n",
      "final distance mean:\n",
      "8.76144150592\n",
      "final distance median:\n",
      "4.05694258576\n",
      "iteration 20\n",
      "-22157.7\n",
      "final distance mean:\n",
      "5.16392734727\n",
      "final distance median:\n",
      "3.68467659554\n",
      "iteration 30\n",
      "-9276.36\n",
      "final distance mean:\n",
      "3.73181683295\n",
      "final distance median:\n",
      "3.43857072748\n",
      "iteration 40\n",
      "-9973.32\n",
      "final distance mean:\n",
      "3.28355798968\n",
      "final distance median:\n",
      "2.91511611905\n",
      "iteration 50\n",
      "-9631.98\n",
      "final distance mean:\n",
      "3.38739928511\n",
      "final distance median:\n",
      "3.15167354258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:4011: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 60\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 70\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 80\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 90\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 100\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 110\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 120\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 130\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 140\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 150\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 160\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 170\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 180\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 190\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n",
      "iteration 200\n",
      "nan\n",
      "final distance mean:\n",
      "nan\n",
      "final distance median:\n",
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-3e8d58713927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-5b001c961075>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, step_number, sess)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_env_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mlist_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0;31m#file_writer.add_summary(list_output[1], j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverall_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9h 27min 7s\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "exp = Experiment(1, 0, 400)\n",
    "with tf.Session() as sess:\n",
    "    l = exp.train_batch(5000, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 256 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "r = [exp.overall_res[i][-2] for i in range(len(exp.overall_res))]\n",
    "dr = pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEACAYAAACQx1DIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8a25550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 629 ms\n"
     ]
    }
   ],
   "source": [
    "#pd.rolling_mean(dr, 60).plot()\n",
    "plt.plot(r)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-182937.19,\n",
       " -182937.19,\n",
       " -58116.5,\n",
       " -15716.643,\n",
       " -74588.805,\n",
       " -60870.434,\n",
       " -94771.922,\n",
       " -58028.039,\n",
       " -31981.943,\n",
       " -30729.436,\n",
       " -27055.594,\n",
       " -46303.738,\n",
       " -46303.738,\n",
       " -27625.006,\n",
       " -9790.7119,\n",
       " -68469.773,\n",
       " -16773.783,\n",
       " -23215.176,\n",
       " -10358.177,\n",
       " -47120.938,\n",
       " -10080.265,\n",
       " -13030.263,\n",
       " -22157.701,\n",
       " -22157.701,\n",
       " -18941.359,\n",
       " -13098.636,\n",
       " -9756.0957,\n",
       " -13227.911,\n",
       " -19204.219,\n",
       " -9579.959,\n",
       " -19424.828,\n",
       " -24096.383,\n",
       " -11794.164,\n",
       " -9276.3633,\n",
       " -9276.3633,\n",
       " -15492.31,\n",
       " -13280.396,\n",
       " -9519.8477,\n",
       " -9189.4082,\n",
       " -11323.009,\n",
       " -9812.6641,\n",
       " -30201.002,\n",
       " -10629.354,\n",
       " -11715.265,\n",
       " -9973.3242,\n",
       " -9973.3242,\n",
       " -10271.856,\n",
       " -11241.281,\n",
       " -11192.56,\n",
       " -10017.45,\n",
       " -12653.22,\n",
       " -9235.8359,\n",
       " -10840.249,\n",
       " -19158.432,\n",
       " -9851.3223,\n",
       " -9631.9766,\n",
       " -9631.9766,\n",
       " -9319.8818,\n",
       " -10204.132,\n",
       " -11105.599,\n",
       " -9811.1533,\n",
       " -15095.022,\n",
       " -16264.184,\n",
       " -9364.1768,\n",
       " -22028.66,\n",
       " -11208.357,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.4 ms\n"
     ]
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [2 1]]\n",
      "time: 543 ms\n"
     ]
    }
   ],
   "source": [
    "e = tf.constant([[1, 2], [3, 4]])\n",
    "g = tf.gather_nd(e, [tf.constant([[1, 0], [1, 1]]), tf.constant([[0, 1], [0, 0]])])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.38 ms\n"
     ]
    }
   ],
   "source": [
    "e = tf.constant([[0, 1, 2], [1, 0, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_16:0' shape=(2, 3) dtype=int32>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.49 ms\n"
     ]
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.1 ms\n"
     ]
    }
   ],
   "source": [
    "np.median([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-87063.805,\n",
       " -87063.805,\n",
       " -42613.492,\n",
       " -95466.906,\n",
       " -51702.867,\n",
       " -119452.19,\n",
       " -54361.605,\n",
       " -45506.168,\n",
       " -45355.227,\n",
       " -54363.707,\n",
       " -50592.652,\n",
       " -64282.707,\n",
       " -64282.707,\n",
       " -44239.941,\n",
       " -42706.688,\n",
       " -48918.352,\n",
       " -31315.318,\n",
       " -12464.795,\n",
       " -16229.566,\n",
       " -17335.041,\n",
       " -34374.93,\n",
       " -33092.418,\n",
       " -33758.09,\n",
       " -33758.09,\n",
       " -23054.051,\n",
       " -26396.902,\n",
       " -23441.33,\n",
       " -13553.037,\n",
       " -16636.049,\n",
       " -22000.59,\n",
       " -15910.657,\n",
       " -17852.219,\n",
       " -22044.727,\n",
       " -16584.189,\n",
       " -16584.189,\n",
       " -13721.631,\n",
       " -17386.037,\n",
       " -17495.488,\n",
       " -17994.559,\n",
       " -15598.205,\n",
       " -9668.4219,\n",
       " -18942.807,\n",
       " -17743.613,\n",
       " -9740.2227,\n",
       " -14156.621,\n",
       " -14156.621,\n",
       " -10293.151,\n",
       " -12772.105,\n",
       " -14022.875,\n",
       " -12508.376,\n",
       " -13253.797,\n",
       " -13280.086,\n",
       " -9958.9531,\n",
       " -6889.3926,\n",
       " -9030.5986,\n",
       " -14340.563,\n",
       " -14340.563,\n",
       " -11904.121,\n",
       " -10879.037,\n",
       " -7775.1309,\n",
       " -12467.575,\n",
       " -12387.378,\n",
       " -11923.172,\n",
       " -11323.783,\n",
       " -11144.868,\n",
       " -10955.39,\n",
       " -8239.79,\n",
       " -8239.79,\n",
       " -8856.7529,\n",
       " -8973.5801,\n",
       " -10009.217,\n",
       " -8228.1475,\n",
       " -9959.7656,\n",
       " -8921.8408,\n",
       " -9621.7822,\n",
       " -8656.2256,\n",
       " -8147.7202,\n",
       " -9009.5645,\n",
       " -9009.5645,\n",
       " -8581.2041,\n",
       " -9847.1289,\n",
       " -8783.6055,\n",
       " -8135.1001,\n",
       " -8027.188,\n",
       " -8681.8428,\n",
       " -7703.0547,\n",
       " -10157.399,\n",
       " -8117.313,\n",
       " -8001.7373,\n",
       " -8001.7373,\n",
       " -8407.6816,\n",
       " -7545.3403,\n",
       " -8257.0498,\n",
       " -8077.3325,\n",
       " -9683.75,\n",
       " -8234.916,\n",
       " -8465.2119,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.5 ms\n"
     ]
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-a268cdbdf94a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverall_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-206-a268cdbdf94a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverall_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gl' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.4 ms\n"
     ]
    }
   ],
   "source": [
    "d = [np.mean(np.sqrt(np.sum((pos[1] - gl[0])**2, axis = 0))) for pos in exp.overall_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,\n",
       "         0.,  1.,  1.,  1.,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.51 ms\n"
     ]
    }
   ],
   "source": [
    "n_samples = 20\n",
    "n_classes = 3\n",
    "J = np.random.choice(n_classes, n_samples)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(n_values=n_classes, sparse=False)\n",
    "np.transpose(enc.fit_transform(J.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "time: 2.03 ms\n"
     ]
    }
   ],
   "source": [
    "for i, k in enumerate(zip([1, 2, 3], [4, 5, 6], [7, 8, 9])):\n",
    "    print(np.dot(k, [0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
