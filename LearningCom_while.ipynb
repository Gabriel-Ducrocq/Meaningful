{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 5.03 ms\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python import debug as tf_debug\n",
    "%load_ext autotime\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 768 Âµs\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.95 ms\n"
     ]
    }
   ],
   "source": [
    "def softmax_pooling(x):\n",
    "    coefs = tf.nn.softmax(x, dim = -1)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = -1)\n",
    "    return softmax_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.4 ms\n"
     ]
    }
   ],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, output_size, keep_prob = 0.9, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    #tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    #tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                #B = tf.Variable(tf.random_normal([self.layer_sizes[i], 1], stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                B = tf.get_variable(\"bias_\" + str(i), shape=[self.layer_sizes[i], 1],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                #tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): ## ADD THE DROPOUTS ## ADD THE SOFTMAX AT THE END ?\n",
    "            for i in range(self.nb_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (self.nb_layers - 1):\n",
    "                    x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "                else:\n",
    "                    x = tf.nn.elu(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 82.9 ms\n"
     ]
    }
   ],
   "source": [
    "class CommunicationNet: ## ADD THE MEMORY !! \n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, keep_prob = 0.9, memory_size = 32,\n",
    "                 stddev_epsilon = 0.35, output_size = 256, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.memory_size = memory_size\n",
    "        self.stddev_epsilon = stddev_epsilon\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.Variable(tf.random_normal([self.layer_sizes[(self.nb_layers-1)], self.memory_size]\n",
    "                                                            ,stddev = self.stddev))\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size], stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    #tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    #tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"com_net_weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    #tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                #B = tf.Variable(tf.random_normal([self.layer_sizes[i], 1],stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                B = tf.Variable(tf.zeros([self.layer_sizes[i], 1]), name = \"com_net_bias_\" + str(i))\n",
    "                #tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        #self.W_mem = tf.Variable(tf.random_normal(shape =[self.memory_size,self.output_size],stddev = self.stddev), name = \"weight_mem_com\")\n",
    "        self.W_mem = tf.get_variable(\"weight_mem_com\" , shape=[self.memory_size,self.output_size],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "        self.b_mem = tf.Variable(tf.zeros(shape = [self.memory_size, 1]), name = \"bias_mem_com\")\n",
    "\n",
    "        \n",
    "    def compute_output(self, x, memory):## ADD THE DROPOUTS AND SOFTMAX ?\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                x = tf.nn.elu(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = tf.add(tf.matmul(self.W_mem, x),self.b_mem)\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 90.9 ms\n"
     ]
    }
   ],
   "source": [
    "class LastNet: ## ADD THE MEMORY !! The memory initialization is random ==> set it 0\n",
    "    \n",
    "    def __init__(self, layer_sizes, input_size, keep_prob = 0.9, memory_size = 32, \n",
    "                 stddev_epsilon = 0.35, output_size = 24, stddev = 0.0001):\n",
    "        self.nb_layers = len(layer_sizes)\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.input_size = input_size\n",
    "        self.memory_size = memory_size\n",
    "        self.stddev_epsilon = stddev_epsilon\n",
    "        self.output_size = output_size\n",
    "        self.stddev = stddev\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.Variable(tf.random_normal([self.output_size, self.memory_size],stddev = self.stddev))\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.get_variable(\"lastnet_weight_\" + str(i), shape=[self.layer_sizes[i], self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[i], self.input_size],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    #tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (self.nb_layers - 1):\n",
    "                    W = tf.get_variable(\"last_net_weight_\" + str(i), shape=[self.layer_sizes[(i+1)], self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.layer_sizes[(i+1)], self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    #tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.get_variable(\"last_net_weight_\" + str(i), shape=[self.output_size, self.layer_sizes[i]],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "                    #W = tf.Variable(tf.random_normal([self.output_size, self.layer_sizes[i]],stddev = self.stddev), name = \"weight_\" + str(i))\n",
    "                    #tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(self.nb_layers):\n",
    "                if i != (self.nb_layers - 1):\n",
    "                    #B = tf.Variable(tf.random_normal([self.layer_sizes[i+1], 1],stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                    B = tf.Variable(tf.zeros([self.layer_sizes[i], 1]), name = \"last_net_bias_\" + str(i))\n",
    "                    #tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    #B = tf.Variable(tf.random_normal([self.output_size, 1], stddev = self.stddev), name = \"bias_\" + str(i))\n",
    "                    B = tf.Variable(tf.zeros([self.output_size, 1]), name = \"last_net_bias_\" + str(i))\n",
    "                    #tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        #self.W_mem = tf.Variable(tf.random_normal(shape =[self.memory_size,self.output_size],stddev = self.stddev),\n",
    "        #                        name = \"weight_mem_last\")\n",
    "        self.W_mem = tf.get_variable(\"weight_mem_last\", shape=[self.memory_size,self.output_size],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer(False))\n",
    "        self.b_mem = tf.Variable(tf.zeros(shape = [self.memory_size, 1]),\n",
    "                                name = \"bias_mem_last\")\n",
    "        \n",
    "    def compute_output(self, x, memory):## ADD THE DROPOUTS !!! REMOVE THE SOFTMAX OF THE LAST LAYER !!!\n",
    "        for i in range(self.nb_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (self.nb_layers - 1):\n",
    "                x = tf.nn.dropout(tf.nn.elu(tf.matmul(W, x) + b), keep_prob = 0.9)\n",
    "            else:\n",
    "                x = tf.nn.elu(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "               \n",
    "        delta_mem = tf.add(tf.matmul(self.W_mem, x),self.b_mem)\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.7 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Phys:\n",
    "    \n",
    "    def __init__(self, nb_agent, nb_landmark, hidden_layer_size = 256, env_dim = 2, \n",
    "                 batch_size = 1024, stddev_phys_output = 0.0001):\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.batch_size = batch_size\n",
    "        self.env_dim = env_dim\n",
    "        self.nb_agent = nb_agent\n",
    "        self.nb_landmark = nb_landmark\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.init_all()\n",
    "        \n",
    "    def init_phys_module(self):\n",
    "        self.network_phys = PhysicalNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                              self.env_dim, self.hidden_layer_size)\n",
    "\n",
    "\n",
    "    def compute_output(self, x_agent):\n",
    "        output = []\n",
    "        for x in x_agent:\n",
    "            output.append(tf.reshape(self.network_phys.compute_output(x), [256, -1, 1]))\n",
    "            \n",
    "        all_phys_output = tf.concat(output, axis = 2)\n",
    "        self.PhiX = softmax_pooling(all_phys_output)\n",
    "        return self.PhiX\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_phys_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.3 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Utterance:\n",
    "    \n",
    "    def __init__(self, nb_agent, goal_size, vocabulary_size = 20, \n",
    "                 hidden_layer_size = 256, memory_size = 32, temperature = 1, batch_size = 1024,\n",
    "                 stddev_phys_output = 0.0001):\n",
    "        self.size_goal = goal_size\n",
    "        self.nb_agent = nb_agent\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.memory_size = memory_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.goal = tf.placeholder(tf.float32, [self.size_goal, None])\n",
    "        \n",
    "        self.init_all()\n",
    "        \n",
    "\n",
    "    def init_com_module(self):## Les poids seront les mÃªmes pour tous les agents\n",
    "        self.network_com = CommunicationNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                             self.vocabulary_size)\n",
    "\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_com_module()\n",
    "\n",
    "    def compute_output(self, c_agent, mem_agent):\n",
    "        output = []\n",
    "        delta_mem = []\n",
    "        for c, mem in zip(c_agent, mem_agent):\n",
    "            o, m = self.network_com.compute_output(c, mem)\n",
    "            output.append(tf.reshape(o, [256, -1, 1]))\n",
    "            delta_mem.append(m)\n",
    "\n",
    "        all_comm_output = tf.concat(output, axis = 2)\n",
    "        PhiC = softmax_pooling(all_comm_output)\n",
    "        \n",
    "        return PhiC, delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.7 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy_Last:\n",
    "    \n",
    "    def __init__(self, hidden_layer_size = 256, size_goal = 8, memory_size = 32, batch_size = 1024, \n",
    "                 stddev_phys_output = 0.0001, vocabulary_size = 20, env_dim = 2, temperature = 1):\n",
    "        self.temperature = temperature\n",
    "        self.stddev_phys_output = stddev_phys_output\n",
    "        self.env_dim = env_dim\n",
    "        self.vocabulary_size = vocabulary_size \n",
    "        self.batch_size = batch_size\n",
    "        self.memory_size = memory_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.size_goal = size_goal\n",
    "        self.init_all()\n",
    "\n",
    "    def init_last_module(self):\n",
    "        inp_size = (2*self.hidden_layer_size + self.size_goal)\n",
    "        out_size = self.vocabulary_size + 2*self.env_dim\n",
    "        self.last_net = LastNet([self.hidden_layer_size, self.hidden_layer_size, self.hidden_layer_size], \n",
    "                                inp_size, output_size = out_size)\n",
    "\n",
    "    def init_all(self):\n",
    "        self.init_last_module()\n",
    "\n",
    "    def sample_utterance(self, output):## VÃ©rifier qu'on prend un bon slice sur l'output\n",
    "        u = -tf.log(-tf.log(tf.random_uniform(shape = [self.vocabulary_size, self.batch_size],dtype=tf.float32)))\n",
    "        utterance_output = tf.slice(output, [2*self.env_dim, 0], [self.vocabulary_size, self.batch_size])\n",
    "        gumbel = tf.exp((utterance_output + u)/self.temperature)\n",
    "        denoms = tf.reduce_sum(gumbel, axis = 0)\n",
    "        utterance = gumbel/denoms\n",
    "        return utterance\n",
    "        \n",
    "    def sample_phys(self, output):\n",
    "        u = tf.random_normal(shape = [2*self.env_dim, self.batch_size],dtype=tf.float32, stddev = self.stddev_phys_output)\n",
    "        o = tf.add(tf.slice(output, [0, 0], [2*self.env_dim, self.batch_size]), u)\n",
    "        sample_move = tf.slice(o, [0, 0], [self.env_dim, self.batch_size])\n",
    "        sample_gaze  = tf.slice(o, [self.env_dim, 0], [self.env_dim, self.batch_size])\n",
    "        return sample_move, sample_gaze\n",
    "            \n",
    "    def compute_output(self, PhiX, PhiC, last_mem, goal):\n",
    "        Phi = tf.concat([PhiX, goal, PhiC], axis = 0)\n",
    "        output, memory = self.last_net.compute_output(Phi, last_mem)\n",
    "        utterance = self.sample_utterance(output)\n",
    "        move, gaze = self.sample_phys(output)\n",
    "        return move, gaze, utterance, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.5 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy:# Two memories per Agent: one for the communication module, the other one for the last module. Is it correct ?\n",
    "\n",
    "    def __init__(self,nb_agent, nb_landmark, goal_size, vocabulary_size = 20, hidden_layer_size = 256, \n",
    "                 memory_size = 32, temperature = 1, batch_size = 1024, stddev_phys_output = 0.0001, env_dim = 2):\n",
    "        self.nb_agent = nb_agent\n",
    "        self.goal_size = goal_size\n",
    "        self.nb_landmark = nb_landmark\n",
    "        \n",
    "        self.phys_module = Policy_Phys(self.nb_agent, self.nb_landmark)\n",
    "        self.utterance_module = Policy_Utterance(self.nb_agent, self.goal_size)\n",
    "        self.last_module = Policy_Last()\n",
    "        \n",
    "        self.list_PhiX = []\n",
    "        self.list_PhiC = []\n",
    "            \n",
    "    def compute_output(self, list_pos, list_utterances, list_goals, list_mem, list_last_mem):\n",
    "        list_moves = []\n",
    "        list_gazes = []\n",
    "        list_new_utterances = []\n",
    "        list_last_delta_mem = []\n",
    "        PhiX = self.phys_module.compute_output(list_pos)\n",
    "        PhiC, list_delta_mem = self.utterance_module.compute_output(list_utterances, list_mem)\n",
    "        self.list_PhiX.append(PhiX)\n",
    "        self.list_PhiC.append(PhiC)\n",
    "        for last_mem, goal in zip(list_last_mem, list_goals):\n",
    "            m, g, u, ldm = self.last_module.compute_output(PhiX, PhiC, last_mem, goal)\n",
    "            list_moves.append(m)\n",
    "            list_gazes.append(g)\n",
    "            list_new_utterances.append(u)\n",
    "            list_last_delta_mem.append(ldm)\n",
    "            \n",
    "        return list_moves, list_gazes, list_new_utterances, list_delta_mem, list_last_delta_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 153 ms\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, name, name_target, vocabulary_size = 20, batch_size = 1024, env_dim = 2, goal_size = 8, \n",
    "                 memory_size = 32, time_delta = 0.1, nb_actions = 3, damping_coeff = 0.5):\n",
    "        self.nb_actions = nb_actions\n",
    "        self.name_target = name_target\n",
    "        self.env_dim = env_dim\n",
    "        self.memory_size = memory_size\n",
    "        self.name = name\n",
    "        self.goal_size = goal_size\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        \n",
    "        with tf.variable_scope(\"agent\" + str(self.name)):\n",
    "            self.pos = tf.placeholder(tf.float32, [self.env_dim, self.batch_size]) \n",
    "            self.velocity = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.gaze = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.utterance = tf.placeholder(tf.float32, [self.vocabulary_size, self.batch_size])\n",
    "\n",
    "            self.memory = tf.placeholder(tf.float32, [self.memory_size,self.batch_size])\n",
    "\n",
    "            self.memory_last = tf.placeholder(tf.float32, [self.memory_size, self.batch_size])\n",
    "\n",
    "            self.tensor_goal_location = tf.placeholder(tf.float32, [self.env_dim, self.batch_size])\n",
    "            self.tensor_goal_type = tf.placeholder(tf.float32, [self.nb_actions, self.batch_size])\n",
    "            self.col = tf.placeholder(tf.float32, [3, 1])\n",
    "\n",
    "    def compute_reward_agent(self,goal_agent_pos, goal_agent_gaze, output_velocity, output_gaze, new_utterance): \n",
    "        ## Modifier la norme u, il s'agit de l'output\n",
    "        #du rÃ©seau, non pas de la position !\n",
    "        with tf.name_scope(\"reward_computation\"):\n",
    "            r1 = tf.reshape(tf.square(tf.norm(goal_agent_pos - self.tensor_goal_location, axis = 0)), [1, self.batch_size])\n",
    "            r2 = tf.reshape(tf.square(tf.norm(goal_agent_gaze - self.tensor_goal_location, axis = 0)), [1, self.batch_size])\n",
    "            utt_norm = tf.square(tf.norm(new_utterance, axis = 0))\n",
    "            u_norm = tf.square(tf.norm(tf.concat([output_velocity, output_gaze], axis = 0), axis = 0))\n",
    "            vec = tf.concat([r1, r2, tf.zeros([1,self.batch_size], tf.float32)], axis = 0)\n",
    "            v1 = tf.reduce_sum(tf.multiply(vec, self.tensor_goal_type), axis = 0)\n",
    "            r = -(v1 + utt_norm + u_norm)\n",
    "        return r\n",
    "                                            \n",
    "    def get_position(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def get_velocity(self):\n",
    "        return self.velocity\n",
    "    \n",
    "    def get_gaze(self):\n",
    "        return self.gaze\n",
    "\n",
    "    def get_utterance(self):\n",
    "        return self.utterance\n",
    "                                        \n",
    "    def get_memory(self):\n",
    "        return self.memory\n",
    "    \n",
    "    def get_memory_last(self):\n",
    "        return self.memory_last\n",
    "    \n",
    "    def get_phys_state(self):\n",
    "        return (self.get_position(), self.get_velocity(), self.get_gaze(), self.get_col)\n",
    "    \n",
    "    def get_name_target(self):\n",
    "        return self.name_target\n",
    "    \n",
    "    def get_goal(self, other_ags):\n",
    "        other_agents = [other_ags[i].get_color() for i in self.name_target[0, :]]\n",
    "        colors = tf.concat(other_agents, axis = 1)\n",
    "        return tf.concat([self.tensor_goal_type, self.tensor_goal_location, colors], axis = 0)\n",
    "          \n",
    "    def get_all_iterations_variables(self):\n",
    "        return self.pos, self.velocity, self.gaze, self.utterance, self.memory, self.memory_last\n",
    "    \n",
    "    def get_color(self):\n",
    "        return self.col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 344 ms\n"
     ]
    }
   ],
   "source": [
    "class Environment:\n",
    "    # Use this class to instantiate an environment on N batches. All batches share the same structure, but not not the\n",
    "    # same goals.\n",
    "    def __init__(self, nb_agents = 3, nb_landmarks = 0, time_delta = 0.1, env_dim = 2, batch_size = 1024,\n",
    "                 goal_type_size = 3, damping_coef = 0.5, vocabulary_size = 20):\n",
    "        self.env_dim = env_dim\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.batch_size = batch_size\n",
    "        self.goal_type_size = goal_type_size\n",
    "        self.goal_size = self.goal_type_size + 3 + self.env_dim\n",
    "        self.nb_agents = nb_agents\n",
    "        self.nb_landmarks = nb_landmarks\n",
    "        self.time_delta = tf.constant([time_delta])\n",
    "        self.list_agents = []\n",
    "        self.list_phys_tensors = []\n",
    "        self.list_utter_tensors = []\n",
    "        self.list_mem_tensors = []\n",
    "        self.list_mem_last_tensors = []\n",
    "        self.list_goals_tensors = []\n",
    "        self.list_velocity_tensors = []\n",
    "        self.list_gaze_tensors = []\n",
    "        self.goal_type_tensors = []\n",
    "        self.col_tensors = []\n",
    "        self.goal_location_tensors = []\n",
    "        self.damping_coeff = damping_coef\n",
    "    \n",
    "        \n",
    "    def init_agents(self):\n",
    "        for i in range(self.nb_agents):\n",
    "            ag = Agent(name = i, name_target = self.name_of_targets[i])\n",
    "            self.list_agents.append(ag)\n",
    "            self.list_phys_tensors.append(ag.get_position())\n",
    "            self.list_utter_tensors.append(ag.get_utterance())\n",
    "            self.list_velocity_tensors.append(ag.velocity)\n",
    "            self.list_gaze_tensors.append(ag.velocity)\n",
    "            self.goal_location_tensors.append(ag.tensor_goal_location)\n",
    "            self.goal_type_tensors.append(ag.tensor_goal_type)\n",
    "            self.col_tensors.append(ag.col)\n",
    "            self.list_mem_tensors.append(ag.get_memory())\n",
    "            self.list_mem_last_tensors.append(ag.get_memory_last())\n",
    "            \n",
    "    def init_goals_tensors(self):\n",
    "        for ag in self.list_agents: \n",
    "            self.list_goals_tensors.append(ag.get_goal(self.list_agents))\n",
    "     \n",
    "    #def init_new_agents_states(self):\n",
    "    #    for i in range(self.nb_agents):\n",
    "    #        ag = self.list_agents[i]\n",
    "    #        tens_utterance = self.policy.list_utterance[i]\n",
    "    #        tens_velocity = self.policy.list_move[i]\n",
    "    #        tens_gaze = self.policy.list_gaze[i]\n",
    "    #        tens_mem_delta = self.policy.list_delta_mem_comm[i]\n",
    "    #        tens_mem_delta_last = self.policy.list_delta_mem_last[i]\n",
    "    #        ag.compute_new_state(tens_utterance, tens_velocity, tens_gaze, tens_mem_delta, tens_mem_delta_last)\n",
    "         \n",
    "\n",
    "    def compute_reward_agents(self, new_pos, new_gaze, list_move, new_utterance): \n",
    "        ## Check the shuffle for the pos of agent and gaze is OK !!\n",
    "        rewards = []\n",
    "        ag_positions = []\n",
    "        ag_gazes = []\n",
    "        ag_goal_on_agent = []\n",
    "        ag_velocities = []\n",
    "        ag_utterances = []\n",
    "        for i,agent in enumerate(self.list_agents):## Useless, take list directly\n",
    "            ag_positions.append(new_pos[i])\n",
    "            ag_gazes.append(new_gaze[i])\n",
    "            ag_velocities.append(list_move[i])\n",
    "            ag_utterances.append(new_utterance[i])\n",
    "            \n",
    "        agent_positions = tf.stack(ag_positions, axis = 2)\n",
    "        agent_gazes = tf.stack(ag_gazes, axis = 2)\n",
    "        agent_velocities = tf.stack(ag_velocities, axis = 2)\n",
    "        agent_utterances = tf.stack(ag_utterances, axis = 2)\n",
    "        \n",
    "        for i in range(self.nb_agents):\n",
    "            agent = self.list_agents[i]\n",
    "            name_target = agent.get_name_target()[0, :]\n",
    "            l1 = [[0, k, j] for k,j in enumerate(name_target)]\n",
    "            l2 = [[1, k, j] for k,j in enumerate(name_target)]\n",
    "            l3 = [l1, l2]\n",
    "\n",
    "            position_target = tf.gather_nd(agent_positions, l3)\n",
    "            gaze_target = tf.gather_nd(agent_gazes, l3)\n",
    "            \n",
    "            own_velocity = tf.reshape(tf.slice(agent_velocities, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                         [self.env_dim, self.batch_size])  \n",
    "            \n",
    "            own_gaze = tf.reshape(tf.slice(agent_gazes, [0, 0, i], [self.env_dim, self.batch_size, 1]), \n",
    "                                         [self.env_dim, self.batch_size])\n",
    "            \n",
    "            own_utterance = tf.reshape(tf.slice(agent_utterances, [0, 0, i], [self.vocabulary_size, self.batch_size, 1]), \n",
    "                                         [self.vocabulary_size, self.batch_size])\n",
    "            \n",
    "            reward_agent = agent.compute_reward_agent(position_target, gaze_target, own_velocity, own_gaze, own_utterance)\n",
    "            rewards.append(reward_agent)\n",
    "          \n",
    "        #Concat on another axis\n",
    "        rewards_batch = tf.reduce_mean(tf.concat(rewards, axis = 0), axis = 0)\n",
    "        return rewards_batch\n",
    "    \n",
    "    def compute_new_state(self, tensor_new_utterance, tensor_new_velocity, tensor_new_gaze, tensor_memory_delta, \n",
    "                          tensor_memory_delta_last, tensor_pos, tensor_velocity, tensor_memory, tensor_memory_last):\n",
    "        ## ADD THE FORCES TO THE NEW VELOCITY !!\n",
    "        ## ADD GAUSSIAN NOISE TO THE MEMORY UPDATE !\n",
    "        new_pos = tensor_pos + tf.multiply(tensor_velocity,self.time_delta)\n",
    "        new_velocity = (tf.multiply(tensor_velocity, self.damping_coeff) + \n",
    "                                                  tf.multiply(tensor_new_velocity, self.time_delta))\n",
    "        new_gaze = tensor_new_gaze\n",
    "        new_memory = tensor_memory + tensor_memory_delta\n",
    "        new_memory_last = tensor_memory_last + tensor_memory_delta_last\n",
    "        new_utterance = tensor_new_utterance\n",
    "        \n",
    "        return new_pos, new_velocity, new_gaze, new_utterance, new_memory, new_memory_last\n",
    "\n",
    "    def random_env_init(self):\n",
    "        self.name_of_targets = []\n",
    "        self.p = []\n",
    "        self.v = []\n",
    "        self.g = []\n",
    "        self.go = []\n",
    "        self.co = []\n",
    "        self.gl = []\n",
    "        self.utter = []\n",
    "        self.memory = []\n",
    "        self.memory_last = []\n",
    "        for i in range(self.nb_agents):\n",
    "            self.name_of_targets.append(np.random.randint(0, self.nb_agents, (1, self.batch_size)))\n",
    "            #self.p.append(np.transpose(np.array([[0.0,0.0] for i in range(self.batch_size)])))\n",
    "            bound = 5\n",
    "            self.p.append(np.round(np.random.uniform(-bound, bound, [2, self.batch_size]), 2))\n",
    "            #self.gl.append(np.transpose(np.array([[1.0,1.0] for i in range(self.batch_size)])))\n",
    "            #Before [0, 10]\n",
    "            self.gl.append(np.round(np.random.uniform(-bound, bound, [2, self.batch_size]), 2))\n",
    "            self.v.append(np.zeros([self.env_dim, self.batch_size]))\n",
    "            self.g.append(np.zeros([self.env_dim, self.batch_size]))\n",
    "            self.go.append(np.transpose(np.array([[1,0, 0] for i in range(self.batch_size)])))\n",
    "            self.co.append(np.random.uniform(0, 255, [3, 1]))\n",
    "            \n",
    "            self.utter.append(np.zeros([20, self.batch_size]))\n",
    "            self.memory.append(np.zeros([32, self.batch_size]))\n",
    "            self.memory_last.append(np.zeros([32, self.batch_size]))\n",
    "            \n",
    "            \n",
    "        \n",
    "        self.init_agents()\n",
    "        self.init_goals_tensors()   \n",
    "        return self.p, self.gl, self.v, self.g, self.go, self.utter, self.co, self.memory, self.memory_last\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.list_agents, self.list_phys_tensors, self.list_utter_tensors,self.list_velocity_tensors, \n",
    "        self.list_gaze_tensors, self.goal_location_tensors, self.goal_type_tensors, self.col_tensors, \n",
    "        self.list_mem_tensors, self.list_mem_last_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 276 ms\n"
     ]
    }
   ],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self, nb_agents, nb_landmarks, time_horizon, batch_size = 1024, time_delta = 0.1):\n",
    "        #tf.reset_default_graph()\n",
    "        self.time_horizon = time_horizon\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_agents = nb_agents\n",
    "        self.nb_landmarks = nb_landmarks\n",
    "        self.time_delta = time_delta\n",
    "\n",
    "    def instantiate_environment(self):## ADD THE AUXILIARY REWARDS !!!!!\n",
    "        self.env = Environment(nb_agents = self.nb_agents)\n",
    "        self.policy = Policy(self.nb_agents, self.nb_landmarks, self.env.goal_size)\n",
    "     \n",
    "    def create_feed_dict(self, p, gl, v, g, go, utter, co, memory, memory_last, h_pos, h_utter, h_velocity, \n",
    "                         h_gaze, h_goal_location, h_goal_type, h_col, h_mem, h_last_mem):\n",
    "        init_values = p + gl + v + g + go + utter + co + memory + memory_last\n",
    "        placeholders_list = (h_pos + h_goal_location + h_velocity + h_gaze + h_goal_type + h_utter + h_col + h_mem + \n",
    "        h_last_mem)\n",
    "        feed_dict = {a:b for a,b in zip(placeholders_list, init_values)}\n",
    "        return feed_dict\n",
    "        \n",
    "    def train_batch(self, step_number, sess):\n",
    "        self.overall_res = []\n",
    "        p, gl, v, g, go, utter, co,  memory, memory_last = self.env.random_env_init()\n",
    "        list_ag, h_pos, h_utter, h_velocity, h_gaze, h_goal_location, h_goal_type, h_col, h_mem, h_last_mem = self.env.get_placeholders()\n",
    "        self.feed_dict = self.create_feed_dict(p, gl, v, g, go, utter, co, memory, memory_last, h_pos, h_utter, \n",
    "                        h_velocity, h_gaze, h_goal_location, h_goal_type, h_col, h_mem, h_last_mem)\n",
    "        \n",
    "        list_goals = self.env.list_goals_tensors\n",
    "        t = tf.constant(1)\n",
    "        return_sofar = tf.constant(0.0)\n",
    "        optimizer = tf.train.RMSPropOptimizer(0.00001)\n",
    "        self.suite_pos = []\n",
    "        arguments = [h_pos, h_utter, h_velocity, list_goals, h_mem, h_last_mem, return_sofar, t]\n",
    "        result = tf.while_loop(self.condition, self.body, loop_vars = arguments)\n",
    "        #tf.summary.scalar('accuracy', result[-2])\n",
    "        #step = optimizer.minimize(-result[-2])\n",
    "        grads = optimizer.compute_gradients(-result[-2])\n",
    "        step = optimizer.apply_gradients(grads)\n",
    "        #for index, grad in enumerate(grads):\n",
    "        #    tf.summary.histogram(\"{}-grad\".format(grads[index][1].name), grads[index])\n",
    "        \n",
    "        print(\"Initializing variables\")\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        #merged = tf.summary.merge_all()\n",
    "        #file_writer = tf.summary.FileWriter('Summary/train',sess.graph)\n",
    "        sess.run(init_op)\n",
    "        print(\"Start running\")\n",
    "        for j in range(step_number):\n",
    "            #return sess.run(self.env.list_agents[0].tensor_goal_location, self.feed_dict)\n",
    "            list_output = sess.run([step] + result, self.feed_dict)\n",
    "            #file_writer.add_summary(list_output[0], j)\n",
    "            self.overall_res.append(list_output)\n",
    "            if j%10 == 0:\n",
    "                final_pos = list_output[1]\n",
    "                final_dist = [np.mean(np.sqrt(np.sum((pos - gl[0])**2, axis = 0))) for pos in final_pos]\n",
    "                final_place = [np.mean(final_pos[0], axis = 1)]\n",
    "                min_x = [final_pos[0][0, :].min()]\n",
    "                min_y = [final_pos[0][1, :].min()]\n",
    "                max_x = [final_pos[0][0, :].max()]\n",
    "                max_y = [final_pos[0][1, :].max()]\n",
    "                self.overall_res.append(list_output)\n",
    "                print(list_output[-2])\n",
    "                print(final_dist)\n",
    "                print(final_place)\n",
    "                print(\"mean goals\")\n",
    "                print(np.mean(gl[0], axis = 1))\n",
    "                print(\"min\")\n",
    "                print(min_x, min_y)\n",
    "                print(\"max\")\n",
    "                print(max_x, max_y)\n",
    "                print(\"\\n\")\n",
    "        \n",
    "        return self.overall_res\n",
    "    \n",
    "    # Structure of args [h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t]\n",
    "    def body(self, h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t):\n",
    "        list_moves, list_gazes, list_utterances, list_delta_mem, list_last_delta_mem =self.policy.compute_output(\n",
    "                h_pos, h_utterance, list_goals, h_mem, h_mem_last)\n",
    "        new_pos_agents = []\n",
    "        new_utterance_agents = []\n",
    "        new_velocity_agents = []\n",
    "        new_gaze_agents = []\n",
    "        new_h_mem_agents = []\n",
    "        new_h_mem_last_agents = []\n",
    "        for i in range(self.env.nb_agents):\n",
    "            output_utterance = list_utterances[i]\n",
    "            output_velocity = list_moves[i]\n",
    "            output_gaze = list_gazes[i]\n",
    "            memory_delta = list_delta_mem[i]\n",
    "            memory_delta_last = list_last_delta_mem[i]\n",
    "            \n",
    "            new_pos, new_velocity, new_gaze, new_utterance, new_memory, new_memory_last = self.env.compute_new_state(\n",
    "                output_utterance, output_velocity, output_gaze, memory_delta, memory_delta_last, h_pos[i], \n",
    "                h_velocity[i], h_mem[i], h_mem_last[i])\n",
    "            \n",
    "            new_pos_agents.append(new_pos)\n",
    "            new_velocity_agents.append(new_velocity)\n",
    "            new_utterance_agents.append(new_utterance)\n",
    "            new_gaze_agents.append(new_gaze)\n",
    "            new_h_mem_agents.append(new_memory)\n",
    "            new_h_mem_last_agents.append(new_memory_last)\n",
    "\n",
    "        new_reward_batch = self.env.compute_reward_agents(new_pos_agents, new_gaze_agents, new_velocity_agents,\n",
    "                                              new_utterance_agents)\n",
    "        \n",
    "\n",
    "        return_sofar += new_reward_batch\n",
    "        t += 1\n",
    "        \n",
    "        return [new_pos_agents, new_utterance_agents, new_velocity_agents, list_goals, new_h_mem_agents, new_h_mem_last_agents, \n",
    "        return_sofar, t]\n",
    "        \n",
    "    # Structure of args [h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t]\n",
    "    def condition(self, h_pos, h_utterance, h_velocity, list_goals, h_mem, h_mem_last, return_sofar, t):\n",
    "        return tf.less(t, self.time_horizon)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing variables\n",
      "Start running\n",
      "-24126.3\n",
      "[12.558162760472847]\n",
      "[array([ -2.92517948,  11.61891079], dtype=float32)]\n",
      "mean goals\n",
      "[-0.05139648  0.0296875 ]\n",
      "min\n",
      "[-7.989243] [5.833817]\n",
      "max\n",
      "[2.1687386] [18.497654]\n",
      "\n",
      "\n",
      "-11990.5\n",
      "[5.7454875816741708]\n",
      "[array([-1.09017062,  4.05628777], dtype=float32)]\n",
      "mean goals\n",
      "[-0.05139648  0.0296875 ]\n",
      "min\n",
      "[-6.6677108] [-0.90103358]\n",
      "max\n",
      "[4.2361732] [9.5750217]\n",
      "\n",
      "\n",
      "-8422.22\n",
      "[4.4242144477652259]\n",
      "[array([ 1.17210484,  0.99846673], dtype=float32)]\n",
      "mean goals\n",
      "[-0.05139648  0.0296875 ]\n",
      "min\n",
      "[-4.3653402] [-3.7793193]\n",
      "max\n",
      "[6.8054862] [6.1948915]\n",
      "\n",
      "\n",
      "-7392.06\n",
      "[4.3491698411054154]\n",
      "[array([ 1.15792847,  0.05318924], dtype=float32)]\n",
      "mean goals\n",
      "[-0.05139648  0.0296875 ]\n",
      "min\n",
      "[-4.5640259] [-4.7941818]\n",
      "max\n",
      "[6.5850792] [5.1933756]\n",
      "\n",
      "\n",
      "-6756.67\n",
      "[4.2334846645283584]\n",
      "[array([ 0.75640285, -0.39220488], dtype=float32)]\n",
      "mean goals\n",
      "[-0.05139648  0.0296875 ]\n",
      "min\n",
      "[-4.5951529] [-5.0542321]\n",
      "max\n",
      "[6.0022473] [4.3164759]\n",
      "\n",
      "\n",
      "-6312.94\n",
      "[4.1575263289714108]\n",
      "[array([ 0.4032377 , -0.60603064], dtype=float32)]\n",
      "mean goals\n",
      "[-0.05139648  0.0296875 ]\n",
      "min\n",
      "[-4.4707932] [-5.2016921]\n",
      "max\n",
      "[5.7014208] [4.003654]\n",
      "\n",
      "\n",
      "-5915.96\n",
      "[4.0311922528643347]\n",
      "[array([ 0.1698222 , -0.61400622], dtype=float32)]\n",
      "mean goals\n",
      "[-0.05139648  0.0296875 ]\n",
      "min\n",
      "[-4.8790598] [-5.0035672]\n",
      "max\n",
      "[5.4510117] [3.9720814]\n",
      "\n",
      "\n",
      "-5569.78\n",
      "[3.7651666388921905]\n",
      "[array([ 0.01140625,  0.07604174], dtype=float32)]\n",
      "mean goals\n",
      "[-0.05139648  0.0296875 ]\n",
      "min\n",
      "[-4.6358709] [-4.1372495]\n",
      "max\n",
      "[4.712564] [4.4194551]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-064772ad3d88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstantiate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-c876f43e1a06>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, step_number, sess)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m#return sess.run(self.env.list_agents[0].tensor_goal_location, self.feed_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mlist_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;31m#file_writer.add_summary(list_output[0], j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverall_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielducrocq/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57min 48s\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "exp = Experiment(1, 0, 200)\n",
    "exp.instantiate_environment()\n",
    "with tf.Session() as sess:\n",
    "    l = exp.train_batch(5000, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
