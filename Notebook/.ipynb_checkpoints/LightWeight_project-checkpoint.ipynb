{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabrielducrocq_maths/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from datetime import datetime\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "#%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "#0.0008\n",
    "flags.DEFINE_float('learning_rate', 0.0008, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('max_steps', 20000, 'Number of iteration to train.')\n",
    "flags.DEFINE_integer('number_layers', 3, 'Number of layers in each network')\n",
    "flags.DEFINE_integer('layer_sizes', 256, 'Number of units in hidden layer.')\n",
    "flags.DEFINE_integer('batch_size', 100, 'Batch size.')\n",
    "flags.DEFINE_integer('dim_env', 2, 'dimension of the environment')\n",
    "flags.DEFINE_integer('number_goal_types', 3, 'number of different goal types')\n",
    "flags.DEFINE_integer('color_size', 3, 'number of components of the color: RGB as usual')\n",
    "flags.DEFINE_integer(\"output_size\", 256, \"number of units in the output layer\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.9, \"Dropouts rate of keeping\")\n",
    "flags.DEFINE_boolean(\"xav_init\", False,\"Distribution of initialization: False for normal, True for uniform\" )\n",
    "flags.DEFINE_integer(\"number_agents\", 1, \"Number of agents in the environment\")\n",
    "flags.DEFINE_integer(\"number_landmarks\", 1, \"Number of landmarks in the environment\")\n",
    "flags.DEFINE_integer(\"vocabulary_size\", 20, \"Size of the vocabulary\")\n",
    "flags.DEFINE_integer(\"mem_size\", 32, \"Size of the communication network's memory\")\n",
    "flags.DEFINE_integer(\"last_mem_size\", 32, \"Size of the last network's memory\")\n",
    "flags.DEFINE_float(\"gumbel_temperature\", 1, \"Temperature use for the gumbel softmax trick\")\n",
    "flags.DEFINE_float(\"sddev_phys_sampling\", 0.0001, \"Standard deviation used to sample the velocity and gaze output\")\n",
    "flags.DEFINE_float(\"delta_t\", 0.1, \"delta of time between timesteps\")\n",
    "flags.DEFINE_float(\"damping_coef\", 0.5, \"damping coefficient for the new velocity computation\")\n",
    "flags.DEFINE_float(\"stddev_memory\", 0.0001, \"standard deviation of the gaussian used to update memories\")\n",
    "flags.DEFINE_integer(\"bound\", 5, \"Bounds of generation of initial positions, centered in 0.\")\n",
    "flags.DEFINE_integer(\"time_horizon\", 100, \"Number of timestep before the end of the experiment.\")\n",
    "flags.DEFINE_integer(\"print_frequency\", 500, \"Frequency at which we print the reward, in number of steps.\")\n",
    "flags.DEFINE_boolean(\"learning_rate_decay\", True, \"Wether to use a piecewise learning rate decay or no decay at all\")\n",
    "flags.DEFINE_integer(\"tensorboard_freq\", 100, \"Frequency at which we save the statistics in tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire:\n",
    "\n",
    "- Checker que le softmax pooling est correct\n",
    "\n",
    "- Checker que le gumbel trick est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le sampling physique est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le calcul du nouvel état est correct, notamment sur les débuts et longueur de slicing et concaténation\n",
    "\n",
    "- Ajouter le calcul des forces dans le calcul du nouvel état\n",
    "\n",
    "- Vérifier que le shuffling est correct\n",
    "\n",
    "- Vérifier que le calcul du reward est correct\n",
    "\n",
    "- Vérifier que la backprop considère bien les variables broadcastées comme les mêmes.\n",
    "\n",
    "- Vérifier que le tenseur states est bien dans cet ordre sur le second axe: position, velocité, gaze, couleurs\n",
    "\n",
    "- RELIER LES LANDMARKS AUX POSITIONS DES GOALS, SINON CA N A PAS DE SENS !!!\n",
    "\n",
    "- Checker que les goals types sont bien distribués: une unique coordonnée doit être 1, les autres 0, et ce pour chaque agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_trajectory(coordinates, target_point):\n",
    "    x = coordinates[1:-1, 0]\n",
    "    y = coordinates[1:-1, 1]\n",
    "    \n",
    "    x_start = coordinates[0, 0]\n",
    "    y_start = coordinates[0, 1]\n",
    "    \n",
    "    x_final = coordinates[-1, 0]\n",
    "    y_final = coordinates[-1, 1]\n",
    "    \n",
    "    x_target, y_target = target_point\n",
    "    \n",
    "    \n",
    "    plt.plot(x,y, \"o\")\n",
    "    plt.plot(x_start, y_start, 'ro')\n",
    "    plt.plot(x_target, y_target, 'go')\n",
    "    plt.plot(x_final, y_final, 'yo')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def python_shuffle(positions, shuffle_indexes):\n",
    "    shuffled_array = np.stack(\n",
    "    [positions[shuffle_indexes[: , 0, i], :, i] for i in range(FLAGS.batch_size)], axis = 2)\n",
    "    return shuffled_array\n",
    "    \n",
    "    \n",
    "def delete_history_files():\n",
    "    if os.path.isfile(\"env_history.pkl\"):\n",
    "        os.remove(\"env_history.pkl\")\n",
    "        \n",
    "    if os.path.isfile(\"arrays_history.pkl\"):\n",
    "        os.remove(\"arrays_history.pkl\")\n",
    "        \n",
    "    if Path(\"Summary\").is_dir():\n",
    "        shutil.rmtree(\"Summary\")\n",
    "\n",
    "\n",
    "# Param: x, stacking of the output of fully connected physical network for each agent. Shape = (256, batch_size, nb_agents)\n",
    "# return: pooling of input features.\n",
    "def softmax_pooling(x):\n",
    "    # pooling function. Softmax pooling is a compromise between max pooling and average pooling\n",
    "    coefs = tf.nn.softmax(x, dim = 0)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = 0)\n",
    "    return softmax_pool\n",
    "\n",
    "\n",
    "def activation_function(x):\n",
    "    return tf.nn.elu(x)\n",
    "\n",
    "\n",
    "def gumbel_max_trick(x):\n",
    "    # Application of gumbel-softmax trick\n",
    "    # Input: output of the last network \n",
    "    u = -tf.log(-tf.log(tf.random_uniform(shape = [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size],\n",
    "                                          dtype=tf.float32)))\n",
    "    utterance_output = tf.slice(x, [0, 2*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "    gumbel = tf.exp((utterance_output + u)/FLAGS.gumbel_temperature)\n",
    "    denoms = tf.reshape(tf.reduce_sum(gumbel, axis = 1), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    utterance = gumbel/denoms\n",
    "    return utterance \n",
    "\n",
    "\n",
    "def sample_phys(x):\n",
    "    #Input: output of the last network.\n",
    "    #Output: sampled values for new velocity and gaze\n",
    "    u = tf.random_normal(shape = [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size],dtype=tf.float32,\n",
    "                         stddev = FLAGS.sddev_phys_sampling)\n",
    "    o = tf.add(tf.slice(x, [0, 0, 0], [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size]), u)\n",
    "    sample_move = tf.slice(o, [0, 0, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    sample_gaze  = tf.slice(o, [0, FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    return sample_move, sample_gaze\n",
    "\n",
    "\n",
    "def compute_new_states(old_states, new_velocities, new_delta_gazes, new_utterances):\n",
    "    #Computes the new states according to the equations of the papers.\n",
    "    # Input: the old states of shape [number agents + nb_landmarks, 3*env dim + color size, batch size] because color is in state\n",
    "    # and of shape [number_agents, 2*env_dim, batch size]\n",
    "    # Adding the outputs of landmark, which are all zeros.\n",
    "    #new_velocities = tf.concat([new_velocities, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "\n",
    "    #new_delta_gazes = tf.concat([new_delta_gazes, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "    \n",
    "    #old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #new_pos = tf.slice(old_states, [0, 0, 0], \n",
    "    #                   [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    #new_gazes = old_gazes + new_delta_gazes*FLAGS.delta_t\n",
    "    \n",
    "    #new_velocity = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    \n",
    "    old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents , FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    new_pos_agents = tf.slice(old_states, [0, 0, 0], \n",
    "                       [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    new_pos_landmarks = tf.slice(old_states, [FLAGS.number_agents, 0, 0], \n",
    "                       [FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_pos = tf.concat([new_pos_agents, new_pos_landmarks], axis = 0)\n",
    "    \n",
    "    new_gazes_agents = old_gazes + new_delta_gazes*FLAGS.delta_t\n",
    "    new_gazes_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_gazes = tf.concat([new_gazes_agents, new_gazes_landmarks], axis = 0)\n",
    "    \n",
    "    new_velocity_agents = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    new_velocity_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_velocity = tf.concat([new_velocity_agents, new_velocity_landmarks], axis = 0)\n",
    "    \n",
    "    colors = tf.slice(old_states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                            FLAGS.color_size, FLAGS.batch_size])\n",
    "    new_states = tf.concat([new_pos, new_velocity, new_gazes, colors], axis = 1)\n",
    "\n",
    "    return new_states, new_pos, new_gazes\n",
    "\n",
    "\n",
    "\n",
    "def compute_new_memories(old_mem_com, old_mem_last, delta_mem_com, delta_mem_last):\n",
    "    new_memory_com = tf.tanh((2/3)*(old_mem_com + delta_mem_com + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    new_memory_last = tf.tanh((2/3)*(old_mem_last + delta_mem_last + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    \n",
    "    return new_memory_com,new_memory_last\n",
    "\n",
    "\n",
    "\n",
    "def shuffle(x, name_targets, colors = False):\n",
    "    slices_second_dim = []\n",
    "    ones = tf.ones([FLAGS.number_agents, 1, FLAGS.batch_size], tf.int32)\n",
    "    batch_num = tf.tile(tf.reshape(tf.range(0, FLAGS.batch_size, dtype = tf.int32), [1, 1, FLAGS.batch_size]), [FLAGS.number_agents,\n",
    "                                                                                                               1, 1])\n",
    "    if not colors:\n",
    "        for i in range(FLAGS.dim_env):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "    else:\n",
    "        for i in range(FLAGS.color_size):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "            \n",
    "    gathering_tensor = tf.transpose(tf.concat(slices_second_dim, axis = 1), perm = [0, 1, 3, 2])\n",
    "    shuffled_x = tf.gather_nd(x, gathering_tensor)\n",
    "    \n",
    "    return shuffled_x\n",
    "    \n",
    "    \n",
    "def compute_reward(positions, gazes, outputs, utterances, name_targets, goals_loc, goals_types):\n",
    "    shuffled_positions = shuffle(positions, name_targets)\n",
    "    shuffled_gazes = shuffle(gazes, name_targets)\n",
    "    \n",
    "    #shuffled_positions = tf.slice(positions, [0, 0, 0], [FLAGS.number_agents, 2, FLAGS.batch_size])\n",
    "    #shuffled_gazes = tf.slice(gazes, [0, 0, 0], [FLAGS.number_agents, 2, FLAGS.batch_size])\n",
    "    \n",
    "    pos_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_positions - goals_loc)), axis = 1), [FLAGS.number_agents, 1, \n",
    "                                                                                                     FLAGS.batch_size])\n",
    "\n",
    "    gaze_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_gazes - goals_loc)), axis = 1), [FLAGS.number_agents, 1,\n",
    "                                                                                                     FLAGS.batch_size])\n",
    "    zeros = tf.zeros([FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    x = tf.concat([pos_distances, gaze_distances, zeros], axis = 1)\n",
    "    \n",
    "    dists_goal = -tf.reduce_sum(tf.multiply(x, goals_types), axis = 1)\n",
    "    \n",
    "    utterances_term = -tf.reduce_sum(tf.square(utterances), axis = 1)\n",
    "    output_term = -tf.reduce_sum(tf.square(outputs), axis = 1)\n",
    "    \n",
    "    reward_by_batch = tf.reshape(tf.reduce_sum(dists_goal + utterances_term + output_term, axis = 0), [FLAGS.batch_size, 1])\n",
    "\n",
    "    return reward_by_batch\n",
    "\n",
    "\n",
    "\n",
    "def compute_goal_dist(states, goal_location, goal_type):\n",
    "    dist_positions = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 0:2, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    dist_gazes = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 4:6, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    v = np.concatenate([dist_positions, dist_gazes, np.zeros((FLAGS.number_agents, 1, FLAGS.batch_size))], axis = 1)\n",
    "    goal_distances = np.sum(np.multiply(v, goal_type), axis = 1)\n",
    "    \n",
    "    return goal_distances\n",
    "\n",
    "\n",
    "def print_stats_agent(states, goal_location, goal_type, targets):\n",
    "    #Only considering non \"do nothing goals\"\n",
    "    shuffled_states = python_shuffle(states, targets)\n",
    "    goal_distances = compute_goal_dist(shuffled_states, goal_location, goal_type)\n",
    "    \n",
    "    for i in range(FLAGS.number_agents):\n",
    "        distances_agents = goal_distances[i, :]\n",
    "        goal_wo_zeros = distances_agents[distances_agents != 0]\n",
    "        mean = np.mean(goal_wo_zeros)\n",
    "        median = np.median(goal_wo_zeros)\n",
    "        third_quart = np.percentile(goal_wo_zeros, 75)\n",
    "        nine_pct = np.percentile(goal_wo_zeros, 90)\n",
    "        max_dist = np.max(distances_agents)\n",
    "        argmax = np.argmax(distances_agents)\n",
    "        print(\"--- Agent \" + str(i))\n",
    "        print(\"------ Mean distance \" + str(mean))\n",
    "        print(\"------ Median distance \" + str(median))\n",
    "        print(\"------ Third quartile \" + str(third_quart))\n",
    "        print(\"------ Ninetieth percentile \" + str(nine_pct))\n",
    "        print(\"------ max distance \" + str(max_dist))\n",
    "        print(\"------ argmax distance \" + str(argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the physical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 3*FLAGS.dim_env + FLAGS.color_size\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, number of inputs]\n",
    "        #This shape enables us to handle all the agents/landmarks states at once, instead of dealing with list of agents' states\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.layer_sizes, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.output_size, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): \n",
    "        # Compute a forward pass through the network\n",
    "        # Input: a tensor of shape [number of agents, size of input, batch _size]\n",
    "        # Output: a tensor of shape [number of agents, output_size, batch_size]\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "                else:\n",
    "                    x = activation_function(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the communication network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CommunicationNet: \n",
    "    \n",
    "    def __init__(self):    \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"com_memory_read_weight\", shape = [1, FLAGS.output_size, FLAGS.mem_size],\n",
    "                                               initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, vocabulary size]\n",
    "        #This shape enables us to handle all the agents utterances at once, instead of dealing with list of agents' states        \n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.vocabulary_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.output_size, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])  \n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        # Initialization of the weights and biases writing in the memory.\n",
    "        # Their shape are of the form [number of agents, memory_size, output size] and [number of agents, output size, 1]\n",
    "        # So that we can handle the memories of all agents at onces instead of dealing with list of memories.\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_com\" , shape=[1, FLAGS.mem_size,FLAGS.output_size],\n",
    "                            initializer=tf.orthogonal_initializer()), \n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_com\", shape = [1, FLAGS.mem_size, 1],\n",
    "                            initializer=tf.orthogonal_initializer()),\n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LastNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 2*FLAGS.output_size + FLAGS.color_size + FLAGS.number_goal_types + FLAGS.dim_env\n",
    "        self.output_size = 2*FLAGS.dim_env + FLAGS.vocabulary_size\n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"reading_last_mem_weight\", shape = [1, self.output_size, FLAGS.last_mem_size],\n",
    "                                              initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size ],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, self.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, self.output_size, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_last\", shape=[1, FLAGS.last_mem_size ,self.output_size],\n",
    "                                initializer=tf.orthogonal_initializer()),\n",
    "                                 [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_last\" ,shape = [1, FLAGS.last_mem_size, 1], \n",
    "                                    initializer=tf.orthogonal_initializer()),\n",
    "                                  [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "               \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the policy: putting all the networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.phys_network = PhysicalNet()\n",
    "        self.comm_network = CommunicationNet()\n",
    "        self.last_network = LastNet()\n",
    "        \n",
    "        self.define_placeholders()\n",
    "        self.define_full_goals()\n",
    "        \n",
    "        \n",
    "    def define_placeholders(self):\n",
    "        self.states = tf.placeholder(tf.float32, [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                  3*FLAGS.dim_env + FLAGS.color_size, FLAGS.batch_size])\n",
    "        self.utterances = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "        self.memories_com = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size])\n",
    "        self.memories_last = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size])\n",
    "        self.goal_types = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.number_goal_types, FLAGS.batch_size])\n",
    "        self.goal_locations = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        self.name_targets = tf.placeholder(tf.int32, [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "        #self.colors = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        \n",
    "        \n",
    "    def define_full_goals(self):\n",
    "        colors = tf.slice(self.states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        shuffled_colors = shuffle(colors, self.name_targets, colors = True)\n",
    "        self.full_goals = tf.concat([self.goal_types, self.goal_locations, shuffled_colors], axis = 1)\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.states, self.utterances, self.memories_com, self.memories_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets]\n",
    "        \n",
    "    def forward_pass(self, states, utterances, mem, mem_last, goals_last):\n",
    "        #Step 1: processing observed states and utterances\n",
    "        phys_output = self.phys_network.compute_output(states)\n",
    "        comm_output, delta_mem_com = self.comm_network.compute_output(utterances, mem)\n",
    "        \n",
    "        #Step 2: softmax pooling the results [num_agents, output size, batch_size] --> [1, output size, batch_size]\n",
    "        PhiX = softmax_pooling(phys_output)\n",
    "        PhiC = softmax_pooling(comm_output)\n",
    "        \n",
    "        #Step 3: feeding the last network      \n",
    "        PhiX_last = tf.tile(tf.reshape(PhiX, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        PhiC_last = tf.tile(tf.reshape(PhiC, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        input_last = tf.concat([PhiX_last, goals_last, PhiC_last], axis = 1)\n",
    "        \n",
    "        output_last, delta_mem_last = self.last_network.compute_output(input_last, mem_last)\n",
    "        \n",
    "        velocities_output, gazes_output = sample_phys(output_last)\n",
    "        utterances_output = gumbel_max_trick(output_last)\n",
    "        phys_output = tf.concat([velocities_output, gazes_output], axis = 1)\n",
    "        \n",
    "        return phys_output, velocities_output, gazes_output, utterances_output, delta_mem_com, delta_mem_last\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.enc = OneHotEncoder(n_values=FLAGS.number_goal_types, sparse=False)\n",
    "        self.colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)] \n",
    "        self.cols, self.cols_agents, self.cols_landmarks = self.create_colors()\n",
    "    \n",
    "    \n",
    "    def create_colors(self):\n",
    "        cols_agents = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_agents)], axis = 0)\n",
    "        cols_landmarks = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_landmarks)], axis = 0)\n",
    "        \n",
    "        cols = np.concatenate([cols_agents, cols_landmarks], axis = 0)\n",
    "            \n",
    "        return cols, cols_agents, cols_landmarks\n",
    "            \n",
    "        \n",
    "    def create_consistent_targets(self):\n",
    "        targets_by_exp = [np.random.choice(FLAGS.number_agents, (FLAGS.number_agents, 1), replace = False) for _ in range(FLAGS.batch_size)]\n",
    "        #targets_by_exp = [np.array([[0], [1]]) for _ in range(FLAGS.batch_size)]\n",
    "        targets_batch = np.stack(targets_by_exp, axis = 2)\n",
    "        return targets_batch\n",
    "    \n",
    "    def create_goal_locations(self, pos_landmarks):\n",
    "        landmark_nb = [np.random.choice(FLAGS.number_landmarks, (FLAGS.number_agents, 1), replace = True) for _ in range(FLAGS.batch_size)]\n",
    "        landmark_nb_batch = np.stack(landmark_nb, axis = 2)\n",
    "        \n",
    "        goal_loc = python_shuffle(pos_landmarks, landmark_nb_batch)\n",
    "        \n",
    "        return goal_loc\n",
    "        \n",
    "        \n",
    "    def random_generation(self):\n",
    "        positions_agents = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        #positions_agents = np.array([[[-1 for i in range(100)], [-1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        \n",
    "        positions_landmarks = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        #positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]], [[4 for i in range(100)], [4 for i in range(100)]]])\n",
    "        positions = np.concatenate([positions_agents, positions_landmarks], axis = 0)\n",
    "        \n",
    "        gazes = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        #velocities = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "        #                                                          FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        velocities = np.zeros([FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        \n",
    "        #goal_locations = np.random.uniform(-FLAGS.bound, FLAGS.bound, [FLAGS.number_agents, \n",
    "        #                                                          FLAGS.dim_env, FLAGS.batch_size])\n",
    " \n",
    "        goal_locations = self.create_goal_locations(positions_landmarks)\n",
    "        \n",
    "        goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "                        np.random.choice(FLAGS.number_goal_types, FLAGS.batch_size).reshape(-1,1))), \n",
    "                                  [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "        #goal_types = np.array([[[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]]])\n",
    "        utterances = np.zeros((FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size))\n",
    "        memories_com = np.zeros((FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size))\n",
    "        memories_last = np.zeros((FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size))\n",
    "        \n",
    "        states = np.concatenate([positions, velocities, gazes, self.cols], axis = 1)\n",
    "        targets = self.create_consistent_targets()\n",
    "        \n",
    "        return states, utterances, memories_com, memories_last, goal_locations, goal_types, targets\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-90-87d88428bee2>, line 114)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-90-87d88428bee2>\"\u001b[0;36m, line \u001b[0;32m114\u001b[0m\n\u001b[0;31m    name_targets, self.array_outputs, t, return_sofar):\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.policy = Policy()\n",
    "        self.env = Environment()\n",
    "        delete_history_files()\n",
    "        \n",
    "        self.get_placeholders()\n",
    "        self.definition_arrays()\n",
    "        self.write_arrays()\n",
    "        self.learning_rate = self.learning_rate_decay()\n",
    "        tf.summary.scalar('learning rate', self.learning_rate)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        self.loop()\n",
    "        self.output_to_run = [self.step, self.array_states_stack, self.array_utterances_stack, self.array_mem_com_stack, self.array_mem_last_stack, \n",
    "                                self.f_g , self.array_outputs_stack, self.t_fin, self.reward]\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "        self.reward_history = []\n",
    "        self.env_history = []\n",
    "        self.arrays_history = []\n",
    "        \n",
    "        \n",
    "    def learning_rate_decay(self):\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        if FLAGS.learning_rate_decay:\n",
    "            starter_learning_rate = FLAGS.learning_rate\n",
    "            boundaries = [1000, 2000]\n",
    "            values = [FLAGS.learning_rate, FLAGS.learning_rate/10, FLAGS.learning_rate/100]\n",
    "            return tf.train.piecewise_constant(self.global_step, boundaries, values, name=None)\n",
    "        else:\n",
    "            return FLAGS.learning_rate\n",
    "        \n",
    "    def definition_arrays(self):\n",
    "        # Create goals vectors \n",
    "        self.array_states = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_utterances = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_com = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_last = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_outputs = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        \n",
    "    def get_placeholders(self):\n",
    "        [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets] = self.policy.get_placeholders()\n",
    "            \n",
    "            \n",
    "    def write_arrays(self):\n",
    "        self.array_states = self.array_states.write(0, self.states)\n",
    "        self.array_utterances = self.array_utterances.write(0, self.utterances)\n",
    "        self.array_mem_com = self.array_mem_com.write(0, self.mem_com)\n",
    "        self.array_mem_last = self.array_mem_last.write(0, self.mem_last)\n",
    "        self.array_outputs = self.array_outputs.write(0, np.zeros((FLAGS.number_agents, 4, FLAGS.batch_size)))\n",
    "        \n",
    "    def loop(self):\n",
    "        t = tf.constant(0)\n",
    "        return_sofar = tf.zeros([FLAGS.batch_size, 1], tf.float32)\n",
    "        args = [self.array_states, self.array_utterances, self.array_mem_com, self.array_mem_last, self.goal_types, \n",
    "                self.goal_locations, self.full_goals, self.name_targets, self.array_outputs, t, return_sofar]\n",
    "        \n",
    "        (array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t_fin, rewards_batch) = tf.while_loop(self.condition, self.body, args, parallel_iterations=1)\n",
    "            \n",
    "        reward = tf.reshape(tf.reduce_mean(rewards_batch, axis = 0), [])\n",
    "        tf.summary.scalar('accuracy', -reward)\n",
    "        grads = self.optimizer.compute_gradients(-reward)\n",
    "        self.step = self.optimizer.apply_gradients(grads, global_step=self.global_step)\n",
    "        for index, grad in enumerate(grads):\n",
    "            tf.summary.histogram(\"{}-grad\".format(grads[index][1].name), grads[index])\n",
    "            \n",
    "        self.array_states_stack = array_states.stack()\n",
    "        self.array_utterances_stack = array_utterances.stack() \n",
    "        self.array_mem_com_stack = array_mem_com.stack() \n",
    "        self.array_mem_last_stack = array_mem_last.stack() \n",
    "        self.array_outputs_stack = array_outputs.stack()\n",
    "        self.f_g = full_goals\n",
    "        self.t_fin = t_fin, \n",
    "        self.reward = reward\n",
    "    \n",
    "        \n",
    "    def body(self, array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar):\n",
    "        \n",
    "        #Reading the last state of environment\n",
    "        states = array_states.read(t)\n",
    "        utterances = array_utterances.read(t)\n",
    "        mem_com = array_mem_com.read(t)\n",
    "        mem_last = array_mem_last.read(t)\n",
    "        \n",
    "        phys_output, new_velocities, new_delta_gazes, new_utterances, delta_mem_com, delta_mem_last = self.policy.forward_pass(states,\n",
    "                                                                    utterances, mem_com, mem_last, full_goals)\n",
    "\n",
    "        new_states, new_positions, new_gazes = compute_new_states(states, new_velocities, new_delta_gazes, new_utterances)\n",
    "\n",
    "        new_mem_com, new_mem_last = compute_new_memories(mem_com, mem_last, delta_mem_com, delta_mem_last)\n",
    "        \n",
    "        return_sofar += compute_reward(new_positions, new_gazes, phys_output, new_utterances, name_targets, goal_locations, \n",
    "                                        goal_types)\n",
    "\n",
    "        #Writing the new state\n",
    "        array_states = array_states.write((t+1), new_states)\n",
    "        array_utterances = array_utterances.write((t+1), new_utterances)\n",
    "        array_mem_com = array_mem_com.write((t+1), new_mem_com)\n",
    "        array_mem_last = array_mem_last.write((t+1), new_mem_last)\n",
    "        array_outputs = array_outputs.write((t+1), phys_output)\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "        return [array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar]\n",
    "        \n",
    "        \n",
    "    def condition(self, array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, self.array_outputs, t, return_sofar):\n",
    "        return tf.less(t, FLAGS.time_horizon)\n",
    "    \n",
    "    \n",
    "    def create_feed_dict(self, states, utterances, memories_com, memories_last, goal_locations, goal_types, targets):\n",
    "        list_values = [states, utterances, memories_com, memories_last, goal_types, goal_locations, targets]\n",
    "        list_placeholders = [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, \n",
    "                             self.goal_locations, self.name_targets]\n",
    "        feed_dict = {a:b for a,b in zip(list_placeholders, list_values)}\n",
    "        return feed_dict\n",
    "    \n",
    "    def train(self, sess):\n",
    "        self.train_writer = tf.summary.FileWriter('Summary', sess.graph)\n",
    "        print(\"Initializing variables\")\n",
    "        sess.run(self.init)\n",
    "        sess.graph.finalize()\n",
    "        print(\"Start training\")\n",
    "        start = datetime.now()\n",
    "        self.arrays_history = [0, 0, 0, 0, 0]\n",
    "        self.full_g = []\n",
    "        #states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = self.env.random_generation()\n",
    "        for i in range(FLAGS.max_steps):\n",
    "            states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = self.env.random_generation()\n",
    "            generation_time = datetime.now() - start\n",
    "            feed_dict = self.create_feed_dict(states, utterances, memories_com, memories_last, goal_locations, goal_types, targets)\n",
    "            if i % FLAGS.tensorboard_freq == 0:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, t, reward, summary = sess.run(self.output_to_run + [self.merged], feed_dict)\n",
    "                self.train_writer.add_summary(summary, i)\n",
    "            else:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, t, reward = sess.run(self.output_to_run, feed_dict)\n",
    "            \n",
    "            self.reward_history.append(reward)\n",
    "            self.full_g.append(self.arrays_history[-1])\n",
    "            self.arrays_history = [array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs]\n",
    "            \n",
    "            with open('env_history.pkl', 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([states, utterances, memories_com, memories_last, goal_locations, goal_types, targets])\n",
    "                \n",
    "            with open(\"arrays_history.pkl\", 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([array_states, array_utterances, array_mem_com, array_mem_last, array_outputs])\n",
    "                \n",
    "            if i % FLAGS.print_frequency == 0:\n",
    "                print(\"\\n\")\n",
    "                print(\"iteration \" + str(i))\n",
    "                print(reward)\n",
    "                final_states = array_states[0][-1, :, :, :]\n",
    "                print_stats_agent(final_states, goal_locations, goal_types, targets)\n",
    "                print(\"computing time\")\n",
    "                print(datetime.now() - start)\n",
    "                print(\"generation time\")\n",
    "                print(generation_time)\n",
    "                print(\"memory usage\")\n",
    "                memory()\n",
    "\n",
    "                start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent 0\n",
      "------ Mean distance 0.867064467737\n",
      "------ Median distance 0.376699668914\n",
      "------ Third quartile 1.28781578471\n",
      "------ Ninetieth percentile 2.06480002055\n",
      "------ max distance 5.82216777566\n",
      "------ argmax distance 50\n"
     ]
    }
   ],
   "source": [
    "print_stats_agent(array_states[0][-1, :, :, :], goal_locations, goal_types, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def memory():\n",
    "    import os\n",
    "    import psutil\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "    print('memory use:', memoryUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_0:0-grad is illegal; using phys_variable/weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_1:0-grad is illegal; using phys_variable/weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_2:0-grad is illegal; using phys_variable/weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_0:0-grad is illegal; using phys_variable/bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_1:0-grad is illegal; using phys_variable/bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_2:0-grad is illegal; using phys_variable/bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_memory_read_weight:0-grad is illegal; using com_memory_read_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_0:0-grad is illegal; using com_variable/com_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_1:0-grad is illegal; using com_variable/com_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_2:0-grad is illegal; using com_variable/com_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_0:0-grad is illegal; using com_variable/com_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_1:0-grad is illegal; using com_variable/com_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_2:0-grad is illegal; using com_variable/com_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_com:0-grad is illegal; using weight_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_com:0-grad is illegal; using bias_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name reading_last_mem_weight:0-grad is illegal; using reading_last_mem_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_0:0-grad is illegal; using last_variable/last_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_1:0-grad is illegal; using last_variable/last_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_2:0-grad is illegal; using last_variable/last_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_0:0-grad is illegal; using last_variable/last_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_1:0-grad is illegal; using last_variable/last_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_2:0-grad is illegal; using last_variable/last_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_last:0-grad is illegal; using weight_mem_last_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_last:0-grad is illegal; using bias_mem_last_0-grad instead.\n",
      "Initializing variables\n",
      "Start training\n",
      "\n",
      "\n",
      "iteration 0\n",
      "-2864.83\n",
      "--- Agent 0\n",
      "------ Mean distance 6.03139059367\n",
      "------ Median distance 5.86841227054\n",
      "------ Third quartile 8.18477046736\n",
      "------ Ninetieth percentile 10.1019085448\n",
      "------ max distance 11.51262935\n",
      "------ argmax distance 16\n",
      "computing time\n",
      "0:00:01.708146\n",
      "generation time\n",
      "0:00:00.007314\n",
      "memory usage\n",
      "memory use: 0.9061470031738281\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-be27836522b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-856b840946cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0marray_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_utterances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_com\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabrielducrocq_maths/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabrielducrocq_maths/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabrielducrocq_maths/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabrielducrocq_maths/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabrielducrocq_maths/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp = Experiment()\n",
    "with tf.Session() as sess:\n",
    "    exp.train(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iteration 4000\n",
    "-272.204\n",
    "--- Agent 0\n",
    "------ Mean distance 0.498034281441\n",
    "------ Median distance 0.46455717478\n",
    "------ Third quartile 0.692155415243\n",
    "------ Ninetieth percentile 0.91114070268\n",
    "------ max distance 1.26939498787\n",
    "------ argmax distance 63\n",
    "--- Agent 1\n",
    "------ Mean distance 0.439739801915\n",
    "------ Median distance 0.39883461282\n",
    "------ Third quartile 0.641415463254\n",
    "------ Ninetieth percentile 0.760335241822\n",
    "------ max distance 1.20678139295\n",
    "------ argmax distance 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "iteration 19500\n",
    "-726.305\n",
    "--- Agent 0\n",
    "------ Mean distance 0.440592825452\n",
    "------ Median distance 0.453401856347\n",
    "------ Third quartile 0.609330856092\n",
    "------ Ninetieth percentile 0.754517853157\n",
    "------ max distance 1.03534185773\n",
    "------ argmax distance 25\n",
    "--- Agent 1\n",
    "------ Mean distance 0.46381734155\n",
    "------ Median distance 0.409665639312\n",
    "------ Third quartile 0.538080032366\n",
    "------ Ninetieth percentile 0.791099401087\n",
    "------ max distance 2.27306580287\n",
    "------ argmax distance 62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agent 0\n",
    "------ Mean distance 0.380871340075\n",
    "------ Median distance 0.390718111261\n",
    "------ Third quartile 0.493501544375\n",
    "------ Ninetieth percentile 0.570767339994\n",
    "------ max distance 0.818012924181\n",
    "------ argmax distance 63\n",
    "- Agent 1\n",
    "------ Mean distance 0.388320904741\n",
    "------ Median distance 0.317189196094\n",
    "------ Third quartile 0.607768454472\n",
    "------ Ninetieth percentile 0.752598386052\n",
    "------ max distance 1.07770408928\n",
    "------ argmax distance 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"env_history.pkl\", \"rb\") as openfile:\n",
    "    states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = cPickle.load(openfile)\n",
    "\n",
    "    \n",
    "array_states, array_utterances, array_mem_com, array_mem_last, full_goals = exp.arrays_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.        ,  0.        , -4.38704252, -2.96934271,\n",
       "        1.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[0, :, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 9), dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0][-1, 2:4, :, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dist_to_goal = compute_goal_dist(python_shuffle(array_states[0][-1, :, :, :],targets),  goal_locations, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent 0\n",
      "------ Mean distance 0.867064467737\n",
      "------ Median distance 0.376699668914\n",
      "------ Third quartile 1.28781578471\n",
      "------ Ninetieth percentile 2.06480002055\n",
      "------ max distance 5.82216777566\n",
      "------ argmax distance 50\n"
     ]
    }
   ],
   "source": [
    "print_stats_agent(array_states[0][-1, :, :, :], goal_locations, goal_types, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9333c045124d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoal_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "np.where((goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1d7d6842848c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#shuffle = dist_to_goal[:, targets[1, 0, :] == 0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msame_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_to_goal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgoal_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdiff_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist_to_goal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgoal_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "move = dist_to_goal[:, goal_types[0, 0, :] == 1]\n",
    "gaze = dist_to_goal[:, goal_types[0, 1, :] == 1]\n",
    "nothing = dist_to_goal[:, goal_types[0, 2, :] == 1]\n",
    "\n",
    "#no_shuffle = dist_to_goal[:, targets[0, 0, :] == 0]\n",
    "#shuffle = dist_to_goal[:, targets[1, 0, :] == 0]\n",
    "\n",
    "same_loc = dist_to_goal[:, (goal_locations[0, :, :] == goal_locations[1, :, :])[0, :]]\n",
    "diff_loc = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :]]\n",
    "\n",
    "diff_n_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]\n",
    "rest = dist_to_goal[:, ~(goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- rest:\n",
      "---- median:0.0522072964903\n",
      "---- mean:0.0688841431843\n",
      "---- max:0.299766462265\n",
      "---- third quartile:0.108318737919\n",
      "---- ninetieth percentile:0.167590340246\n",
      "\n",
      "\n",
      "- diff and shuffle:\n",
      "---- median:0.110170765322\n",
      "---- mean:0.121479755056\n",
      "---- max:0.434131854045\n",
      "---- third quartile:0.161362873382\n",
      "---- ninetieth percentile:0.268960404957\n"
     ]
    }
   ],
   "source": [
    "print(\"- rest:\")\n",
    "print(\"---- median:\" + str(np.median(rest)))\n",
    "print(\"---- mean:\" + str(np.mean(rest)))\n",
    "print(\"---- max:\" + str(np.max(rest)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(rest, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(rest, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_n_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_n_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_n_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_n_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_n_shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False, False, False, False, False,\n",
       "        True, False, False,  True, False,  True, False, False, False,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True, False, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False,  True,  True, False, False,\n",
       "        True, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "       False, False, False, False,  True, False,  True, False,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- no_shuffle:\n",
      "---- median:0.0565573323221\n",
      "---- mean:0.0871001578737\n",
      "---- max:0.420056936261\n",
      "---- third quartile:0.117766474013\n",
      "---- ninetieth percentile:0.254661087049\n",
      "\n",
      "\n",
      "- shuffle:\n",
      "---- median:0.0880245352644\n",
      "---- mean:0.0972857735953\n",
      "---- max:0.434131854045\n",
      "---- third quartile:0.139491016647\n",
      "---- ninetieth percentile:0.218207560007\n"
     ]
    }
   ],
   "source": [
    "print(\"- no_shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(no_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(no_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(no_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(no_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(no_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(shuffle)))\n",
    "print(\"---- max:\" + str(np.max(shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- move:\n",
      "---- median:1.28781578471\n",
      "---- mean:1.62510484628\n",
      "---- max:5.82216777566\n",
      "---- third quartile:1.83488682323\n",
      "---- ninetieth percentile:3.19903215803\n",
      "\n",
      "\n",
      "- gaze:\n",
      "---- median:0.068824774865\n",
      "---- mean:0.0873657926588\n",
      "---- max:0.25814431634\n",
      "---- third quartile:0.127700067753\n",
      "---- ninetieth percentile:0.153858530504\n"
     ]
    }
   ],
   "source": [
    "print(\"- move:\")\n",
    "print(\"---- median:\" + str(np.median(move)))\n",
    "print(\"---- mean:\" + str(np.mean(move)))\n",
    "print(\"---- max:\" + str(np.max(move)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(move, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(move, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- gaze:\")\n",
    "print(\"---- median:\" + str(np.median(gaze)))\n",
    "print(\"---- mean:\" + str(np.mean(gaze)))\n",
    "print(\"---- max:\" + str(np.max(gaze)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(gaze, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(gaze, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- same loc:\n",
      "---- median:0.0574692180866\n",
      "---- mean:0.074350570539\n",
      "---- max:0.299766462265\n",
      "---- third quartile:0.118950136743\n",
      "---- ninetieth percentile:0.187021824825\n",
      "\n",
      "\n",
      "- diff loc:\n",
      "---- median:0.0812581136655\n",
      "---- mean:0.108662868992\n",
      "---- max:0.434131854045\n",
      "---- third quartile:0.148231233871\n",
      "---- ninetieth percentile:0.281130610367\n"
     ]
    }
   ],
   "source": [
    "print(\"- same loc:\")\n",
    "print(\"---- median:\" + str(np.median(same_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(same_loc)))\n",
    "print(\"---- max:\" + str(np.max(same_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(same_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(same_loc, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff loc:\")\n",
    "print(\"---- median:\" + str(np.median(diff_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_loc)))\n",
    "print(\"---- max:\" + str(np.max(diff_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_loc, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.22691896])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[0, :, 47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23993602688828053"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(dist_to_goal, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.75605869, -3.65026283],\n",
       "       [-0.84835589, -1.78519177],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0][-1, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14831297, -4.97242832],\n",
       "       [ 1.16328669, -1.77039778],\n",
       "       [-2.98628569,  0.18662429],\n",
       "       [-4.54645157,  4.09530401]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0][0, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:,:, 87].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0][:, 0, 0:2, 82].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_stats_agent() missing 1 required positional argument: 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6df541d46d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: print_stats_agent() missing 1 required positional argument: 'targets'"
     ]
    }
   ],
   "source": [
    "print_stats_agent(array_states[0][-1, :, :, :], goal_locations, goal_types)\n",
    "print_stats_agent(array_states[0][0, :, :, :], goal_locations, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43413185404476412"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  [[0]]\n",
      "first [ 1.  0.  0.]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9eb7fc8c325f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"target \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"second\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "nb = 46\n",
    "print(\"target \", targets[:, :, nb])\n",
    "print(\"first\", goal_types[0, :, nb])\n",
    "print(\"second\", goal_types[1, :, nb])\n",
    "plot_trajectory(array_states[0][:, 1, 0:2,nb], goal_locations[0, :, nb])\n",
    "print(\"first:\", goal_locations[0, :, nb])\n",
    "print(\"second:\", goal_locations[1, :, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndyIXWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82a1d6f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]]\n",
      "[ 0.97108358  4.93932674]\n"
     ]
    }
   ],
   "source": [
    "nb = 39\n",
    "plot_trajectory(array_states[0][:, 0, 0:2,nb], goal_locations[0, :, nb])\n",
    "print(goal_types[:,:, nb])\n",
    "print(goal_locations[0, :, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 2, 9, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.94084525,  5.52172947], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0][-1, 1, 0:2,nb] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.67927814, -2.5525627 ],\n",
       "       [-1.34914591, -3.25983646]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228.63954674676216"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((array_states[0][-1, 1, 0:2,37] - goal_locations[1, :, 37])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = tf.Variable(array_states[0][-1, :, :,:])\n",
    "targs = tf.Variable(targets, dtype = tf.int32)\n",
    "s_pos = shuffle(pos, targs)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sp = sess.run(s_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.1622076 ,  33.22509003],\n",
       "       [ -4.39629889,   1.50046945]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp[:, :, 46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -4.39629889,   1.50046945],\n",
       "       [  3.1622076 ,  33.22509003]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0][-1, 0:2, 0:2,46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.21458349,  0.99837589,  0.99996912,  0.99989748,\n",
       "        0.99835831,  0.99935341,  0.99817449,  0.99272031,  0.99590147,\n",
       "        0.99916804,  0.99063897,  0.9970454 ,  0.99723125,  0.9697637 ,\n",
       "        0.9998709 ,  0.9997167 ,  0.99710006,  0.99759543,  0.99936271,\n",
       "        0.99360609,  0.99580538,  0.99995017,  0.99980658,  0.99950868,\n",
       "        0.99999171,  0.99953073,  0.99909329,  0.99997604,  0.9996466 ,\n",
       "        0.99985826,  0.99903381,  0.99947876,  0.99969512,  0.99958038,\n",
       "        0.99915469,  0.99893618,  0.99953365,  0.99773985,  0.99991387,\n",
       "        0.99136442,  0.99991816,  0.99588758,  0.99628168,  0.99985117,\n",
       "        0.99481028,  0.99983966,  0.99872673,  0.99911529,  0.99990505,\n",
       "        0.99391896], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_mem_last[0][:, 0, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999587769273"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tanh(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2721e9fc7115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'exp' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = exp.env.create_colors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols[2, :, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions_landmarks = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_landmarks, \n",
    "                                                        FLAGS.dim_env, FLAGS.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 100)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_landmarks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions_landmarks = np.array([[[0 for i in range(100)], [0 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_landmarks[1, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[0][6, 0, :, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[0][34, 1, :, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent1 = []\n",
    "agent2 = []\n",
    "for i in range(100):\n",
    "    for j in range(51):\n",
    "        agent1.append(np.argmax(array_utterances[0][j, 0, :, i]))\n",
    "        agent2.append(np.argmax(array_utterances[0][j, 1, :, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 345.,  197.,  148.,  260.,  840.,  416.,  718.,  745.,  798.,  633.]),\n",
       " array([  0. ,   1.9,   3.8,   5.7,   7.6,   9.5,  11.4,  13.3,  15.2,\n",
       "         17.1,  19. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5e807c2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(agent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 166.,  179.,  722.,  225.,  550.,  629.,  770.,  690.,  510.,  659.]),\n",
       " array([  0. ,   1.9,   3.8,   5.7,   7.6,   9.5,  11.4,  13.3,  15.2,\n",
       "         17.1,  19. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6TGGfSS1Lj/B3JRuQE9u8VrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5e8075550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(agent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.46327496, -0.0907781 ],\n",
       "       [ 2.55825901,  0.48680466],\n",
       "       [ 2.46211743,  0.82728028],\n",
       "       [ 2.36734462,  1.13113403],\n",
       "       [ 2.27541089,  1.41585934],\n",
       "       [ 2.18245244,  1.66908538],\n",
       "       [ 2.09242463,  1.86419761],\n",
       "       [ 2.00430608,  2.02224684],\n",
       "       [ 1.90823185,  2.15841794],\n",
       "       [ 1.81365526,  2.35307145],\n",
       "       [ 1.72436297,  2.48915744],\n",
       "       [ 1.63475418,  2.59689689],\n",
       "       [ 1.55905938,  2.71981263],\n",
       "       [ 1.47504807,  2.8521862 ],\n",
       "       [ 1.38762915,  2.91553283],\n",
       "       [ 1.30308855,  3.00459909],\n",
       "       [ 1.22659457,  3.09313989],\n",
       "       [ 1.15261102,  3.12872458],\n",
       "       [ 1.08149695,  3.14987063],\n",
       "       [ 1.02363396,  3.18703127],\n",
       "       [ 0.96473867,  3.24975133],\n",
       "       [ 0.90465003,  3.26653242],\n",
       "       [ 0.85253155,  3.31852102],\n",
       "       [ 0.80041778,  3.32909608],\n",
       "       [ 0.7506234 ,  3.38352561],\n",
       "       [ 0.72113955,  3.39209104],\n",
       "       [ 0.67278886,  3.43317199],\n",
       "       [ 0.62693191,  3.46602035],\n",
       "       [ 0.58365136,  3.48225117],\n",
       "       [ 0.56496835,  3.51002598],\n",
       "       [ 0.5257898 ,  3.49067879],\n",
       "       [ 0.48158643,  3.50794673],\n",
       "       [ 0.45084861,  3.53858447],\n",
       "       [ 0.43333134,  3.55195141],\n",
       "       [ 0.40279979,  3.57581806],\n",
       "       [ 0.38139266,  3.56633997],\n",
       "       [ 0.34605753,  3.57442713],\n",
       "       [ 0.33010948,  3.5654614 ],\n",
       "       [ 0.29912576,  3.55881524],\n",
       "       [ 0.28731966,  3.59411359],\n",
       "       [ 0.28884453,  3.60612249],\n",
       "       [ 0.26701617,  3.6096766 ],\n",
       "       [ 0.25638407,  3.59111023],\n",
       "       [ 0.24826308,  3.59414721],\n",
       "       [ 0.23445472,  3.58936334],\n",
       "       [ 0.22966646,  3.59039354],\n",
       "       [ 0.2384153 ,  3.59979153],\n",
       "       [ 0.20810881,  3.63838029],\n",
       "       [ 0.21411105,  3.6401124 ],\n",
       "       [ 0.22830437,  3.66500092],\n",
       "       [ 0.21668175,  3.65443563],\n",
       "       [ 0.20240833,  3.6497457 ],\n",
       "       [ 0.1953028 ,  3.64792514],\n",
       "       [ 0.17589779,  3.6532793 ],\n",
       "       [ 0.18610893,  3.64781117],\n",
       "       [ 0.20012508,  3.63420081],\n",
       "       [ 0.20948181,  3.66055655],\n",
       "       [ 0.20598865,  3.64752817],\n",
       "       [ 0.21356754,  3.63712597],\n",
       "       [ 0.22933683,  3.63395524],\n",
       "       [ 0.24471974,  3.63293982],\n",
       "       [ 0.22699913,  3.64704394],\n",
       "       [ 0.2311528 ,  3.64549065],\n",
       "       [ 0.23384351,  3.68231249],\n",
       "       [ 0.20719771,  3.67047715],\n",
       "       [ 0.20707427,  3.66363549],\n",
       "       [ 0.20203416,  3.6775856 ],\n",
       "       [ 0.17740025,  3.67877579],\n",
       "       [ 0.14372052,  3.67094922],\n",
       "       [ 0.13782795,  3.66262603],\n",
       "       [ 0.14397541,  3.66947889],\n",
       "       [ 0.15476283,  3.66921496],\n",
       "       [ 0.16085516,  3.68736076],\n",
       "       [ 0.16668266,  3.6700089 ],\n",
       "       [ 0.15381913,  3.66373348],\n",
       "       [ 0.16647506,  3.66945696],\n",
       "       [ 0.17129564,  3.65809679],\n",
       "       [ 0.18013923,  3.6385653 ],\n",
       "       [ 0.15865326,  3.64830804],\n",
       "       [ 0.18344875,  3.63172674],\n",
       "       [ 0.1653672 ,  3.64181352],\n",
       "       [ 0.15818925,  3.62995911],\n",
       "       [ 0.17073014,  3.64757037],\n",
       "       [ 0.1771514 ,  3.64171171],\n",
       "       [ 0.17864498,  3.65386081],\n",
       "       [ 0.18767767,  3.65011525],\n",
       "       [ 0.19510533,  3.65766668],\n",
       "       [ 0.196438  ,  3.6751368 ],\n",
       "       [ 0.19188359,  3.68010712],\n",
       "       [ 0.18316586,  3.68119574],\n",
       "       [ 0.18079406,  3.67033505],\n",
       "       [ 0.16581693,  3.66909003],\n",
       "       [ 0.16710581,  3.67516494],\n",
       "       [ 0.18240449,  3.69411397],\n",
       "       [ 0.18160807,  3.70279646],\n",
       "       [ 0.17259762,  3.69934893],\n",
       "       [ 0.18178234,  3.72818828],\n",
       "       [ 0.17137276,  3.73106933],\n",
       "       [ 0.18751028,  3.7334466 ],\n",
       "       [ 0.19407791,  3.73740697],\n",
       "       [ 0.21206905,  3.75370693]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = 10\n",
    "array_states[0][:, 0, 4:6, nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.943128"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(np.sum(np.square(array_states[0][:, 0, 4:6, :]), axis = 1)))\n",
    "print(np.median(np.sum(np.square(array_states[0][:, 0, 4:6, :]), axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0405909\n",
      "0.00101032\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.sum(np.square(array_states[0][:, 0, 2:4, :]), axis = 1)))\n",
    "print(np.median(np.sum(np.square(array_states[0][:, 0, 2:4, :]), axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101,)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean((np.sum(np.square(array_states[0][:, 0, 2:4, :]), axis = 1)), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8268c63400>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8268ae9828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.mean((np.sum(np.square(array_states[0][:, 0, 2:4, :]), axis = 1)), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
