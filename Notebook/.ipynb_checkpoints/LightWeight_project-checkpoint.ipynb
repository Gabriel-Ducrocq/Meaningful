{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from datetime import datetime\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "#%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "#0.0008\n",
    "flags.DEFINE_float('learning_rate', 0.0008, 'Initial learning rate.')#0.0008\n",
    "flags.DEFINE_integer('max_steps', 20000, 'Number of iteration to train.')\n",
    "flags.DEFINE_integer('number_layers', 3, 'Number of layers in each network')\n",
    "flags.DEFINE_integer('layer_sizes', 256, 'Number of units in hidden layer.')\n",
    "flags.DEFINE_integer('batch_size', 100, 'Batch size.')#100\n",
    "flags.DEFINE_integer('dim_env', 2, 'dimension of the environment')\n",
    "flags.DEFINE_integer('number_goal_types', 3, 'number of different goal types')\n",
    "flags.DEFINE_integer('color_size', 3, 'number of components of the color: RGB as usual')\n",
    "flags.DEFINE_integer(\"output_size\", 256, \"number of units in the output layer\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.9, \"Dropouts rate of keeping\")\n",
    "flags.DEFINE_boolean(\"xav_init\", False,\"Distribution of initialization: False for normal, True for uniform\" )\n",
    "flags.DEFINE_integer(\"number_agents\", 2, \"Number of agents in the environment\")\n",
    "flags.DEFINE_integer(\"number_landmarks\", 3, \"Number of landmarks in the environment\")\n",
    "flags.DEFINE_integer(\"vocabulary_size\", 20, \"Size of the vocabulary\")\n",
    "flags.DEFINE_integer(\"mem_size\", 32, \"Size of the communication network's memory\")\n",
    "flags.DEFINE_integer(\"last_mem_size\", 32, \"Size of the last network's memory\")\n",
    "flags.DEFINE_float(\"gumbel_temperature\", 1, \"Temperature use for the gumbel softmax trick\")\n",
    "flags.DEFINE_float(\"sddev_phys_sampling\", 0.0001, \"Standard deviation used to sample the velocity and gaze output\")\n",
    "flags.DEFINE_float(\"delta_t\", 0.3, \"delta of time between timesteps\")#0.5\n",
    "flags.DEFINE_float(\"damping_coef\", 0.5, \"damping coefficient for the new velocity computation\")\n",
    "flags.DEFINE_float(\"stddev_memory\", 0.0001, \"standard deviation of the gaussian used to update memories\")\n",
    "flags.DEFINE_integer(\"bound\", 5, \"Bounds of generation of initial positions, centered in 0.\")#5 usually\n",
    "flags.DEFINE_integer(\"time_horizon\", 50, \"Number of timestep before the end of the experiment.\")#50\n",
    "flags.DEFINE_integer(\"print_frequency\", 50, \"Frequency at which we print the reward, in number of steps.\")#500\n",
    "flags.DEFINE_boolean(\"learning_rate_decay\", True, \"Wether to use a piecewise learning rate decay or no decay at all\")#True\n",
    "flags.DEFINE_integer(\"tensorboard_freq\", 2000, \"Frequency at which we save the statistics in tensorflow\")#500\n",
    "flags.DEFINE_float(\"alpha_dirichlet\", 0, \"Probability of seeing an out of vocabulary word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire:\n",
    "\n",
    "- Checker que le softmax pooling est correct\n",
    "\n",
    "- Checker que le gumbel trick est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le sampling physique est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le calcul du nouvel état est correct, notamment sur les débuts et longueur de slicing et concaténation\n",
    "\n",
    "- Ajouter le calcul des forces dans le calcul du nouvel état\n",
    "\n",
    "- Vérifier que le shuffling est correct\n",
    "\n",
    "- Vérifier que le calcul du reward est correct\n",
    "\n",
    "- Vérifier que la backprop considère bien les variables broadcastées comme les mêmes.\n",
    "\n",
    "- Vérifier que le tenseur states est bien dans cet ordre sur le second axe: position, velocité, gaze, couleurs\n",
    "\n",
    "- RELIER LES LANDMARKS AUX POSITIONS DES GOALS, SINON CA N A PAS DE SENS !!!\n",
    "\n",
    "- Checker que les goals types sont bien distribués: une unique coordonnée doit être 1, les autres 0, et ce pour chaque agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory():\n",
    "    import os\n",
    "    import psutil\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "    print('memory use:', memoryUse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_trajectory(coordinates, target_point, middle_point):\n",
    "    x = coordinates[1:-1, 0]\n",
    "    y = coordinates[1:-1, 1]\n",
    "    \n",
    "    x_start = coordinates[0, 0]\n",
    "    y_start = coordinates[0, 1]\n",
    "    \n",
    "    x_final = coordinates[-1, 0]\n",
    "    y_final = coordinates[-1, 1]\n",
    "    \n",
    "    x_target, y_target = target_point\n",
    "    x_middle, y_middle = middle_point\n",
    "    \n",
    "    plt.plot(x,y, \"o\")\n",
    "    plt.plot(x_start, y_start, 'ro')\n",
    "    plt.plot(x_target, y_target, 'go')\n",
    "    plt.plot(x_final, y_final, 'yo')\n",
    "    plt.plot(x_middle, y_middle, 'mo')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5, 5])\n",
    "    axes.set_ylim([-5, 5])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def python_shuffle(positions, shuffle_indexes):\n",
    "    shuffled_array = np.stack(\n",
    "    [positions[shuffle_indexes[: , 0, i], :, i] for i in range(FLAGS.batch_size)], axis = 2)\n",
    "    return shuffled_array\n",
    "    \n",
    "    \n",
    "def delete_history_files():\n",
    "    if os.path.isfile(\"env_history.pkl\"):\n",
    "        os.remove(\"env_history.pkl\")\n",
    "        \n",
    "    if os.path.isfile(\"arrays_history.pkl\"):\n",
    "        os.remove(\"arrays_history.pkl\")\n",
    "        \n",
    "    if Path(\"Summary\").is_dir():\n",
    "        shutil.rmtree(\"Summary\")\n",
    "\n",
    "\n",
    "def print_stat_vocabulary(utterances_array, l):\n",
    "    x = np.argmax(utterances_array, axis = 2)\n",
    "    r = []\n",
    "    for i in range(FLAGS.batch_size):\n",
    "        #r.append(len(np.unique(x[:, :, i])))\n",
    "        r.append(len(np.unique(x[:, 0, i])))\n",
    "        r.append(len(np.unique(x[:, 1, i])))\n",
    "    \n",
    "    if l%FLAGS.print_frequency == 0:\n",
    "        print(\"-- Stats word count:\")\n",
    "        print(\"---- Mean number of word activated: \" + str(np.mean(r)))\n",
    "        print(\"---- Median number of word activated: \" + str(np.median(r)))\n",
    "        print(\"---- Total number of word activated: \" + str(len(np.unique(x))))\n",
    "        \n",
    "    return np.mean(r)\n",
    "    \n",
    "        \n",
    "def dirichlet_log_lik_end(utterances_array):\n",
    "    #Note: we don't take minus the log-likelihood as we minimize minus the entire reward then !\n",
    "    by_symbol = tf.reduce_sum(utterances_array, axis =[0, 1, 3])\n",
    "    total_nb_uttered = FLAGS.number_agents*FLAGS.time_horizon*FLAGS.batch_size\n",
    "    #total_nb_uttered = tf.reduce_sum(utterances_array)\n",
    "    ratio = by_symbol/(FLAGS.alpha_dirichlet + total_nb_uttered - 1)\n",
    "    tiled_ratios = tf.tile(tf.reshape(ratio, [1, 1, FLAGS.vocabulary_size, 1]), [FLAGS.time_horizon, FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    #log_likelihood = tf.reduce_sum(tf.gather_nd(tf.log(tiled_ratios), tf.where(tf.equal(utterances_array, 1))))\n",
    "    terms = tf.multiply(tf.stop_gradient(tf.log(tf.clip_by_value(ratio, 1e-10, 1e+10))),by_symbol)\n",
    "    log_likelihood = tf.reduce_sum(terms)\n",
    "    #log_likelihood = tf.Print(log_likelihood, [log_likelihood])\n",
    "    return log_likelihood/FLAGS.batch_size\n",
    "    \n",
    "    \n",
    "# Param: x, stacking of the output of fully connected physical network for each agent. Shape = (256, batch_size, nb_agents)\n",
    "# return: pooling of input features.\n",
    "def softmax_pooling(x):\n",
    "    # pooling function. Softmax pooling is a compromise between max pooling and average pooling\n",
    "    coefs = tf.nn.softmax(x, dim = 0)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = 0)\n",
    "    return softmax_pool\n",
    "\n",
    "\n",
    "def activation_function(x):\n",
    "    return tf.nn.elu(x)\n",
    "\n",
    "\n",
    "def gumbel_max_trick(x, hard = True):\n",
    "    # Application of gumbel-softmax trick\n",
    "    # Input: output of the last network \n",
    "    u = -tf.log(-tf.log(tf.random_uniform(shape = [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size],\n",
    "                                          dtype=tf.float32)))\n",
    "    utterance_output = tf.slice(x, [0, 2*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "    gumbel = tf.exp((utterance_output + u)/FLAGS.gumbel_temperature)\n",
    "    denoms = tf.reshape(tf.reduce_sum(gumbel, axis = 1), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    utterance = gumbel/denoms\n",
    "    if hard:\n",
    "        idx_utt = tf.argmax(utterance, axis = 1)\n",
    "        utt_hard = tf.transpose(tf.one_hot(idx_utt, depth = FLAGS.vocabulary_size), [0, 2, 1])\n",
    "        utterance = tf.stop_gradient(utt_hard - utterance) + utterance\n",
    "        \n",
    "    return utterance \n",
    "\n",
    "\n",
    "def sample_phys(x):\n",
    "    #Input: output of the last network.\n",
    "    #Output: sampled values for new velocity and gaze\n",
    "    u = tf.random_normal(shape = [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size],dtype=tf.float32,\n",
    "                         stddev = FLAGS.sddev_phys_sampling)\n",
    "    o = tf.add(tf.slice(x, [0, 0, 0], [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size]), u)\n",
    "    sample_move = tf.slice(o, [0, 0, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    sample_gaze  = tf.slice(o, [0, FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    return sample_move, sample_gaze\n",
    "\n",
    "\n",
    "def compute_new_states(old_states, new_velocities, new_delta_gazes, new_utterances):\n",
    "    #Computes the new states according to the equations of the papers.\n",
    "    # Input: the old states of shape [number agents + nb_landmarks, 3*env dim + color size, batch size] because color is in state\n",
    "    # and of shape [number_agents, 2*env_dim, batch size]\n",
    "    # Adding the outputs of landmark, which are all zeros.\n",
    "    #new_velocities = tf.concat([new_velocities, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "\n",
    "    #new_delta_gazes = tf.concat([new_delta_gazes, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "    \n",
    "    #old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #new_pos = tf.slice(old_states, [0, 0, 0], \n",
    "    #                   [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    #new_gazes = old_gazes + new_delta_gazes*FLAGS.delta_t\n",
    "    \n",
    "    #new_velocity = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    \n",
    "    old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents , FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    new_pos_agents = tf.slice(old_states, [0, 0, 0], \n",
    "                       [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    new_pos_landmarks = tf.slice(old_states, [FLAGS.number_agents, 0, 0], \n",
    "                       [FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_pos = tf.concat([new_pos_agents, new_pos_landmarks], axis = 0)\n",
    "    \n",
    "    new_gazes_agents = old_gazes + new_delta_gazes*FLAGS.delta_t*FLAGS.delta_t\n",
    "    new_gazes_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_gazes = tf.concat([new_gazes_agents, new_gazes_landmarks], axis = 0)\n",
    "    \n",
    "    new_velocity_agents = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    new_velocity_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_velocity = tf.concat([new_velocity_agents, new_velocity_landmarks], axis = 0)\n",
    "    \n",
    "    colors = tf.slice(old_states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                            FLAGS.color_size, FLAGS.batch_size])\n",
    "    \n",
    "    new_states = tf.concat([new_pos, new_velocity, new_gazes, colors], axis = 1)\n",
    "\n",
    "    return new_states, new_pos, new_gazes\n",
    "\n",
    "\n",
    "\n",
    "def compute_new_memories(old_mem_com, old_mem_last, delta_mem_com, delta_mem_last):\n",
    "    new_memory_com = tf.tanh((2/3)*(old_mem_com + delta_mem_com + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    new_memory_last = tf.tanh((2/3)*(old_mem_last + delta_mem_last + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                   FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    \n",
    "    #new_memory_com = tf.zeros([FLAGS.number_agents, 32, FLAGS.batch_size])\n",
    "    #new_memory_last = tf.zeros([FLAGS.number_agents, 32, FLAGS.batch_size])\n",
    "    return new_memory_com,new_memory_last\n",
    "\n",
    "\n",
    "\n",
    "def shuffle(x, name_targets, colors = False, goal = False):\n",
    "    slices_second_dim = []\n",
    "    ones = tf.ones([FLAGS.number_agents, 1, FLAGS.batch_size], tf.int32)\n",
    "    batch_num = tf.tile(tf.reshape(tf.range(0, FLAGS.batch_size, dtype = tf.int32), [1, 1, FLAGS.batch_size]), [FLAGS.number_agents,\n",
    "                                                                                                               1, 1])\n",
    "    if (not colors) and (not goal):\n",
    "        for i in range(FLAGS.dim_env):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "    if colors:\n",
    "        for i in range(FLAGS.color_size):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "            \n",
    "    if goal:\n",
    "        for i in range(2):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))   \n",
    "    \n",
    "            \n",
    "    gathering_tensor = tf.transpose(tf.concat(slices_second_dim, axis = 1), perm = [0, 1, 3, 2])\n",
    "    shuffled_x = tf.gather_nd(x, gathering_tensor)\n",
    "    \n",
    "    return shuffled_x\n",
    "    \n",
    "    \n",
    "def compute_reward(positions, gazes, outputs, utterances, name_targets, goals_loc, goals_types):\n",
    "    shuffled_positions = shuffle(positions, name_targets)\n",
    "    shuffled_gazes = shuffle(gazes, name_targets)\n",
    "\n",
    "    pos_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_positions - goals_loc)), axis = 1), [FLAGS.number_agents, 1, \n",
    "                                                                                                     FLAGS.batch_size])\n",
    "\n",
    "    gaze_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_gazes - goals_loc)), axis = 1), [FLAGS.number_agents, 1,\n",
    "                                                                                                     FLAGS.batch_size])\n",
    "    zeros = tf.zeros([FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    x = tf.concat([pos_distances, gaze_distances, zeros], axis = 1)\n",
    "\n",
    "    dists_goal = -tf.reduce_sum(tf.multiply(x, goals_types), axis = 1)\n",
    "    \n",
    "    utterances_term = -tf.reduce_sum(tf.square(utterances), axis = 1)\n",
    "   # utterances_term = -tf.reduce_sum(tf.square(tf.slice(utterances, [0, 1, 0], [FLAGS.number_agents, (FLAGS.vocabulary_size-1), FLAGS.batch_size])), axis = 1)\n",
    "    output_term = -tf.reduce_sum(tf.square(outputs), axis = 1)\n",
    "    \n",
    "    reward_by_batch = tf.reshape(tf.reduce_sum(dists_goal + utterances_term + output_term, axis = 0), [FLAGS.batch_size, 1])\n",
    "\n",
    "    return reward_by_batch\n",
    "\n",
    "\n",
    "\n",
    "def compute_goal_dist(states, goal_location, goal_type):\n",
    "    dist_positions = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 0:2, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    dist_gazes = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 4:6, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    v = np.concatenate([dist_positions, dist_gazes, np.zeros((FLAGS.number_agents, 1, FLAGS.batch_size))], axis = 1)\n",
    "    goal_distances = np.sum(np.multiply(v, goal_type), axis = 1)\n",
    "    \n",
    "    return goal_distances\n",
    "\n",
    "\n",
    "def print_stats_agent(states, goal_location, goal_type, targets):\n",
    "    #Only considering non \"do nothing goals\"\n",
    "    shuffled_states = python_shuffle(states, targets)\n",
    "    goal_distances = compute_goal_dist(shuffled_states, goal_location, goal_type)\n",
    "    \n",
    "    for i in range(FLAGS.number_agents):\n",
    "        distances_agents = goal_distances[i, :]\n",
    "        goal_wo_zeros = distances_agents[distances_agents != 0]\n",
    "        mean = np.mean(goal_wo_zeros)\n",
    "        median = np.median(goal_wo_zeros)\n",
    "        third_quart = np.percentile(goal_wo_zeros, 75)\n",
    "        nine_pct = np.percentile(goal_wo_zeros, 90)\n",
    "        max_dist = np.max(distances_agents)\n",
    "        argmax = np.argmax(distances_agents)\n",
    "        print(\"--- Agent \" + str(i))\n",
    "        print(\"------ Mean distance \" + str(mean))\n",
    "        print(\"------ Median distance \" + str(median))\n",
    "        print(\"------ Third quartile \" + str(third_quart))\n",
    "        print(\"------ Ninetieth percentile \" + str(nine_pct))\n",
    "        print(\"------ max distance \" + str(max_dist))\n",
    "        print(\"------ argmax distance \" + str(argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the physical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 3*FLAGS.dim_env + FLAGS.color_size\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, number of inputs]\n",
    "        #This shape enables us to handle all the agents/landmarks states at once, instead of dealing with list of agents' states\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                               # [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                                #[FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                                #[FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.layer_sizes, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                                #[FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.output_size, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                                #[FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): \n",
    "        # Compute a forward pass through the network\n",
    "        # Input: a tensor of shape [number of agents, size of input, batch _size]\n",
    "        # Output: a tensor of shape [number of agents, output_size, batch_size]\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "                else:\n",
    "                    x = activation_function(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the communication network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CommunicationNet: \n",
    "    \n",
    "    def __init__(self):    \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"com_memory_read_weight\", shape = [1, FLAGS.output_size, FLAGS.mem_size],\n",
    "                                               initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        self.def_pred_layer()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, vocabulary size]\n",
    "        #This shape enables us to handle all the agents utterances at once, instead of dealing with list of agents' states        \n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.vocabulary_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.output_size, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])  \n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        # Initialization of the weights and biases writing in the memory.\n",
    "        # Their shape are of the form [number of agents, memory_size, output size] and [number of agents, output size, 1]\n",
    "        # So that we can handle the memories of all agents at onces instead of dealing with list of memories.\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_com\" , shape=[1, FLAGS.mem_size,FLAGS.output_size],\n",
    "                            initializer=tf.orthogonal_initializer()), \n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_com\", shape = [1, FLAGS.mem_size, 1],\n",
    "                            initializer=tf.orthogonal_initializer()),\n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "      \n",
    "    def def_pred_layer(self):\n",
    "        self.W_pred = tf.tile(tf.get_variable(\"weight_pred_com\" , shape=[1, FLAGS.number_goal_types + FLAGS.dim_env + 3,FLAGS.output_size],\n",
    "                            initializer=tf.orthogonal_initializer()), \n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        self.b_pred = tf.tile(tf.get_variable(\"bias_pred_com\", shape = [1, FLAGS.number_goal_types + FLAGS.dim_env + 3, 1],\n",
    "                            initializer=tf.orthogonal_initializer()),\n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        predicted_goal = tf.matmul(self.W_pred, x) + self.b_pred\n",
    "        return x, delta_mem, predicted_goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LastNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 2*FLAGS.output_size + FLAGS.color_size + FLAGS.number_goal_types + FLAGS.dim_env\n",
    "        #self.input_size = 2*FLAGS.output_size + FLAGS.color_size + FLAGS.number_goal_types + FLAGS.number_landmarks\n",
    "        self.output_size = 2*FLAGS.dim_env + FLAGS.vocabulary_size\n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"reading_last_mem_weight\", shape = [1, self.output_size, FLAGS.last_mem_size],\n",
    "                                              initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, self.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    #W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, 2, FLAGS.layer_sizes],\n",
    "                    #                    initializer=tf.orthogonal_initializer()),\n",
    "                    #            [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, self.output_size, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    #B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, 2, 1], \n",
    "                    #                    initializer=tf.orthogonal_initializer()),\n",
    "                    #            [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_last\", shape=[1, FLAGS.last_mem_size ,self.output_size],\n",
    "                                initializer=tf.orthogonal_initializer()),\n",
    "                                 [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_last\" ,shape = [1, FLAGS.last_mem_size, 1], \n",
    "                                    initializer=tf.orthogonal_initializer()),\n",
    "                                  [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "               \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        \n",
    "        return x , delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the policy: putting all the networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.phys_network = PhysicalNet()\n",
    "        self.comm_network = CommunicationNet()\n",
    "        self.last_network = LastNet()\n",
    "        \n",
    "        self.define_placeholders()\n",
    "        self.define_full_goals()\n",
    "        \n",
    "        \n",
    "    def define_placeholders(self):\n",
    "        self.states = tf.placeholder(tf.float32, [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                  3*FLAGS.dim_env + FLAGS.color_size, FLAGS.batch_size])\n",
    "        self.utterances = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "        self.memories_com = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size])\n",
    "        self.memories_last = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size])\n",
    "        self.goal_types = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.number_goal_types, FLAGS.batch_size])\n",
    "        self.goal_locations = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        #self.which_landmarks = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.number_landmarks, FLAGS.batch_size])\n",
    "        self.name_targets = tf.placeholder(tf.int32, [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "        #self.colors = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        \n",
    "        \n",
    "    def define_full_goals(self):\n",
    "        colors = tf.slice(self.states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        shuffled_colors = shuffle(colors, self.name_targets, colors = True)\n",
    "        #shuffled_goal_loc = shuffle(self.goal_locations, self.name_targets, colors = False, goal = True)\n",
    "        #self.full_goals = tf.concat([self.goal_types, self.goal_locations, shuffled_colors], axis = 1)\n",
    "        #shuffled_colors = tf.zeros([FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        self.full_goals = tf.concat([self.goal_types, self.goal_locations, shuffled_colors], axis = 1)\n",
    "        #self.full_goals = tf.concat([self.goal_types, self.which_landmarks, shuffled_colors], axis = 1)\n",
    "\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.states, self.utterances, self.memories_com, self.memories_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets]#, self.which_landmarks]\n",
    "        \n",
    "    def forward_pass(self, states, utterances, mem, mem_last, goals_last):\n",
    "        #Step 1: processing observed states and utterances\n",
    "        \n",
    "        soft_outputs_phys = []\n",
    "        for i in range(FLAGS.number_agents):\n",
    "            st_agent = tf.slice(states, [i, 0, 0], [1, FLAGS.dim_env*3+FLAGS.color_size, FLAGS.batch_size])\n",
    "            st_landmarks = tf.slice(states, [FLAGS.number_agents, 0, 0], [FLAGS.number_landmarks, FLAGS.dim_env*3+FLAGS.color_size, FLAGS.batch_size])\n",
    "            st = tf.concat([st_agent, st_landmarks], axis = 0)\n",
    "            softmax_output = softmax_pooling(self.phys_network.compute_output(st))\n",
    "            soft_outputs_phys.append(tf.reshape(softmax_output, [1, FLAGS.output_size, FLAGS.batch_size]))\n",
    "            \n",
    "            \n",
    "        comm_output, new_mem_com, predicted_goal = self.comm_network.compute_output(utterances, mem)\n",
    "        \n",
    "        #Step 2: softmax pooling the results [num_agents, output size, batch_size] --> [1, output size, batch_size]\n",
    "        #PhiX = softmax_pooling(phys_output)\n",
    "        PhiX_last = tf.concat(soft_outputs_phys, axis = 0)\n",
    "        PhiC = softmax_pooling(comm_output)\n",
    "        \n",
    "        #PhiX = tf.Print(PhiX_last, [tf.reduce_sum(tf.cast(tf.is_nan(PhiX_last), tf.float32)), \"PhiX\"])\n",
    "        #PhiC = tf.Print(PhiC, [tf.reduce_sum(tf.cast(tf.is_nan(PhiC), tf.float32)), \"PhiC\"])\n",
    "        \n",
    "        #Step 3: feeding the last network      \n",
    "        #PhiX_last = tf.tile(tf.reshape(PhiX, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        PhiC_last = tf.tile(tf.reshape(PhiC, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        #input_last = tf.concat([PhiX_last, goals_last, PhiC_last], axis = 1)\n",
    "        input_last = tf.concat([PhiX_last, goals_last, PhiC_last], axis = 1)\n",
    "        \n",
    "        output_last, new_mem_last = self.last_network.compute_output(input_last, mem_last)\n",
    "        #output_last = self.last_network.compute_output(input_last, mem_last)\n",
    "        velocities_output, gazes_output = sample_phys(output_last)\n",
    "        utterances_output = gumbel_max_trick(output_last)\n",
    "        phys_output = tf.concat([velocities_output, gazes_output], axis = 1)\n",
    "        \n",
    "        return phys_output, velocities_output, gazes_output, utterances_output, new_mem_com, new_mem_last, predicted_goal\n",
    "        #return output_last\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.enc = OneHotEncoder(n_values=FLAGS.number_goal_types, sparse=False)\n",
    "        self.colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)] \n",
    "        self.cols, self.cols_agents, self.cols_landmarks = self.create_colors()\n",
    "        self.colors_ld = np.stack([np.eye(FLAGS.number_landmarks) for i in range(FLAGS.batch_size)], axis = 2)\n",
    "    \n",
    "    \n",
    "    def create_colors(self):\n",
    "        cols_agents = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_agents)], axis = 0)\n",
    "        cols_landmarks = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_landmarks)], axis = 0)\n",
    "        \n",
    "        cols = np.concatenate([cols_agents, cols_landmarks], axis = 0)\n",
    "            \n",
    "        return cols, cols_agents, cols_landmarks\n",
    "            \n",
    "        \n",
    "    def create_consistent_targets(self):\n",
    "        #targets_by_exp = [np.random.choice(FLAGS.number_agents, (FLAGS.number_agents, 1), replace = False) for _ in range(FLAGS.batch_size)]\n",
    "        targets_by_exp = [np.array([[0], [1]]) for _ in range(FLAGS.batch_size)]\n",
    "        targets_batch = np.stack(targets_by_exp, axis = 2)\n",
    "        return targets_batch\n",
    "    \n",
    "    def create_goal_locations(self, pos_landmarks):\n",
    "        landmark_nb = [np.random.choice(FLAGS.number_landmarks, (FLAGS.number_agents, 1), replace = True) for _ in range(FLAGS.batch_size)]\n",
    "        landmark_nb_batch = np.stack(landmark_nb, axis = 2)\n",
    "        \n",
    "        goal_loc = python_shuffle(pos_landmarks, landmark_nb_batch)\n",
    "        which_landmark = python_shuffle(self.colors_ld, landmark_nb_batch)\n",
    "        \n",
    "        return goal_loc, which_landmark\n",
    "        \n",
    "        \n",
    "    def random_generation(self):\n",
    "        positions_agents = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        #positions_agents = np.array([[[1 for i in range(100)], [1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        \n",
    "        #positions_landmarks = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_landmarks, \n",
    "        #                                                          FLAGS.dim_env, FLAGS.batch_size))\n",
    "        positions_landmarks = np.array([[[-3 for i in range(FLAGS.batch_size)], [-3 for i in range(FLAGS.batch_size)]], [[ 2.5 for i in range(FLAGS.batch_size)], [-1 for i in range(FLAGS.batch_size)]], [[1.5 for i in range(FLAGS.batch_size)], [2 for i in range(FLAGS.batch_size)]]])\n",
    "        #positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]], [[4 for i in range(100)], [4 for i in range(100)]]])\n",
    "\n",
    "\n",
    "        positions = np.concatenate([positions_agents, positions_landmarks], axis = 0)\n",
    "        \n",
    "        gazes = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        #gazes_agents = np.array([[[1 for i in range(100)], [1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        #gazes = np.concatenate([gazes_agents, gazes_landmarks], axis = 0)\n",
    "        #velocities = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "        #                                                     FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        velocities = np.zeros([FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        \n",
    "        #goal_locations = np.random.uniform(-FLAGS.bound, FLAGS.bound, [FLAGS.number_agents, \n",
    "        #                                                          FLAGS.dim_env, FLAGS.batch_size])\n",
    " \n",
    "        goal_locations, which_landmarks = self.create_goal_locations(positions_landmarks)\n",
    "        \n",
    "        #goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "        #                np.random.choice(FLAGS.number_goal_types, FLAGS.batch_size).reshape(-1,1))), \n",
    "        #                          [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "        #goal_types = np.array([[[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]], [[1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]], [[1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]]])\n",
    "        \n",
    "        #goal_types = np.array([[[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]], [[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]]])\n",
    "        goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "                        np.random.choice([0,1], FLAGS.batch_size).reshape(-1,1))), \n",
    "                                  [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "\n",
    "        #goal_types = np.array([[[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]] for m in range(2)])\n",
    "        utterances = np.zeros((FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size))\n",
    "        memories_com = np.zeros((FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size))\n",
    "        memories_last = np.zeros((FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size))\n",
    "        \n",
    "        states = np.concatenate([positions, velocities, gazes, self.cols], axis = 1)\n",
    "        targets = self.create_consistent_targets()\n",
    "\n",
    "        return states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_return(output, full_goals, targets):\n",
    "    #shuffled_output = shuffle(output, targets)\n",
    "    shuffled_output = output\n",
    "    return -tf.reshape(tf.reduce_sum(tf.sqrt(tf.reduce_sum((shuffled_output - full_goals)**2, axis = 1)), axis = 0), [FLAGS.batch_size, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_nan(tensor):\n",
    "    nb_nan = np.sum(np.isnan(tensor))\n",
    "    if nb_nan == 0:\n",
    "        print(\"TRUETRUETRUETRUETRUETRUE\")\n",
    "        \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.policy = Policy()\n",
    "        self.env = Environment()\n",
    "        delete_history_files()\n",
    "        \n",
    "        self.get_placeholders()\n",
    "        self.definition_arrays()\n",
    "        self.write_arrays()\n",
    "        self.learning_rate = self.learning_rate_decay()\n",
    "        tf.summary.scalar('learning rate', self.learning_rate)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        self.loop()\n",
    "        self.output_to_run = [self.step, self.array_states_stack, self.array_utterances_stack, self.array_mem_com_stack, self.array_mem_last_stack, self.array_pred_stack,\n",
    "                                self.f_g , self.array_outputs_stack, self.t_fin, self.reward, self.phys_reward, self.voc_reward, self.pred_reward]\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "        self.reward_history = []\n",
    "        self.reward_batch_history = []\n",
    "        self.voc_reward_history = []\n",
    "        self.pred_reward_history = []\n",
    "        self.env_history = []\n",
    "        self.arrays_history = []\n",
    "        self.mean_act_count = []\n",
    "        \n",
    "        self.utt_hist = []\n",
    "        self.grads_history = []\n",
    "        self.vars_history = []\n",
    "        \n",
    "        self.array_utt = []\n",
    "        \n",
    "        \n",
    "    def learning_rate_decay(self):\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        if FLAGS.learning_rate_decay:\n",
    "            starter_learning_rate = FLAGS.learning_rate\n",
    "            boundaries = [600]#1500 #3000] #, 10000]\n",
    "            values = [FLAGS.learning_rate, FLAGS.learning_rate/10] #, FLAGS.learning_rate/100]\n",
    "            return tf.train.piecewise_constant(self.global_step, boundaries, values, name=None)\n",
    "            #return tf.train.exponential_decay(starter_learning_rate, self.global_step, 150, 0.5, staircase = True)#0.05#150\n",
    "        else:\n",
    "            return FLAGS.learning_rate\n",
    "        \n",
    "    def definition_arrays(self):\n",
    "        # Create goals vectors \n",
    "        self.array_states = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_utterances = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_com = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_last = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_outputs = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_pred = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        \n",
    "    def get_placeholders(self):\n",
    "        [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets] = self.policy.get_placeholders()\n",
    "            \n",
    "            \n",
    "    def write_arrays(self):\n",
    "        self.array_states = self.array_states.write(0, self.states)\n",
    "        self.array_utterances = self.array_utterances.write(0, self.utterances)\n",
    "        self.array_mem_com = self.array_mem_com.write(0, self.mem_com)\n",
    "        self.array_mem_last = self.array_mem_last.write(0, self.mem_last)\n",
    "        self.array_outputs = self.array_outputs.write(0, np.zeros((FLAGS.number_agents, 4, FLAGS.batch_size), dtype = np.float32))\n",
    "        #self.array_outputs = self.array_outputs.write(0, np.zeros((FLAGS.number_agents, 2, FLAGS.batch_size), dtype = np.float32))\n",
    "        self.array_pred = self.array_pred.write(0, np.zeros((FLAGS.number_agents, FLAGS.number_goal_types + FLAGS.dim_env + 3, FLAGS.batch_size), dtype = np.float32))\n",
    "    \n",
    "    def loop(self):\n",
    "        t = tf.constant(0)\n",
    "        return_sofar = tf.zeros([FLAGS.batch_size, 1], tf.float32)\n",
    "        return_pred = tf.zeros([FLAGS.batch_size, 1], tf.float32)\n",
    "        #return_sofar = tf.zeros([2, FLAGS.batch_size], tf.float32)\n",
    "        args = [self.array_states, self.array_utterances, self.array_mem_com, self.array_mem_last, self.array_pred, self.goal_types, \n",
    "                self.goal_locations, self.full_goals, self.name_targets, self.array_outputs, t, return_sofar, return_pred]\n",
    "        \n",
    "        (array_states, array_utterances, array_mem_com, array_mem_last, array_pred, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t_fin, rewards_batch, return_pred) = tf.while_loop(self.condition, self.body, args, parallel_iterations=1)\n",
    "        \n",
    "        self.array_states_stack = array_states.stack()\n",
    "        self.array_utterances_stack = array_utterances.stack() \n",
    "        self.array_mem_com_stack = array_mem_com.stack() \n",
    "        self.array_mem_last_stack = array_mem_last.stack() \n",
    "        self.array_outputs_stack = array_outputs.stack()\n",
    "        self.array_pred_stack = array_pred.stack()\n",
    "        \n",
    "        self.phys_reward = tf.reshape(tf.reduce_mean(rewards_batch, axis = 0), [])\n",
    "        self.pred_reward = tf.reshape(tf.reduce_mean(return_pred, axis = 0), [])\n",
    "        #self.phys_reward = tf.reshape(tf.reduce_mean(self.reward_batch), [])\n",
    "        self.voc_reward = dirichlet_log_lik_end(tf.slice(self.array_utterances_stack, [1, 0, 0, 0], [FLAGS.time_horizon, FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size]))\n",
    "        self.f_g = full_goals\n",
    "        self.t_fin = t_fin, \n",
    "        self.reward = tf.Print(self.phys_reward +self.pred_reward + 0.5*self.voc_reward, [\"END\", self.phys_reward, self.voc_reward]) #+ self.voc_reward\n",
    "        #0.5\n",
    "        tf.summary.scalar('accuracy', -self.reward)\n",
    "        self.grads = self.optimizer.compute_gradients(-self.reward)\n",
    "            \n",
    "        #self.clipped_gradients = [(tf.clip_by_norm(grad, 0.0001), var) for grad, var in self.grads]\n",
    "        self.step = self.optimizer.apply_gradients(self.grads, global_step=self.global_step)\n",
    "        for index, grad in enumerate(self.grads):\n",
    "            tf.summary.histogram(\"{}-grad\".format(self.grads[index][1].name), self.grads[index]) \n",
    "    \n",
    "        \n",
    "    def body(self, array_states, array_utterances, array_mem_com, array_mem_last, array_pred, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar, return_pred_sofar):\n",
    "        \n",
    "        #Reading the last state of environment\n",
    "        states = array_states.read(t)\n",
    "        utterances = array_utterances.read(t)\n",
    "        mem_com = array_mem_com.read(t)\n",
    "        mem_last = array_mem_last.read(t)\n",
    "        \n",
    "        \n",
    "        phys_output, new_velocities, new_delta_gazes, new_utterances, delta_mem_com, delta_mem_last, pred = self.policy.forward_pass(states,\n",
    "                                                                    utterances, mem_com, mem_last, full_goals)\n",
    "        \n",
    "        #phys_output = self.policy.forward_pass(states, utterances, mem_com, mem_last, full_goals)\n",
    "\n",
    "        new_states, new_positions, new_gazes = compute_new_states(states, new_velocities, new_delta_gazes, new_utterances)\n",
    "        #new_utterances = tf.zeros([FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "        new_mem_com, new_mem_last = compute_new_memories(mem_com, mem_last, delta_mem_com, delta_mem_last)\n",
    "        \n",
    "        return_sofar += compute_reward(new_positions, new_gazes, phys_output, new_utterances, name_targets, goal_locations, \n",
    "                                        goal_types)\n",
    "        \n",
    "        return_pred_sofar = comp_return(pred, full_goals, name_targets)\n",
    "        \n",
    "        #return_sofar += comp_return(phys_output, goal_locations, name_targets)\n",
    "\n",
    "        #Writing the new state\n",
    "        \n",
    "        array_states = array_states.write((t+1), new_states)\n",
    "        array_utterances = array_utterances.write((t+1), new_utterances)\n",
    "        array_mem_com = array_mem_com.write((t+1), new_mem_com)\n",
    "        array_mem_last = array_mem_last.write((t+1), new_mem_last)\n",
    "        array_outputs = array_outputs.write((t+1), phys_output)\n",
    "        array_pred = array_pred.write((t+1), pred)\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "        return [array_states, array_utterances, array_mem_com, array_mem_last, array_pred, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar, return_pred_sofar]\n",
    "        \n",
    "        \n",
    "    def condition(self, array_states, array_utterances, array_mem_com, array_mem_last, array_pred, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar, return_pred_sofar):\n",
    "        return tf.less(t, FLAGS.time_horizon)\n",
    "    \n",
    "    \n",
    "    def create_feed_dict(self, states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks):\n",
    "        list_values = [states, utterances, memories_com, memories_last, goal_types, goal_locations, targets]#, which_landmarks]\n",
    "        list_placeholders = [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, \n",
    "                             self.goal_locations, self.name_targets]#, self.which_landmarks]\n",
    "        feed_dict = {a:b for a,b in zip(list_placeholders, list_values)} #.update({self.learning_rate:self.lr})\n",
    "        return feed_dict\n",
    "    \n",
    "    def train(self, sess):\n",
    "        self.train_writer = tf.summary.FileWriter('Summary', sess.graph)\n",
    "        print(\"Initializing variables\")\n",
    "        sess.run(self.init)\n",
    "        sess.graph.finalize()\n",
    "        print(\"Start training\")\n",
    "        start = datetime.now()\n",
    "        self.arrays_history = [0, 0, 0, 0, 0]\n",
    "        self.full_g = []\n",
    "        #states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks = self.env.random_generation()\n",
    "        for i in range(FLAGS.max_steps):            \n",
    "            states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks = self.env.random_generation()\n",
    "            generation_time = datetime.now() - start\n",
    "            feed_dict = self.create_feed_dict(states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks)\n",
    "            if (i+1) % FLAGS.tensorboard_freq == 0:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, array_pred, full_goals, array_outputs, t, reward, phys_reward, voc_reward, pred_reward, summary = sess.run(self.output_to_run + [self.merged], feed_dict)\n",
    "                self.train_writer.add_summary(summary, i)\n",
    "            else:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, array_pred, full_goals, array_outputs, t, reward, phys_reward, voc_reward, pred_reward = sess.run(self.output_to_run, feed_dict)\n",
    "            \n",
    "            \n",
    "            self.reward_history.append(reward)\n",
    "            self.pred_reward_history.append(pred_reward)\n",
    "            self.voc_reward_history.append(voc_reward)\n",
    "            self.arrays_history = [array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, array_pred]\n",
    "            with open('env_history.pkl', 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks])\n",
    "                \n",
    "            with open(\"arrays_history.pkl\", 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([array_states, array_utterances, array_mem_com, array_mem_last, array_outputs])\n",
    "                \n",
    "            if i % FLAGS.print_frequency == 0:\n",
    "                print(\"\\n\")\n",
    "                print(\"iteration \" + str(i))\n",
    "                print(\"physical reward: \" + str(phys_reward))\n",
    "                print(\"prediction reward: \" + str(pred_reward))\n",
    "                print(\"vocabulary reward: \" + str(voc_reward))\n",
    "                print(\"total reward: \" + str(reward))\n",
    "                final_states = array_states[-1, :, :, :]\n",
    "                print_stats_agent(final_states, goal_locations, goal_types, targets)\n",
    "    \n",
    "                print(\"computing time\")\n",
    "                print(datetime.now() - start)\n",
    "                print(\"generation time\")\n",
    "                print(generation_time)\n",
    "                print(\"memory usage\")\n",
    "                memory()\n",
    "\n",
    "                start = datetime.now()\n",
    "                \n",
    "            self.mean_act_count.append(print_stat_vocabulary(array_utterances[1:, :, :,:], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_0:0-grad is illegal; using phys_variable/weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_1:0-grad is illegal; using phys_variable/weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_2:0-grad is illegal; using phys_variable/weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_0:0-grad is illegal; using phys_variable/bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_1:0-grad is illegal; using phys_variable/bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_2:0-grad is illegal; using phys_variable/bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_memory_read_weight:0-grad is illegal; using com_memory_read_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_0:0-grad is illegal; using com_variable/com_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_1:0-grad is illegal; using com_variable/com_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_2:0-grad is illegal; using com_variable/com_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_0:0-grad is illegal; using com_variable/com_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_1:0-grad is illegal; using com_variable/com_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_2:0-grad is illegal; using com_variable/com_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_com:0-grad is illegal; using weight_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_com:0-grad is illegal; using bias_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_pred_com:0-grad is illegal; using weight_pred_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_pred_com:0-grad is illegal; using bias_pred_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name reading_last_mem_weight:0-grad is illegal; using reading_last_mem_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_0:0-grad is illegal; using last_variable/last_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_1:0-grad is illegal; using last_variable/last_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_2:0-grad is illegal; using last_variable/last_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_0:0-grad is illegal; using last_variable/last_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_1:0-grad is illegal; using last_variable/last_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_2:0-grad is illegal; using last_variable/last_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_last:0-grad is illegal; using weight_mem_last_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_last:0-grad is illegal; using bias_mem_last_0-grad instead.\n",
      "Initializing variables\n",
      "Start training\n",
      "\n",
      "\n",
      "iteration 0\n",
      "physical reward: -3176.474\n",
      "prediction reward: -7.31842\n",
      "vocabulary reward: -293.8507\n",
      "total reward: -3330.7178\n",
      "--- Agent 0\n",
      "------ Mean distance 5.113931849653776\n",
      "------ Median distance 5.03814470317315\n",
      "------ Third quartile 6.942305988653226\n",
      "------ Ninetieth percentile 8.90358160778681\n",
      "------ max distance 12.699272721643688\n",
      "------ argmax distance 62\n",
      "--- Agent 1\n",
      "------ Mean distance 5.31000445775047\n",
      "------ Median distance 4.845476066924932\n",
      "------ Third quartile 6.652396391607194\n",
      "------ Ninetieth percentile 9.479811174012623\n",
      "------ max distance 12.034529963374702\n",
      "------ argmax distance 69\n",
      "computing time\n",
      "0:00:02.262668\n",
      "generation time\n",
      "0:00:00.010663\n",
      "memory usage\n",
      "memory use: 0.7515068054199219\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 17.825\n",
      "---- Median number of word activated: 18.0\n",
      "---- Total number of word activated: 20\n",
      "\n",
      "\n",
      "iteration 50\n",
      "physical reward: -1135.058\n",
      "prediction reward: -7.134111\n",
      "vocabulary reward: -279.72665\n",
      "total reward: -1282.0554\n",
      "--- Agent 0\n",
      "------ Mean distance 1.0969355551035365\n",
      "------ Median distance 0.8439389048680953\n",
      "------ Third quartile 1.1221896641157816\n",
      "------ Ninetieth percentile 2.7261592637706817\n",
      "------ max distance 3.5221094704030214\n",
      "------ argmax distance 41\n",
      "--- Agent 1\n",
      "------ Mean distance 0.805848840120265\n",
      "------ Median distance 0.7820294433495261\n",
      "------ Third quartile 0.9291840438591332\n",
      "------ Ninetieth percentile 1.133782849972387\n",
      "------ max distance 3.504128192838361\n",
      "------ argmax distance 13\n",
      "computing time\n",
      "0:00:47.762656\n",
      "generation time\n",
      "0:00:46.777143\n",
      "memory usage\n",
      "memory use: 0.7679595947265625\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 16.325\n",
      "---- Median number of word activated: 16.0\n",
      "---- Total number of word activated: 20\n",
      "\n",
      "\n",
      "iteration 100\n",
      "physical reward: -1039.5889\n",
      "prediction reward: -6.7645745\n",
      "vocabulary reward: -125.40328\n",
      "total reward: -1109.055\n",
      "--- Agent 0\n",
      "------ Mean distance 0.9181228865872203\n",
      "------ Median distance 0.7983195626300628\n",
      "------ Third quartile 1.0942347628259375\n",
      "------ Ninetieth percentile 1.5479761221655133\n",
      "------ max distance 3.885612701416819\n",
      "------ argmax distance 60\n",
      "--- Agent 1\n",
      "------ Mean distance 0.8595112731328911\n",
      "------ Median distance 0.7977596363338205\n",
      "------ Third quartile 0.9862959056343562\n",
      "------ Ninetieth percentile 1.3856576601525277\n",
      "------ max distance 3.804505235251202\n",
      "------ argmax distance 52\n",
      "computing time\n",
      "0:01:06.282924\n",
      "generation time\n",
      "0:01:05.030448\n",
      "memory usage\n",
      "memory use: 0.7684669494628906\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 4.615\n",
      "---- Median number of word activated: 4.0\n",
      "---- Total number of word activated: 20\n",
      "\n",
      "\n",
      "iteration 150\n",
      "physical reward: -1043.0465\n",
      "prediction reward: -6.760771\n",
      "vocabulary reward: -105.975334\n",
      "total reward: -1102.7949\n",
      "--- Agent 0\n",
      "------ Mean distance 0.7306663994261108\n",
      "------ Median distance 0.6143545451229071\n",
      "------ Third quartile 0.786672430750244\n",
      "------ Ninetieth percentile 1.0277616072090299\n",
      "------ max distance 3.966567481786812\n",
      "------ argmax distance 73\n",
      "--- Agent 1\n",
      "------ Mean distance 0.758653232405609\n",
      "------ Median distance 0.5752821950969719\n",
      "------ Third quartile 0.7676417000400876\n",
      "------ Ninetieth percentile 0.9280062412225908\n",
      "------ max distance 4.009232949038466\n",
      "------ argmax distance 49\n",
      "computing time\n",
      "0:01:10.698581\n",
      "generation time\n",
      "0:01:09.363553\n",
      "memory usage\n",
      "memory use: 0.7684707641601562\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 3.03\n",
      "---- Median number of word activated: 3.0\n",
      "---- Total number of word activated: 8\n",
      "\n",
      "\n",
      "iteration 200\n",
      "physical reward: -987.2343\n",
      "prediction reward: -6.6890764\n",
      "vocabulary reward: -95.41381\n",
      "total reward: -1041.6302\n",
      "--- Agent 0\n",
      "------ Mean distance 0.5454333443798021\n",
      "------ Median distance 0.4008573029853332\n",
      "------ Third quartile 0.5286081720745376\n",
      "------ Ninetieth percentile 1.0217095808903116\n",
      "------ max distance 3.3245345396148234\n",
      "------ argmax distance 21\n",
      "--- Agent 1\n",
      "------ Mean distance 0.577208159129898\n",
      "------ Median distance 0.3264614489945085\n",
      "------ Third quartile 0.5013975642194634\n",
      "------ Ninetieth percentile 1.3935289313308632\n",
      "------ max distance 3.510739607142927\n",
      "------ argmax distance 74\n",
      "computing time\n",
      "0:01:14.127619\n",
      "generation time\n",
      "0:01:12.870847\n",
      "memory usage\n",
      "memory use: 0.7687225341796875\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 3.03\n",
      "---- Median number of word activated: 3.0\n",
      "---- Total number of word activated: 7\n",
      "\n",
      "\n",
      "iteration 250\n",
      "physical reward: -1024.3185\n",
      "prediction reward: -6.6411095\n",
      "vocabulary reward: -70.186005\n",
      "total reward: -1066.0526\n",
      "--- Agent 0\n",
      "------ Mean distance 0.8524006293458377\n",
      "------ Median distance 0.6923351811934285\n",
      "------ Third quartile 0.8602817925489835\n",
      "------ Ninetieth percentile 1.3887190848628599\n",
      "------ max distance 4.523904210348519\n",
      "------ argmax distance 95\n",
      "--- Agent 1\n",
      "------ Mean distance 0.6870279881840016\n",
      "------ Median distance 0.5467901565817332\n",
      "------ Third quartile 0.7301533355264713\n",
      "------ Ninetieth percentile 0.9385345480435147\n",
      "------ max distance 4.215780680737794\n",
      "------ argmax distance 42\n",
      "computing time\n",
      "0:01:21.138696\n",
      "generation time\n",
      "0:01:19.339631\n",
      "memory usage\n",
      "memory use: 0.7687225341796875\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.095\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration 300\n",
      "physical reward: -903.677\n",
      "prediction reward: -6.642596\n",
      "vocabulary reward: -69.539635\n",
      "total reward: -945.0894\n",
      "--- Agent 0\n",
      "------ Mean distance 0.687574147871886\n",
      "------ Median distance 0.5643365279019704\n",
      "------ Third quartile 0.8860901142386675\n",
      "------ Ninetieth percentile 1.4259299747145637\n",
      "------ max distance 3.2622803309492125\n",
      "------ argmax distance 23\n",
      "--- Agent 1\n",
      "------ Mean distance 0.7673435288570124\n",
      "------ Median distance 0.6090109707072318\n",
      "------ Third quartile 0.9927003774318159\n",
      "------ Ninetieth percentile 1.6417308474254166\n",
      "------ max distance 3.784789675208689\n",
      "------ argmax distance 93\n",
      "computing time\n",
      "0:01:43.071047\n",
      "generation time\n",
      "0:01:40.425717\n",
      "memory usage\n",
      "memory use: 0.7687263488769531\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.015\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 4\n",
      "\n",
      "\n",
      "iteration 350\n",
      "physical reward: -1099.2769\n",
      "prediction reward: -6.6602464\n",
      "vocabulary reward: -69.49119\n",
      "total reward: -1140.6827\n",
      "--- Agent 0\n",
      "------ Mean distance 0.5770452958199332\n",
      "------ Median distance 0.2589628306940195\n",
      "------ Third quartile 0.4323670018251229\n",
      "------ Ninetieth percentile 1.5795872491549023\n",
      "------ max distance 3.906899941066066\n",
      "------ argmax distance 1\n",
      "--- Agent 1\n",
      "------ Mean distance 0.6021604619842866\n",
      "------ Median distance 0.30514028775962465\n",
      "------ Third quartile 0.4496310097642792\n",
      "------ Ninetieth percentile 1.7418351156602723\n",
      "------ max distance 3.415408647515536\n",
      "------ argmax distance 24\n",
      "computing time\n",
      "0:01:39.011928\n",
      "generation time\n",
      "0:01:36.994413\n",
      "memory usage\n",
      "memory use: 0.7687263488769531\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.01\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 4\n",
      "\n",
      "\n",
      "iteration 400\n",
      "physical reward: -981.04987\n",
      "prediction reward: -6.620898\n",
      "vocabulary reward: -69.404335\n",
      "total reward: -1022.3729\n",
      "--- Agent 0\n",
      "------ Mean distance 0.8819660627685064\n",
      "------ Median distance 0.865797895759661\n",
      "------ Third quartile 1.111464743328811\n",
      "------ Ninetieth percentile 1.4191359684398293\n",
      "------ max distance 3.6088090660769265\n",
      "------ argmax distance 72\n",
      "--- Agent 1\n",
      "------ Mean distance 0.9331774547264524\n",
      "------ Median distance 1.0761763257553563\n",
      "------ Third quartile 1.3474651359574814\n",
      "------ Ninetieth percentile 1.5815523058108303\n",
      "------ max distance 3.3258446118831873\n",
      "------ argmax distance 45\n",
      "computing time\n",
      "0:01:17.915393\n",
      "generation time\n",
      "0:01:16.056841\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.01\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 450\n",
      "physical reward: -1060.4404\n",
      "prediction reward: -6.452333\n",
      "vocabulary reward: -70.19586\n",
      "total reward: -1101.9907\n",
      "--- Agent 0\n",
      "------ Mean distance 1.0567756683412335\n",
      "------ Median distance 1.0953466679372228\n",
      "------ Third quartile 1.344565942494873\n",
      "------ Ninetieth percentile 1.599391298528539\n",
      "------ max distance 3.402856930428767\n",
      "------ argmax distance 75\n",
      "--- Agent 1\n",
      "------ Mean distance 0.9863224490452631\n",
      "------ Median distance 0.8525057168051593\n",
      "------ Third quartile 1.2359934770491114\n",
      "------ Ninetieth percentile 1.5382404686243936\n",
      "------ max distance 3.2522126470787467\n",
      "------ argmax distance 31\n",
      "computing time\n",
      "0:01:30.723477\n",
      "generation time\n",
      "0:01:28.745868\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.05\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 5\n",
      "\n",
      "\n",
      "iteration 500\n",
      "physical reward: -925.77936\n",
      "prediction reward: -6.4790716\n",
      "vocabulary reward: -69.58645\n",
      "total reward: -967.05164\n",
      "--- Agent 0\n",
      "------ Mean distance 0.623438360587855\n",
      "------ Median distance 0.40393031436676186\n",
      "------ Third quartile 0.6542593421681545\n",
      "------ Ninetieth percentile 1.878538296162873\n",
      "------ max distance 3.371818525105705\n",
      "------ argmax distance 46\n",
      "--- Agent 1\n",
      "------ Mean distance 0.5289482553708945\n",
      "------ Median distance 0.39477258511601787\n",
      "------ Third quartile 0.7125181397390303\n",
      "------ Ninetieth percentile 0.8522206311913538\n",
      "------ max distance 3.1556933844474155\n",
      "------ argmax distance 91\n",
      "computing time\n",
      "0:01:26.984052\n",
      "generation time\n",
      "0:01:25.598858\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.015\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 5\n",
      "\n",
      "\n",
      "iteration 550\n",
      "physical reward: -882.81213\n",
      "prediction reward: -6.407694\n",
      "vocabulary reward: -69.399826\n",
      "total reward: -923.91974\n",
      "--- Agent 0\n",
      "------ Mean distance 0.6224510708250787\n",
      "------ Median distance 0.5501179353150402\n",
      "------ Third quartile 0.7855847068878018\n",
      "------ Ninetieth percentile 1.0694993094746137\n",
      "------ max distance 3.3302894829490426\n",
      "------ argmax distance 61\n",
      "--- Agent 1\n",
      "------ Mean distance 0.6802857128382146\n",
      "------ Median distance 0.6325515319533559\n",
      "------ Third quartile 0.8561490099339966\n",
      "------ Ninetieth percentile 1.0723468471507576\n",
      "------ max distance 2.834538180894704\n",
      "------ argmax distance 55\n",
      "computing time\n",
      "0:01:31.764626\n",
      "generation time\n",
      "0:01:29.787832\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.005\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 600\n",
      "physical reward: -985.99603\n",
      "prediction reward: -6.364757\n",
      "vocabulary reward: -69.39593\n",
      "total reward: -1027.0587\n",
      "--- Agent 0\n",
      "------ Mean distance 0.8183115260342375\n",
      "------ Median distance 0.5738387241676826\n",
      "------ Third quartile 0.9426080855046377\n",
      "------ Ninetieth percentile 1.5540924387202064\n",
      "------ max distance 3.4830999876869733\n",
      "------ argmax distance 95\n",
      "--- Agent 1\n",
      "------ Mean distance 0.6727269465865479\n",
      "------ Median distance 0.5096021237672574\n",
      "------ Third quartile 0.6633623999467324\n",
      "------ Ninetieth percentile 0.993342969392654\n",
      "------ max distance 3.5697036094371195\n",
      "------ argmax distance 26\n",
      "computing time\n",
      "0:01:24.160189\n",
      "generation time\n",
      "0:01:22.313787\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.005\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 650\n",
      "physical reward: -908.81665\n",
      "prediction reward: -6.324707\n",
      "vocabulary reward: -69.303566\n",
      "total reward: -949.79315\n",
      "--- Agent 0\n",
      "------ Mean distance 0.38614063905106877\n",
      "------ Median distance 0.1546242134857294\n",
      "------ Third quartile 0.2568674028224781\n",
      "------ Ninetieth percentile 0.6400808821422271\n",
      "------ max distance 4.4660332806551315\n",
      "------ argmax distance 72\n",
      "--- Agent 1\n",
      "------ Mean distance 0.3516689883278063\n",
      "------ Median distance 0.15023620379743416\n",
      "------ Third quartile 0.23903910917033155\n",
      "------ Ninetieth percentile 1.0425038631310704\n",
      "------ max distance 4.329755728683283\n",
      "------ argmax distance 13\n",
      "computing time\n",
      "0:01:34.127943\n",
      "generation time\n",
      "0:01:32.482955\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n",
      "\n",
      "\n",
      "iteration 700\n",
      "physical reward: -747.2558\n",
      "prediction reward: -6.0999317\n",
      "vocabulary reward: -69.30468\n",
      "total reward: -788.00806\n",
      "--- Agent 0\n",
      "------ Mean distance 0.2939471658435563\n",
      "------ Median distance 0.13757006245980424\n",
      "------ Third quartile 0.2417962267912972\n",
      "------ Ninetieth percentile 0.4403494099980622\n",
      "------ max distance 3.236269137013684\n",
      "------ argmax distance 17\n",
      "--- Agent 1\n",
      "------ Mean distance 0.28110133147887784\n",
      "------ Median distance 0.1466955616244029\n",
      "------ Third quartile 0.19458976512496848\n",
      "------ Ninetieth percentile 0.33710653194331947\n",
      "------ max distance 3.8983824808673977\n",
      "------ argmax distance 79\n",
      "computing time\n",
      "0:01:28.131872\n",
      "generation time\n",
      "0:01:26.273223\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n",
      "\n",
      "\n",
      "iteration 750\n",
      "physical reward: -866.8538\n",
      "prediction reward: -6.3917556\n",
      "vocabulary reward: -69.29889\n",
      "total reward: -907.895\n",
      "--- Agent 0\n",
      "------ Mean distance 0.35719145436567357\n",
      "------ Median distance 0.17666814409031228\n",
      "------ Third quartile 0.2751130487051868\n",
      "------ Ninetieth percentile 0.8570495959154557\n",
      "------ max distance 3.0994343414888283\n",
      "------ argmax distance 57\n",
      "--- Agent 1\n",
      "------ Mean distance 0.3891152279835062\n",
      "------ Median distance 0.16251122514592675\n",
      "------ Third quartile 0.2531875889844102\n",
      "------ Ninetieth percentile 1.0760413988633573\n",
      "------ max distance 4.707265809469764\n",
      "------ argmax distance 31\n",
      "computing time\n",
      "0:01:36.994463\n",
      "generation time\n",
      "0:01:34.988507\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration 800\n",
      "physical reward: -940.1386\n",
      "prediction reward: -6.162406\n",
      "vocabulary reward: -69.29547\n",
      "total reward: -980.9487\n",
      "--- Agent 0\n",
      "------ Mean distance 0.4541730665580825\n",
      "------ Median distance 0.16342673441637112\n",
      "------ Third quartile 0.26796642002759297\n",
      "------ Ninetieth percentile 1.3790348861339001\n",
      "------ max distance 3.8149646025103947\n",
      "------ argmax distance 88\n",
      "--- Agent 1\n",
      "------ Mean distance 0.38155069410898174\n",
      "------ Median distance 0.1816593409946967\n",
      "------ Third quartile 0.2819843111422729\n",
      "------ Ninetieth percentile 1.0183709807995267\n",
      "------ max distance 3.0336789401640467\n",
      "------ argmax distance 45\n",
      "computing time\n",
      "0:01:33.751791\n",
      "generation time\n",
      "0:01:32.368027\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n",
      "\n",
      "\n",
      "iteration 850\n",
      "physical reward: -891.85864\n",
      "prediction reward: -6.254256\n",
      "vocabulary reward: -69.29844\n",
      "total reward: -932.76215\n",
      "--- Agent 0\n",
      "------ Mean distance 0.4968737860923585\n",
      "------ Median distance 0.19819762867473126\n",
      "------ Third quartile 0.3140546363653834\n",
      "------ Ninetieth percentile 1.4390731835979311\n",
      "------ max distance 3.8438878249842054\n",
      "------ argmax distance 98\n",
      "--- Agent 1\n",
      "------ Mean distance 0.2598320801962755\n",
      "------ Median distance 0.16031114714670602\n",
      "------ Third quartile 0.2376879933689637\n",
      "------ Ninetieth percentile 0.4674939782725039\n",
      "------ max distance 1.8563812758315867\n",
      "------ argmax distance 64\n",
      "computing time\n",
      "0:01:35.719905\n",
      "generation time\n",
      "0:01:33.711864\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n",
      "\n",
      "\n",
      "iteration 900\n",
      "physical reward: -855.2048\n",
      "prediction reward: -6.3637943\n",
      "vocabulary reward: -69.39858\n",
      "total reward: -896.2678\n",
      "--- Agent 0\n",
      "------ Mean distance 0.30920903964867036\n",
      "------ Median distance 0.16060904542061066\n",
      "------ Third quartile 0.21824120909132713\n",
      "------ Ninetieth percentile 0.5259405218701414\n",
      "------ max distance 3.1281353465765007\n",
      "------ argmax distance 1\n",
      "--- Agent 1\n",
      "------ Mean distance 0.33081605944520914\n",
      "------ Median distance 0.1624376966790958\n",
      "------ Third quartile 0.24514708335470586\n",
      "------ Ninetieth percentile 0.4165343575183409\n",
      "------ max distance 4.827417529686525\n",
      "------ argmax distance 78\n",
      "computing time\n",
      "0:01:36.233108\n",
      "generation time\n",
      "0:01:34.235996\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.005\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 950\n",
      "physical reward: -975.9793\n",
      "prediction reward: -6.416105\n",
      "vocabulary reward: -69.30465\n",
      "total reward: -1017.0477\n",
      "--- Agent 0\n",
      "------ Mean distance 0.41630880392159597\n",
      "------ Median distance 0.1753443873414076\n",
      "------ Third quartile 0.29134279788973816\n",
      "------ Ninetieth percentile 1.3046917125495936\n",
      "------ max distance 4.307082596505424\n",
      "------ argmax distance 52\n",
      "--- Agent 1\n",
      "------ Mean distance 0.5440859233814576\n",
      "------ Median distance 0.17583890728779747\n",
      "------ Third quartile 0.31032055772297235\n",
      "------ Ninetieth percentile 2.2241970444994363\n",
      "------ max distance 3.654310416625912\n",
      "------ argmax distance 18\n",
      "computing time\n",
      "0:01:41.804247\n",
      "generation time\n",
      "0:01:39.809290\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n",
      "\n",
      "\n",
      "iteration 1000\n",
      "physical reward: -875.8091\n",
      "prediction reward: -6.281213\n",
      "vocabulary reward: -69.30374\n",
      "total reward: -916.7421\n",
      "--- Agent 0\n",
      "------ Mean distance 0.2849146172769364\n",
      "------ Median distance 0.16747365337316245\n",
      "------ Third quartile 0.24400380745122796\n",
      "------ Ninetieth percentile 0.3442450989571023\n",
      "------ max distance 3.193694929924718\n",
      "------ argmax distance 1\n",
      "--- Agent 1\n",
      "------ Mean distance 0.41257766550065617\n",
      "------ Median distance 0.16895566200000253\n",
      "------ Third quartile 0.2434865993952668\n",
      "------ Ninetieth percentile 1.0654786560518956\n",
      "------ max distance 4.383910165364266\n",
      "------ argmax distance 33\n",
      "computing time\n",
      "0:01:39.850414\n",
      "generation time\n",
      "0:01:37.874629\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n",
      "\n",
      "\n",
      "iteration 1050\n",
      "physical reward: -870.4324\n",
      "prediction reward: -6.1808734\n",
      "vocabulary reward: -69.392075\n",
      "total reward: -911.30927\n",
      "--- Agent 0\n",
      "------ Mean distance 0.43980110389976274\n",
      "------ Median distance 0.19462053769891907\n",
      "------ Third quartile 0.33468411767255773\n",
      "------ Ninetieth percentile 1.1770732489352398\n",
      "------ max distance 3.358407550773409\n",
      "------ argmax distance 8\n",
      "--- Agent 1\n",
      "------ Mean distance 0.38603705732572363\n",
      "------ Median distance 0.1924930007055122\n",
      "------ Third quartile 0.29918099399548215\n",
      "------ Ninetieth percentile 0.6581509484919853\n",
      "------ max distance 3.557332889059912\n",
      "------ argmax distance 98\n",
      "computing time\n",
      "0:01:41.036146\n",
      "generation time\n",
      "0:01:39.065209\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.005\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1100\n",
      "physical reward: -850.38525\n",
      "prediction reward: -6.2730165\n",
      "vocabulary reward: -69.30433\n",
      "total reward: -891.3104\n",
      "--- Agent 0\n",
      "------ Mean distance 0.32959039787092237\n",
      "------ Median distance 0.17161633763637402\n",
      "------ Third quartile 0.26602882468409966\n",
      "------ Ninetieth percentile 0.5170322124426323\n",
      "------ max distance 3.2964014998766102\n",
      "------ argmax distance 21\n",
      "--- Agent 1\n",
      "------ Mean distance 0.4353502450832132\n",
      "------ Median distance 0.16947989300094107\n",
      "------ Third quartile 0.2501680862280042\n",
      "------ Ninetieth percentile 1.424748146063983\n",
      "------ max distance 3.388485824201633\n",
      "------ argmax distance 26\n",
      "computing time\n",
      "0:01:39.221153\n",
      "generation time\n",
      "0:01:37.240846\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n",
      "\n",
      "\n",
      "iteration 1150\n",
      "physical reward: -928.1039\n",
      "prediction reward: -6.1751018\n",
      "vocabulary reward: -69.28349\n",
      "total reward: -968.9207\n",
      "--- Agent 0\n",
      "------ Mean distance 0.42673018138945507\n",
      "------ Median distance 0.15925241992268505\n",
      "------ Third quartile 0.24224050744796316\n",
      "------ Ninetieth percentile 1.363669376726977\n",
      "------ max distance 3.342080865048622\n",
      "------ argmax distance 19\n",
      "--- Agent 1\n",
      "------ Mean distance 0.3813314835894313\n",
      "------ Median distance 0.178372765904793\n",
      "------ Third quartile 0.2884136063096477\n",
      "------ Ninetieth percentile 0.8092066590785729\n",
      "------ max distance 3.394292562480998\n",
      "------ argmax distance 63\n",
      "computing time\n",
      "0:01:40.588257\n",
      "generation time\n",
      "0:01:38.591914\n",
      "memory usage\n",
      "memory use: 0.7687301635742188\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.0\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-06409e79a080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-ea537ac1903a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0marray_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_utterances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_com\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphys_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp = Experiment()\n",
    "sess = tf.Session()\n",
    "exp.train(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iteration 46000\n",
    "-253.03172\n",
    "--- Agent 0\n",
    "------ Mean distance 0.3349107071033829\n",
    "------ Median distance 0.29547300157924467\n",
    "------ Third quartile 0.4377302665174422\n",
    "------ Ninetieth percentile 0.638775063507328\n",
    "------ max distance 0.8557159604403306\n",
    "------ argmax distance 39\n",
    "--- Agent 1\n",
    "------ Mean distance 0.3412405142027863\n",
    "------ Median distance 0.31892391108436546\n",
    "------ Third quartile 0.45355292453441526\n",
    "------ Ninetieth percentile 0.6242127385438654\n",
    "------ max distance 0.9072062760757306\n",
    "------ argmax distance 16\n",
    "computing time\n",
    "0:11:42.544759\n",
    "generation time\n",
    "0:11:41.076586\n",
    "memory usage\n",
    "memory use: 0.8258514404296875\n",
    "-- Stats word count:\n",
    "---- Mean number of word activated: 19.28\n",
    "---- Median number of word activated: 19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"env_history.pkl\", \"rb\") as openfile:\n",
    "    states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_ld = cPickle.load(openfile)\n",
    "\n",
    "    \n",
    "array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, pred = exp.arrays_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_stats_agent(array_states[-1, :, :, :], goal_locations, goal_types, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goal_locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dist_to_goal = compute_goal_dist(python_shuffle(array_states[-1, :, :, :],targets),  goal_locations, goal_types)\n",
    "#dist_to_goal = compute_goal_dist(python_shuffle(array_states[-1, :, :, :],targets),  v, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045466732914726"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 35, 37, 38, 40, 42, 44,\n",
       "        46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66,\n",
       "        68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 89, 90, 91, 92,\n",
       "        93, 95, 96, 99]),)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move = dist_to_goal[:, goal_types[0, 0, :] == 1]\n",
    "gaze = dist_to_goal[:, goal_types[0, 1, :] == 1]\n",
    "nothing = dist_to_goal[:, goal_types[0, 2, :] == 1]\n",
    "\n",
    "no_shuffle = dist_to_goal[:, targets[0, 0, :] == 0]\n",
    "shuffle = dist_to_goal[:, targets[1, 0, :] == 0]\n",
    "\n",
    "same_loc = dist_to_goal[:, (goal_locations[0, :, :] == goal_locations[1, :, :])[0, :]]\n",
    "diff_loc = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :]]\n",
    "\n",
    "diff_n_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]\n",
    "diff_not_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 1)]\n",
    "rest = dist_to_goal[:, ~(goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- rest:\n",
      "---- median:0.28894728041085926\n",
      "---- mean:0.3258696595982576\n",
      "---- max:0.8045466732914726\n",
      "---- third quartile:0.45485963684998665\n",
      "---- ninetieth percentile:0.6157374634030559\n",
      "\n",
      "\n",
      "- diff and shuffle:\n",
      "---- median:0.3432538725496517\n",
      "---- mean:0.35289259951391466\n",
      "---- max:0.8025584511627492\n",
      "---- third quartile:0.4681861486882135\n",
      "---- ninetieth percentile:0.5616923920176826\n",
      "\n",
      "\n",
      "- diff and not shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-01f18624306c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- median:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- mean:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- max:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- third quartile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- ninetieth percentile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "print(\"- rest:\")\n",
    "print(\"---- median:\" + str(np.median(rest)))\n",
    "print(\"---- mean:\" + str(np.mean(rest)))\n",
    "print(\"---- max:\" + str(np.max(rest)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(rest, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(rest, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_n_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_n_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_n_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_n_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_n_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and not shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_not_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_not_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_not_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_not_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_not_shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045466732914726"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- no_shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5c0e08e46e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- median:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- mean:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- max:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- third quartile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- ninetieth percentile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "print(\"- no_shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(no_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(no_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(no_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(no_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(no_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(shuffle)))\n",
    "print(\"---- max:\" + str(np.max(shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- move:\n",
      "---- median:0.33451158428247263\n",
      "---- mean:0.3453261763375307\n",
      "---- max:0.8045466732914726\n",
      "---- third quartile:0.4622149582380899\n",
      "---- ninetieth percentile:0.5934106536566446\n",
      "\n",
      "\n",
      "- gaze:\n",
      "---- median:nan\n",
      "---- mean:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5dc8361ef0c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- median:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- mean:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- max:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- third quartile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- ninetieth percentile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "print(\"- move:\")\n",
    "print(\"---- median:\" + str(np.median(move)))\n",
    "print(\"---- mean:\" + str(np.mean(move)))\n",
    "print(\"---- max:\" + str(np.max(move)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(move, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(move, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- gaze:\")\n",
    "print(\"---- median:\" + str(np.median(gaze)))\n",
    "print(\"---- mean:\" + str(np.mean(gaze)))\n",
    "print(\"---- max:\" + str(np.max(gaze)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(gaze, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(gaze, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- same loc:\n",
      "---- median:0.28894728041085926\n",
      "---- mean:0.3258696595982576\n",
      "---- max:0.8045466732914726\n",
      "---- third quartile:0.45485963684998665\n",
      "---- ninetieth percentile:0.6157374634030559\n",
      "\n",
      "\n",
      "- diff loc:\n",
      "---- median:0.3432538725496517\n",
      "---- mean:0.35289259951391466\n",
      "---- max:0.8025584511627492\n",
      "---- third quartile:0.4681861486882135\n",
      "---- ninetieth percentile:0.5616923920176826\n"
     ]
    }
   ],
   "source": [
    "print(\"- same loc:\")\n",
    "print(\"---- median:\" + str(np.median(same_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(same_loc)))\n",
    "print(\"---- max:\" + str(np.max(same_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(same_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(same_loc, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff loc:\")\n",
    "print(\"---- median:\" + str(np.median(diff_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_loc)))\n",
    "print(\"---- max:\" + str(np.max(diff_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_loc, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances[10, 0, :, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40567913, 0.56070427])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5934106536566446"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(dist_to_goal, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e58bbd5f5f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][-1, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-c5b16d5090f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][0, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:,:, 87].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1c1e03e4d0e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][:, 0, 0:2, 82].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-6df541d46d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "print_stats_agent(array_states[0][-1, :, :, :], goal_locations, goal_types)\n",
    "print_stats_agent(array_states[0][0, :, :, :], goal_locations, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-52c6ba3bf0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_array_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_goal_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "save_array_states = array_states\n",
    "save_goal_locations = goal_locations\n",
    "save_v = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21563244, 0.08816148])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-336f6c0b9b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "v[2, :, nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  [[0]\n",
      " [1]]\n",
      "first [0. 1. 0.]\n",
      "second [1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa5c0692550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: [ 2.5 -1. ]\n",
      "second: [-3. -3.]\n",
      "[[-0.25 -2.  ]\n",
      " [-0.25 -2.  ]]\n"
     ]
    }
   ],
   "source": [
    "nb = 21\n",
    "print(\"target \", targets[:, :, nb])\n",
    "print(\"first\", goal_types[0, :, nb])\n",
    "print(\"second\", goal_types[1, :, nb])\n",
    "plot_trajectory(array_states[:,1,0:2,nb], goal_locations[1, :, nb], v[0, :, nb])\n",
    "print(\"first:\", goal_locations[0, :, nb])\n",
    "print(\"second:\", goal_locations[1, :, nb])\n",
    "print(v[:, :, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0196078431372549"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_mem_last == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33333334, -0.6666667 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_states[-1, 2:, 0:2, 1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2. , 0.5], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_states[-1, 3:, 0:2, nb], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  4,  9, 12, 17, 23, 29, 40, 43, 48, 54, 55, 59, 79, 88, 95, 98]),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_types[0, 0, :] == 1) & (goal_types[1, 0, :] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e734a88a1110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = np.mean(goal_locations, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.tile(vv, (2, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2. , 0.5], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_states[0, 3:, 0:2, 1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-2e5bb8609410>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-2e5bb8609410>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    array_states.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "array_states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.843392, -7.008334], dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[-1, 0,0:2,nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.58468604,  3.1692955 ,\n",
       "         0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  1.3187793 , -0.6615655 ,\n",
       "         1.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58468605,  3.16929552],\n",
       "       [ 1.31877935, -0.66156551]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58468604,  3.1692955 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 1.3187793 , -0.6615655 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [-0.98659277, -3.7688777 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[-1, 2:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 100)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]], [[4 for i in range(100)], [4 for i in range(100)]], [[-2 for i in range(100)], [0 for i in range(100)]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2,  0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_landmarks[2, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goal_types = np.array([[[1 for i in range(100)], [0 for i in range(100)], [0 for i in range(100)]], [[1 for i in range(100)], [0 for i in range(100)], [0 for i in range(100)]], [[1 for i in range(100)], [0 for i in range(100)], [0 for i in range(100)]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 100)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f823f2da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.reward_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD9CAYAAABeOxsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICIiKBmIiAhKBiIiAvx/WSs0UkvVvTwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f0a20b278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.voc_reward_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wfkzT1TD/nKNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35bc342208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.mean_act_count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.98"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.mean_act_count[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00478059, 0.02923876],\n",
       "       [4.41817   , 4.4507103 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_outputs[-1, :, :, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.029627  , -0.61482185], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.reward_batch_history[-1][:, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.029627  , 0.61482184])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((array_outputs[-1, [0, 1], :, 50] - goal_locations[[0, 1], :, 50])**2, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.7789516, 1.2834195],\n",
       "       [4.017225 , 1.3816243]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_outputs[-1, :, :, :], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.sum(np.sum(array_outputs[-1, :, :, :], axis = 2), axis = 0)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.406772 , 4.3033895],\n",
       "       [8.583255 , 4.4507103]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(array_outputs[-1, :, :, :], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05605835, -0.26878864],\n",
       "       [-0.06561816, -0.35824925]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(array_outputs[-1, :, :, :], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.209854 , 1.8657004],\n",
       "       [3.2325075, 1.9222469]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(array_outputs[-1, :, :, :], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((goal_locations[:, 1, :] == 0).sum(axis = 1))/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7380105721219263"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plx = np.ones((2, 1, 100))*4\n",
    "ply = np.ones((2, 1, 100))*2.28\n",
    "pl = np.concatenate([plx, ply], axis = 1)\n",
    "np.mean(np.sum(np.sqrt(np.sum((pl - goal_locations)**2, axis = 1)), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.75172211500846"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plx = np.ones((2, 1, 100))*4\n",
    "ply = np.ones((2, 1, 100))*1.33\n",
    "pl = np.concatenate([plx, ply], axis = 1)\n",
    "np.mean(np.sum(np.sqrt(np.sum((pl - goal_locations)**2, axis = 1)), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.642781347408684"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plx = np.ones((3, 1))*4\n",
    "ply = np.ones((3, 1))*2.28\n",
    "pl = np.concatenate([plx, ply], axis = 1)\n",
    "np.mean(np.sqrt(np.sum((pl - array_states[-1, 2:, 0:2, 14])**2, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.700211538103295"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plx = np.ones((3, 1))*4\n",
    "ply = np.ones((3, 1))*1.33\n",
    "pl = np.concatenate([plx, ply], axis = 1)\n",
    "np.mean(np.sqrt(np.sum((pl - array_states[-1, 2:, 0:2, 14])**2, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_5:0' shape=(3, 2, 100) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.goal_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_reward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-89624fec0195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_reward' is not defined"
     ]
    }
   ],
   "source": [
    "pred_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.6263475 , -0.17130268],\n",
       "       [ 3.2847695 ,  3.8299196 ]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[-1, :, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [8, 0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = []\n",
    "for i in range(100):\n",
    "    length.append(len(np.unique(np.argmax(array_utterances[:, 0, :, i], axis = 1))))\n",
    "    length.append(len(np.unique(np.argmax(array_utterances[:, 1, :, i], axis = 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 2, 20, 100)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.argmax(array_utterances[:, 0, :, 10], axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn/j/QpC/Zucyp6wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fb45c0f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.mean_act_count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [8, 0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [8, 0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  3, 17, 17,  0,  3,  0,  3,  0,  0,  9,  0,  3,  3,  3,\n",
       "       18,  3,  0,  3,  0,  0,  0,  0,  3,  3,  3,  3,  7,  0,  0,  9,  0,\n",
       "        0,  3,  3,  3,  3,  0,  3,  3,  3,  3, 10,  9,  7,  3,  3, 15,  0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 0, :, 0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10,  0,  0,  0,  0,  3,  3,  9,  0,  0,  3, 13,  3,  0,  3,  0,\n",
       "        0,  3,  3,  3,  9,  0,  3,  9,  7,  9,  0,  3,  4,  4,  0,  3,  9,\n",
       "       14,  0,  3,  0,  0,  0,  3,  0,  0,  9,  3,  0,  0,  0,  3,  3,  3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 0, :, 2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  3,  3,  0,  0,  3,  0,  0,  0,  8,  0,  0,\n",
       "        0,  6,  3,  0,  0,  0,  0,  3,  0,  4,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0, 10,  0,  0,  0,  3,  0,  0,  3,  3,  0,  0,  0,  3])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 1, :, 5], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.voc_reward_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  4,  6,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18, 19])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 15, 18])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, 0, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 15, 18])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, 1, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  9, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, 0, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  5,  9, 10, 18, 19])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, 1, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       [[17,  5,  5, ..., 12,  6,  5],\n",
       "        [ 6,  5,  6, ...,  5,  6,  2]],\n",
       "\n",
       "       [[ 6,  5, 19, ..., 18,  2,  5],\n",
       "        [ 6,  5, 17, ...,  5,  6, 18]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[11,  9,  0, ...,  8,  6,  5],\n",
       "        [ 6,  5,  6, ...,  5,  6,  9]],\n",
       "\n",
       "       [[19, 19, 19, ...,  9, 19,  5],\n",
       "        [ 6,  7,  6, ...,  5,  6,  6]],\n",
       "\n",
       "       [[16,  5, 11, ..., 14,  6,  5],\n",
       "        [ 6,  5,  6, ...,  5,  2, 19]]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-319-33829bdaa630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'array_pred' is not defined"
     ]
    }
   ],
   "source": [
    "array_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.823529411764707"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.6868453e-04,  9.9153298e-01, -2.8760213e-02,  3.8191910e+00,\n",
       "        4.0793910e+00,  5.5776936e-01,  5.0881344e-01,  3.6988370e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[-1, 1, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 4., 4., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[1, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e-04,\n",
       "       0.000e+00, 0.000e+00, 3.940e-01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "       3.432e-01, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e-04, 2.626e-01,\n",
       "       0.000e+00, 0.000e+00], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(exp.array_utt[-1], axis = (0, 1, 3))/np.sum(exp.array_utt[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.00e+00, 3.00e+00, 2.00e+00, 8.00e+00, 4.00e+00, 7.00e+00,\n",
       "       2.00e+00, 6.20e+01, 3.00e+01, 1.00e+00, 9.81e+03, 1.10e+01,\n",
       "       0.00e+00, 1.00e+01, 1.20e+01, 4.00e+00, 1.20e+01, 6.00e+00,\n",
       "       5.00e+00, 4.00e+00], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(exp.array_utt[-23], axis = (0, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.24"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.mean_act_count[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-661.3527"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.reward_history[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.Variable(np.sum(exp.array_utt[-3], axis = (0, 1, 3)))\n",
    "u = tf.gather(v, tf.where(tf.not_equal(v, 0)))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    ee = sess.run(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.000e+00],\n",
       "       [8.000e+00],\n",
       "       [4.220e+03],\n",
       "       [5.000e+00],\n",
       "       [5.000e+00],\n",
       "       [4.000e+00],\n",
       "       [1.800e+01],\n",
       "       [5.000e+00],\n",
       "       [1.410e+03],\n",
       "       [6.000e+00],\n",
       "       [6.000e+00],\n",
       "       [2.000e+00],\n",
       "       [5.000e+00],\n",
       "       [3.000e+00],\n",
       "       [5.900e+01],\n",
       "       [7.000e+00],\n",
       "       [7.000e+00],\n",
       "       [2.117e+03],\n",
       "       [2.106e+03]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp.voc_reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.00000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  7,  7,  7,  8, 15,  8,  8,  8, 15,  8,  8,  7,  7, 15, 15, 15,\n",
       "        8,  7,  7,  7,  8, 15,  7,  7,  7,  8,  8,  8, 15,  8,  7,  8,  7,\n",
       "        7, 15,  7,  7,  8,  7, 15,  8, 15,  8,  8,  8,  7, 15,  7,  8,  7,\n",
       "        8,  7, 15,  8,  7,  7, 15,  8, 15,  8, 15,  8,  8,  7,  7,  8,  8,\n",
       "        7,  8, 15, 15,  8, 15,  8,  7,  7, 15,  7,  8,  8, 15, 15, 15,  7,\n",
       "       15,  7,  7, 15,  7, 15,  8,  8,  7, 15, 15, 15,  8,  7,  8,  8,  8,\n",
       "        8,  7, 15, 15, 15,  8,  7, 15,  7, 15,  7,  8,  8,  8,  7, 15,  7,\n",
       "       15, 15,  7,  8,  8,  8, 15, 15, 15, 15,  7,  7, 15,  7, 15,  8,  8,\n",
       "        8, 15,  8, 15, 15,  8,  8,  8,  7, 15,  7, 15,  7,  8,  8, 15,  7,\n",
       "        7,  8,  7,  7, 15,  7,  8,  8,  7,  7, 15,  7,  8,  8,  7,  7, 15,\n",
       "       15,  8, 15,  7,  7,  8,  7,  8, 15, 15,  7, 15,  7, 15,  8, 15,  8,\n",
       "       15,  8, 15,  8,  8,  8, 15,  7, 15,  7,  7,  7, 15,  8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances, axis = 2)[:, 0, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.57926386,  1.09727604],\n",
       "       [-1.57926386,  1.09727604]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.48238987, 0.9266134 ,\n",
       "        1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.45202035, 1.5437603 ,\n",
       "        0.        , 1.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.grads_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = tf.Variable(0.0)\n",
    "init = tf.global_variables_initializer()\n",
    "v = tf.log(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    ee = sess.run(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.631021115928547"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 2 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-8d5de4502d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgoal_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 2 with size 100"
     ]
    }
   ],
   "source": [
    "goal_types[:, :, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 13, 16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances[1:, :, :, :], axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "landmark_nb = [np.random.choice(3, (2, 1), replace = True) for _ in range(FLAGS.batch_size)]\n",
    "landmark_nb_batch = np.stack(landmark_nb, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_nb[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, 3:6, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20028409, -0.96775521],\n",
       "       [ 0.86976883,  0.97217373]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10546685, -0.38599977,  0.        ,  0.        ,  1.4818624 ,\n",
       "        -0.6813463 ,  1.        ,  0.        ,  0.        ],\n",
       "       [-0.23637994,  0.06048546,  0.        ,  0.        ,  1.9055567 ,\n",
       "         1.469917  ,  0.        ,  1.        ,  0.        ],\n",
       "       [-0.2568565 , -0.13294637,  0.        ,  0.        , -1.2636497 ,\n",
       "        -0.06211003,  0.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0, 2:, :, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  5,  3, 13,  3,  2, 13, 13, 13, 13,  2, 13,  2,  3,  3, 13,\n",
       "       13,  3,  3, 13,  2,  3, 13,  3,  2,  3, 13,  3,  2, 13,  3,  3,  3,\n",
       "        2,  3,  3,  2,  3,  2,  2,  3,  3, 13,  3,  3,  2, 13,  3, 13,  2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 1, :, 2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 0. , 1.5, 2. , 0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. , 1.5, 2. , 1. , 0. , 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5, -0.5],\n",
       "       [-1. , -1. ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5, -0.5],\n",
       "       [-1. , -1. ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ,  0. ,  1.5, -0.5,  0. ,  1. ,  0. ],\n",
       "       [ 0. ,  1. ,  0. , -1. , -1. ,  1. ,  0. ,  0. ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, : ,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.0697347e-03,  1.0513390e+00,  2.2460965e-02,  2.4765704e+00,\n",
       "        -1.0961896e+00,  5.0263029e-01,  4.7486654e-01, -3.6538243e-03],\n",
       "       [-4.0758252e-03,  1.0102042e+00, -2.4224397e-02, -3.0727093e+00,\n",
       "        -3.0304856e+00,  5.5312365e-01,  4.2007229e-01,  2.5203116e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[-1, :, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ,  0. ,  0. ],\n",
       "       [-1. , -1. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ,  0. ],\n",
       "       [ 1.5, -0.5,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[-1, 2:, :, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ,  0. ,  2.5, -1. ,  0. ,  1. ,  0. ],\n",
       "       [ 1. ,  0. ,  0. , -3. , -3. ,  1. ,  0. ,  0. ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 1, :, 19], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
