{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from datetime import datetime\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "#%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "#0.0008\n",
    "flags.DEFINE_float('learning_rate', 0.0008, 'Initial learning rate.')#0.0008\n",
    "flags.DEFINE_integer('max_steps', 20000, 'Number of iteration to train.')\n",
    "flags.DEFINE_integer('number_layers', 3, 'Number of layers in each network')\n",
    "flags.DEFINE_integer('layer_sizes', 256, 'Number of units in hidden layer.')\n",
    "flags.DEFINE_integer('batch_size', 100, 'Batch size.')#100\n",
    "flags.DEFINE_integer('dim_env', 2, 'dimension of the environment')\n",
    "flags.DEFINE_integer('number_goal_types', 3, 'number of different goal types')\n",
    "flags.DEFINE_integer('color_size', 3, 'number of components of the color: RGB as usual')\n",
    "flags.DEFINE_integer(\"output_size\", 256, \"number of units in the output layer\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.9, \"Dropouts rate of keeping\")\n",
    "flags.DEFINE_boolean(\"xav_init\", False,\"Distribution of initialization: False for normal, True for uniform\" )\n",
    "flags.DEFINE_integer(\"number_agents\", 2, \"Number of agents in the environment\")\n",
    "flags.DEFINE_integer(\"number_landmarks\", 3, \"Number of landmarks in the environment\")\n",
    "flags.DEFINE_integer(\"vocabulary_size\", 20, \"Size of the vocabulary\")\n",
    "flags.DEFINE_integer(\"mem_size\", 32, \"Size of the communication network's memory\")\n",
    "flags.DEFINE_integer(\"last_mem_size\", 32, \"Size of the last network's memory\")\n",
    "flags.DEFINE_float(\"gumbel_temperature\", 1, \"Temperature use for the gumbel softmax trick\")\n",
    "flags.DEFINE_float(\"sddev_phys_sampling\", 0.0001, \"Standard deviation used to sample the velocity and gaze output\")\n",
    "flags.DEFINE_float(\"delta_t\", 0.5, \"delta of time between timesteps\")#0.5\n",
    "flags.DEFINE_float(\"damping_coef\", 0.5, \"damping coefficient for the new velocity computation\")\n",
    "flags.DEFINE_float(\"stddev_memory\", 0.0001, \"standard deviation of the gaussian used to update memories\")\n",
    "flags.DEFINE_integer(\"bound\", 5, \"Bounds of generation of initial positions, centered in 0.\")#5 usually\n",
    "flags.DEFINE_integer(\"time_horizon\", 50, \"Number of timestep before the end of the experiment.\")#50\n",
    "flags.DEFINE_integer(\"print_frequency\", 50, \"Frequency at which we print the reward, in number of steps.\")#500\n",
    "flags.DEFINE_boolean(\"learning_rate_decay\", True, \"Wether to use a piecewise learning rate decay or no decay at all\")#True\n",
    "flags.DEFINE_integer(\"tensorboard_freq\", 2000, \"Frequency at which we save the statistics in tensorflow\")#500\n",
    "flags.DEFINE_float(\"alpha_dirichlet\", 0, \"Probability of seeing an out of vocabulary word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire:\n",
    "\n",
    "- Checker que le softmax pooling est correct\n",
    "\n",
    "- Checker que le gumbel trick est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le sampling physique est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le calcul du nouvel état est correct, notamment sur les débuts et longueur de slicing et concaténation\n",
    "\n",
    "- Ajouter le calcul des forces dans le calcul du nouvel état\n",
    "\n",
    "- Vérifier que le shuffling est correct\n",
    "\n",
    "- Vérifier que le calcul du reward est correct\n",
    "\n",
    "- Vérifier que la backprop considère bien les variables broadcastées comme les mêmes.\n",
    "\n",
    "- Vérifier que le tenseur states est bien dans cet ordre sur le second axe: position, velocité, gaze, couleurs\n",
    "\n",
    "- RELIER LES LANDMARKS AUX POSITIONS DES GOALS, SINON CA N A PAS DE SENS !!!\n",
    "\n",
    "- Checker que les goals types sont bien distribués: une unique coordonnée doit être 1, les autres 0, et ce pour chaque agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory():\n",
    "    import os\n",
    "    import psutil\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "    print('memory use:', memoryUse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_trajectory(coordinates, target_point, middle_point):\n",
    "    x = coordinates[1:-1, 0]\n",
    "    y = coordinates[1:-1, 1]\n",
    "    \n",
    "    x_start = coordinates[0, 0]\n",
    "    y_start = coordinates[0, 1]\n",
    "    \n",
    "    x_final = coordinates[-1, 0]\n",
    "    y_final = coordinates[-1, 1]\n",
    "    \n",
    "    x_target, y_target = target_point\n",
    "    x_middle, y_middle = middle_point\n",
    "    \n",
    "    plt.plot(x,y, \"o\")\n",
    "    plt.plot(x_start, y_start, 'ro')\n",
    "    plt.plot(x_target, y_target, 'go')\n",
    "    plt.plot(x_final, y_final, 'yo')\n",
    "    plt.plot(x_middle, y_middle, 'mo')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5, 5])\n",
    "    axes.set_ylim([-5, 5])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def python_shuffle(positions, shuffle_indexes):\n",
    "    shuffled_array = np.stack(\n",
    "    [positions[shuffle_indexes[: , 0, i], :, i] for i in range(FLAGS.batch_size)], axis = 2)\n",
    "    return shuffled_array\n",
    "    \n",
    "    \n",
    "def delete_history_files():\n",
    "    if os.path.isfile(\"env_history.pkl\"):\n",
    "        os.remove(\"env_history.pkl\")\n",
    "        \n",
    "    if os.path.isfile(\"arrays_history.pkl\"):\n",
    "        os.remove(\"arrays_history.pkl\")\n",
    "        \n",
    "    if Path(\"Summary\").is_dir():\n",
    "        shutil.rmtree(\"Summary\")\n",
    "\n",
    "\n",
    "def print_stat_vocabulary(utterances_array, l):\n",
    "    x = np.argmax(utterances_array, axis = 2)\n",
    "    r = []\n",
    "    for i in range(FLAGS.batch_size):\n",
    "        #r.append(len(np.unique(x[:, :, i])))\n",
    "        r.append(len(np.unique(x[:, 0, i])))\n",
    "        r.append(len(np.unique(x[:, 1, i])))\n",
    "    \n",
    "    if l%FLAGS.print_frequency == 0:\n",
    "        print(\"-- Stats word count:\")\n",
    "        print(\"---- Mean number of word activated: \" + str(np.mean(r)))\n",
    "        print(\"---- Median number of word activated: \" + str(np.median(r)))\n",
    "        print(\"---- Total number of word activated: \" + str(len(np.unique(x))))\n",
    "        \n",
    "    return np.mean(r)\n",
    "    \n",
    "        \n",
    "def dirichlet_log_lik_end(utterances_array):\n",
    "    #Note: we don't take minus the log-likelihood as we minimize minus the entire reward then !\n",
    "    by_symbol = tf.reduce_sum(utterances_array, axis =[0, 1, 3])\n",
    "    total_nb_uttered = FLAGS.number_agents*FLAGS.time_horizon*FLAGS.batch_size\n",
    "    #total_nb_uttered = tf.reduce_sum(utterances_array)\n",
    "    ratio = by_symbol/(FLAGS.alpha_dirichlet + total_nb_uttered - 1)\n",
    "    tiled_ratios = tf.tile(tf.reshape(ratio, [1, 1, FLAGS.vocabulary_size, 1]), [FLAGS.time_horizon, FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    #log_likelihood = tf.reduce_sum(tf.gather_nd(tf.log(tiled_ratios), tf.where(tf.equal(utterances_array, 1))))\n",
    "    terms = tf.multiply(tf.stop_gradient(tf.log(tf.clip_by_value(ratio, 1e-10, 1e+10))),by_symbol)\n",
    "    log_likelihood = tf.reduce_sum(terms)\n",
    "    #log_likelihood = tf.Print(log_likelihood, [log_likelihood])\n",
    "    return log_likelihood/FLAGS.batch_size\n",
    "    \n",
    "    \n",
    "# Param: x, stacking of the output of fully connected physical network for each agent. Shape = (256, batch_size, nb_agents)\n",
    "# return: pooling of input features.\n",
    "def softmax_pooling(x):\n",
    "    # pooling function. Softmax pooling is a compromise between max pooling and average pooling\n",
    "    coefs = tf.nn.softmax(x, dim = 0)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = 0)\n",
    "    return softmax_pool\n",
    "\n",
    "\n",
    "def activation_function(x):\n",
    "    return tf.nn.elu(x)\n",
    "\n",
    "\n",
    "def gumbel_max_trick(x, hard = True):\n",
    "    # Application of gumbel-softmax trick\n",
    "    # Input: output of the last network \n",
    "    u = -tf.log(-tf.log(tf.random_uniform(shape = [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size],\n",
    "                                          dtype=tf.float32)))\n",
    "    utterance_output = tf.slice(x, [0, 2*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "    gumbel = tf.exp((utterance_output + u)/FLAGS.gumbel_temperature)\n",
    "    denoms = tf.reshape(tf.reduce_sum(gumbel, axis = 1), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    utterance = gumbel/denoms\n",
    "    if hard:\n",
    "        idx_utt = tf.argmax(utterance, axis = 1)\n",
    "        utt_hard = tf.transpose(tf.one_hot(idx_utt, depth = FLAGS.vocabulary_size), [0, 2, 1])\n",
    "        utterance = tf.stop_gradient(utt_hard - utterance) + utterance\n",
    "        \n",
    "    return utterance \n",
    "\n",
    "\n",
    "def sample_phys(x):\n",
    "    #Input: output of the last network.\n",
    "    #Output: sampled values for new velocity and gaze\n",
    "    u = tf.random_normal(shape = [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size],dtype=tf.float32,\n",
    "                         stddev = FLAGS.sddev_phys_sampling)\n",
    "    o = tf.add(tf.slice(x, [0, 0, 0], [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size]), u)\n",
    "    sample_move = tf.slice(o, [0, 0, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    sample_gaze  = tf.slice(o, [0, FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    return sample_move, sample_gaze\n",
    "\n",
    "\n",
    "def compute_new_states(old_states, new_velocities, new_delta_gazes, new_utterances):\n",
    "    #Computes the new states according to the equations of the papers.\n",
    "    # Input: the old states of shape [number agents + nb_landmarks, 3*env dim + color size, batch size] because color is in state\n",
    "    # and of shape [number_agents, 2*env_dim, batch size]\n",
    "    # Adding the outputs of landmark, which are all zeros.\n",
    "    #new_velocities = tf.concat([new_velocities, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "\n",
    "    #new_delta_gazes = tf.concat([new_delta_gazes, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "    \n",
    "    #old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #new_pos = tf.slice(old_states, [0, 0, 0], \n",
    "    #                   [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    #new_gazes = old_gazes + new_delta_gazes*FLAGS.delta_t\n",
    "    \n",
    "    #new_velocity = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    \n",
    "    old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents , FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    new_pos_agents = tf.slice(old_states, [0, 0, 0], \n",
    "                       [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    new_pos_landmarks = tf.slice(old_states, [FLAGS.number_agents, 0, 0], \n",
    "                       [FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_pos = tf.concat([new_pos_agents, new_pos_landmarks], axis = 0)\n",
    "    \n",
    "    new_gazes_agents = old_gazes + new_delta_gazes*FLAGS.delta_t*FLAGS.delta_t\n",
    "    new_gazes_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_gazes = tf.concat([new_gazes_agents, new_gazes_landmarks], axis = 0)\n",
    "    \n",
    "    new_velocity_agents = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    new_velocity_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_velocity = tf.concat([new_velocity_agents, new_velocity_landmarks], axis = 0)\n",
    "    \n",
    "    colors = tf.slice(old_states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                            FLAGS.color_size, FLAGS.batch_size])\n",
    "    \n",
    "    new_pos = tf.zeros([5, 2, 100])\n",
    "    new_velocity = tf.zeros([5, 2, 100])\n",
    "    new_states = tf.concat([new_pos, new_velocity, new_gazes, colors], axis = 1)\n",
    "\n",
    "    return new_states, new_pos, new_gazes\n",
    "\n",
    "\n",
    "\n",
    "def compute_new_memories(old_mem_com, old_mem_last, delta_mem_com, delta_mem_last):\n",
    "    new_memory_com = tf.tanh((2/3)*(old_mem_com + delta_mem_com + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    new_memory_last = tf.tanh((2/3)*(old_mem_last + delta_mem_last + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                   FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    \n",
    "    #new_memory_com = tf.zeros([FLAGS.number_agents, 32, FLAGS.batch_size])\n",
    "    #new_memory_last = tf.zeros([FLAGS.number_agents, 32, FLAGS.batch_size])\n",
    "    return new_memory_com,new_memory_last\n",
    "\n",
    "\n",
    "\n",
    "def shuffle(x, name_targets, colors = False, goal = False):\n",
    "    slices_second_dim = []\n",
    "    ones = tf.ones([FLAGS.number_agents, 1, FLAGS.batch_size], tf.int32)\n",
    "    batch_num = tf.tile(tf.reshape(tf.range(0, FLAGS.batch_size, dtype = tf.int32), [1, 1, FLAGS.batch_size]), [FLAGS.number_agents,\n",
    "                                                                                                               1, 1])\n",
    "    if (not colors) and (not goal):\n",
    "        for i in range(FLAGS.dim_env):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "    if colors:\n",
    "        for i in range(FLAGS.color_size):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "            \n",
    "    if goal:\n",
    "        for i in range(2):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))   \n",
    "    \n",
    "            \n",
    "    gathering_tensor = tf.transpose(tf.concat(slices_second_dim, axis = 1), perm = [0, 1, 3, 2])\n",
    "    shuffled_x = tf.gather_nd(x, gathering_tensor)\n",
    "    \n",
    "    return shuffled_x\n",
    "    \n",
    "    \n",
    "def compute_reward(positions, gazes, outputs, utterances, name_targets, goals_loc, goals_types):\n",
    "    shuffled_positions = shuffle(positions, name_targets)\n",
    "    shuffled_gazes = shuffle(gazes, name_targets)\n",
    "\n",
    "    pos_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_positions - goals_loc)), axis = 1), [FLAGS.number_agents, 1, \n",
    "                                                                                                     FLAGS.batch_size])\n",
    "\n",
    "    gaze_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_gazes - goals_loc)), axis = 1), [FLAGS.number_agents, 1,\n",
    "                                                                                                     FLAGS.batch_size])\n",
    "    zeros = tf.zeros([FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    x = tf.concat([pos_distances, gaze_distances, zeros], axis = 1)\n",
    "\n",
    "    dists_goal = -tf.reduce_sum(tf.multiply(x, goals_types), axis = 1)\n",
    "    \n",
    "    utterances_term = -tf.reduce_sum(tf.square(utterances), axis = 1)\n",
    "   # utterances_term = -tf.reduce_sum(tf.square(tf.slice(utterances, [0, 1, 0], [FLAGS.number_agents, (FLAGS.vocabulary_size-1), FLAGS.batch_size])), axis = 1)\n",
    "    output_term = -tf.reduce_sum(tf.square(outputs), axis = 1)\n",
    "    \n",
    "    reward_by_batch = tf.reshape(tf.reduce_sum(dists_goal + utterances_term + output_term, axis = 0), [FLAGS.batch_size, 1])\n",
    "\n",
    "    return reward_by_batch\n",
    "\n",
    "\n",
    "\n",
    "def compute_goal_dist(states, goal_location, goal_type):\n",
    "    dist_positions = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 0:2, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    dist_gazes = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 4:6, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    v = np.concatenate([dist_positions, dist_gazes, np.zeros((FLAGS.number_agents, 1, FLAGS.batch_size))], axis = 1)\n",
    "    goal_distances = np.sum(np.multiply(v, goal_type), axis = 1)\n",
    "    \n",
    "    return goal_distances\n",
    "\n",
    "\n",
    "def print_stats_agent(states, goal_location, goal_type, targets):\n",
    "    #Only considering non \"do nothing goals\"\n",
    "    shuffled_states = python_shuffle(states, targets)\n",
    "    goal_distances = compute_goal_dist(shuffled_states, goal_location, goal_type)\n",
    "    \n",
    "    for i in range(FLAGS.number_agents):\n",
    "        distances_agents = goal_distances[i, :]\n",
    "        goal_wo_zeros = distances_agents[distances_agents != 0]\n",
    "        mean = np.mean(goal_wo_zeros)\n",
    "        median = np.median(goal_wo_zeros)\n",
    "        third_quart = np.percentile(goal_wo_zeros, 75)\n",
    "        nine_pct = np.percentile(goal_wo_zeros, 90)\n",
    "        max_dist = np.max(distances_agents)\n",
    "        argmax = np.argmax(distances_agents)\n",
    "        print(\"--- Agent \" + str(i))\n",
    "        print(\"------ Mean distance \" + str(mean))\n",
    "        print(\"------ Median distance \" + str(median))\n",
    "        print(\"------ Third quartile \" + str(third_quart))\n",
    "        print(\"------ Ninetieth percentile \" + str(nine_pct))\n",
    "        print(\"------ max distance \" + str(max_dist))\n",
    "        print(\"------ argmax distance \" + str(argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the physical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 3*FLAGS.dim_env + FLAGS.color_size\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, number of inputs]\n",
    "        #This shape enables us to handle all the agents/landmarks states at once, instead of dealing with list of agents' states\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                               # [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                                #[FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                                #[FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.layer_sizes, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                                #[FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.output_size, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [1 + FLAGS.number_landmarks, 1, 1])\n",
    "                                #[FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): \n",
    "        # Compute a forward pass through the network\n",
    "        # Input: a tensor of shape [number of agents, size of input, batch _size]\n",
    "        # Output: a tensor of shape [number of agents, output_size, batch_size]\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "                else:\n",
    "                    x = activation_function(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the communication network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CommunicationNet: \n",
    "    \n",
    "    def __init__(self):    \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"com_memory_read_weight\", shape = [1, FLAGS.output_size, FLAGS.mem_size],\n",
    "                                               initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        self.def_pred_layer()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, vocabulary size]\n",
    "        #This shape enables us to handle all the agents utterances at once, instead of dealing with list of agents' states        \n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.vocabulary_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.output_size, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])  \n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        # Initialization of the weights and biases writing in the memory.\n",
    "        # Their shape are of the form [number of agents, memory_size, output size] and [number of agents, output size, 1]\n",
    "        # So that we can handle the memories of all agents at onces instead of dealing with list of memories.\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_com\" , shape=[1, FLAGS.mem_size,FLAGS.output_size],\n",
    "                            initializer=tf.orthogonal_initializer()), \n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_com\", shape = [1, FLAGS.mem_size, 1],\n",
    "                            initializer=tf.orthogonal_initializer()),\n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "      \n",
    "    def def_pred_layer(self):\n",
    "        self.W_pred = tf.tile(tf.get_variable(\"weight_pred_com\" , shape=[1, FLAGS.number_goal_types + FLAGS.dim_env + 3,FLAGS.output_size],\n",
    "                            initializer=tf.orthogonal_initializer()), \n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        self.b_pred = tf.tile(tf.get_variable(\"bias_pred_com\", shape = [1, FLAGS.number_goal_types + FLAGS.dim_env + 3, 1],\n",
    "                            initializer=tf.orthogonal_initializer()),\n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        predicted_goal = tf.matmul(self.W_pred, x) + self.b_pred\n",
    "        return x, delta_mem, predicted_goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LastNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 2*FLAGS.output_size + FLAGS.color_size + FLAGS.number_goal_types + FLAGS.dim_env\n",
    "        #self.input_size = 2*FLAGS.output_size + FLAGS.color_size + FLAGS.number_goal_types + FLAGS.number_landmarks\n",
    "        self.output_size = 2*FLAGS.dim_env + FLAGS.vocabulary_size\n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"reading_last_mem_weight\", shape = [1, self.output_size, FLAGS.last_mem_size],\n",
    "                                              initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, self.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    #W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, 2, FLAGS.layer_sizes],\n",
    "                    #                    initializer=tf.orthogonal_initializer()),\n",
    "                    #            [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, self.output_size, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    #B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, 2, 1], \n",
    "                    #                    initializer=tf.orthogonal_initializer()),\n",
    "                    #            [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_last\", shape=[1, FLAGS.last_mem_size ,self.output_size],\n",
    "                                initializer=tf.orthogonal_initializer()),\n",
    "                                 [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_last\" ,shape = [1, FLAGS.last_mem_size, 1], \n",
    "                                    initializer=tf.orthogonal_initializer()),\n",
    "                                  [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "               \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        \n",
    "        return x , delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the policy: putting all the networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.phys_network = PhysicalNet()\n",
    "        self.comm_network = CommunicationNet()\n",
    "        self.last_network = LastNet()\n",
    "        \n",
    "        self.define_placeholders()\n",
    "        self.define_full_goals()\n",
    "        \n",
    "        \n",
    "    def define_placeholders(self):\n",
    "        self.states = tf.placeholder(tf.float32, [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                  3*FLAGS.dim_env + FLAGS.color_size, FLAGS.batch_size])\n",
    "        self.utterances = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "        self.memories_com = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size])\n",
    "        self.memories_last = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size])\n",
    "        self.goal_types = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.number_goal_types, FLAGS.batch_size])\n",
    "        self.goal_locations = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        #self.which_landmarks = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.number_landmarks, FLAGS.batch_size])\n",
    "        self.name_targets = tf.placeholder(tf.int32, [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "        #self.colors = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        \n",
    "        \n",
    "    def define_full_goals(self):\n",
    "        colors = tf.slice(self.states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        shuffled_colors = shuffle(colors, self.name_targets, colors = True)\n",
    "        #shuffled_goal_loc = shuffle(self.goal_locations, self.name_targets, colors = False, goal = True)\n",
    "        #self.full_goals = tf.concat([self.goal_types, self.goal_locations, shuffled_colors], axis = 1)\n",
    "        #shuffled_colors = tf.zeros([FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        self.full_goals = tf.concat([self.goal_types, self.goal_locations, shuffled_colors], axis = 1)\n",
    "        #self.full_goals = tf.concat([self.goal_types, self.which_landmarks, shuffled_colors], axis = 1)\n",
    "\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.states, self.utterances, self.memories_com, self.memories_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets]#, self.which_landmarks]\n",
    "        \n",
    "    def forward_pass(self, states, utterances, mem, mem_last, goals_last):\n",
    "        #Step 1: processing observed states and utterances\n",
    "        \n",
    "        soft_outputs_phys = []\n",
    "        for i in range(FLAGS.number_agents):\n",
    "            st_agent = tf.slice(states, [i, 0, 0], [1, FLAGS.dim_env*3+FLAGS.color_size, FLAGS.batch_size])\n",
    "            st_landmarks = tf.slice(states, [FLAGS.number_agents, 0, 0], [FLAGS.number_landmarks, FLAGS.dim_env*3+FLAGS.color_size, FLAGS.batch_size])\n",
    "            st = tf.concat([st_agent, st_landmarks], axis = 0)\n",
    "            softmax_output = softmax_pooling(self.phys_network.compute_output(st))\n",
    "            soft_outputs_phys.append(tf.reshape(softmax_output, [1, FLAGS.output_size, FLAGS.batch_size]))\n",
    "            \n",
    "            \n",
    "        comm_output, new_mem_com, predicted_goal = self.comm_network.compute_output(utterances, mem)\n",
    "        \n",
    "        #Step 2: softmax pooling the results [num_agents, output size, batch_size] --> [1, output size, batch_size]\n",
    "        #PhiX = softmax_pooling(phys_output)\n",
    "        PhiX_last = tf.concat(soft_outputs_phys, axis = 0)\n",
    "        PhiC = softmax_pooling(comm_output)\n",
    "        \n",
    "        #PhiX = tf.Print(PhiX_last, [tf.reduce_sum(tf.cast(tf.is_nan(PhiX_last), tf.float32)), \"PhiX\"])\n",
    "        #PhiC = tf.Print(PhiC, [tf.reduce_sum(tf.cast(tf.is_nan(PhiC), tf.float32)), \"PhiC\"])\n",
    "        \n",
    "        #Step 3: feeding the last network      \n",
    "        #PhiX_last = tf.tile(tf.reshape(PhiX, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        PhiC_last = tf.tile(tf.reshape(PhiC, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        #input_last = tf.concat([PhiX_last, goals_last, PhiC_last], axis = 1)\n",
    "        input_last = tf.concat([PhiX_last, goals_last, PhiC_last], axis = 1)\n",
    "        \n",
    "        output_last, new_mem_last = self.last_network.compute_output(input_last, mem_last)\n",
    "        #output_last = self.last_network.compute_output(input_last, mem_last)\n",
    "        velocities_output, gazes_output = sample_phys(output_last)\n",
    "        utterances_output = gumbel_max_trick(output_last)\n",
    "        phys_output = tf.concat([velocities_output, gazes_output], axis = 1)\n",
    "        \n",
    "        return phys_output, velocities_output, gazes_output, utterances_output, new_mem_com, new_mem_last, predicted_goal\n",
    "        #return output_last\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.enc = OneHotEncoder(n_values=FLAGS.number_goal_types, sparse=False)\n",
    "        self.colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)] \n",
    "        self.cols, self.cols_agents, self.cols_landmarks = self.create_colors()\n",
    "        self.colors_ld = np.stack([np.eye(FLAGS.number_landmarks) for i in range(FLAGS.batch_size)], axis = 2)\n",
    "    \n",
    "    \n",
    "    def create_colors(self):\n",
    "        cols_agents = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_agents)], axis = 0)\n",
    "        cols_landmarks = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_landmarks)], axis = 0)\n",
    "        \n",
    "        cols = np.concatenate([cols_agents, cols_landmarks], axis = 0)\n",
    "            \n",
    "        return cols, cols_agents, cols_landmarks\n",
    "            \n",
    "        \n",
    "    def create_consistent_targets(self):\n",
    "        #targets_by_exp = [np.random.choice(FLAGS.number_agents, (FLAGS.number_agents, 1), replace = False) for _ in range(FLAGS.batch_size)]\n",
    "        targets_by_exp = [np.array([[1], [0]]) for _ in range(FLAGS.batch_size)]\n",
    "        targets_batch = np.stack(targets_by_exp, axis = 2)\n",
    "        return targets_batch\n",
    "    \n",
    "    def create_goal_locations(self, pos_landmarks):\n",
    "        landmark_nb = [np.random.choice(FLAGS.number_landmarks, (FLAGS.number_agents, 1), replace = True) for _ in range(FLAGS.batch_size)]\n",
    "        landmark_nb_batch = np.stack(landmark_nb, axis = 2)\n",
    "        \n",
    "        goal_loc = python_shuffle(pos_landmarks, landmark_nb_batch)\n",
    "        which_landmark = python_shuffle(self.colors_ld, landmark_nb_batch)\n",
    "        \n",
    "        return goal_loc, which_landmark\n",
    "        \n",
    "        \n",
    "    def random_generation(self):\n",
    "        positions_agents = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        #positions_agents = np.array([[[1 for i in range(100)], [1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        \n",
    "        #positions_landmarks = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_landmarks, \n",
    "        #                                                          FLAGS.dim_env, FLAGS.batch_size))\n",
    "        positions_landmarks = np.array([[[-3 for i in range(FLAGS.batch_size)], [-3 for i in range(FLAGS.batch_size)]], [[ 2.5 for i in range(FLAGS.batch_size)], [-1 for i in range(FLAGS.batch_size)]], [[1.5 for i in range(FLAGS.batch_size)], [2 for i in range(FLAGS.batch_size)]]])\n",
    "        #positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]], [[4 for i in range(100)], [4 for i in range(100)]]])\n",
    "\n",
    "\n",
    "        positions = np.concatenate([positions_agents, positions_landmarks], axis = 0)\n",
    "        \n",
    "        gazes = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        #gazes_agents = np.array([[[1 for i in range(100)], [1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        #gazes = np.concatenate([gazes_agents, gazes_landmarks], axis = 0)\n",
    "        #velocities = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "        #                                                     FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        velocities = np.zeros([FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        \n",
    "        #goal_locations = np.random.uniform(-FLAGS.bound, FLAGS.bound, [FLAGS.number_agents, \n",
    "        #                                                          FLAGS.dim_env, FLAGS.batch_size])\n",
    " \n",
    "        goal_locations, which_landmarks = self.create_goal_locations(positions_landmarks)\n",
    "        \n",
    "        #goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "        #                np.random.choice(FLAGS.number_goal_types, FLAGS.batch_size).reshape(-1,1))), \n",
    "        #                          [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "        #goal_types = np.array([[[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]], [[1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]], [[1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]]])\n",
    "        \n",
    "        goal_types = np.array([[[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]], [[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]]])\n",
    "        #goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "        #                np.random.choice([0,1], FLAGS.batch_size).reshape(-1,1))), \n",
    "        #                          [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "\n",
    "        #goal_types = np.array([[[0 for i in range(FLAGS.batch_size)], [1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]] for m in range(2)])\n",
    "        utterances = np.zeros((FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size))\n",
    "        memories_com = np.zeros((FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size))\n",
    "        memories_last = np.zeros((FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size))\n",
    "        \n",
    "        states = np.concatenate([positions, velocities, gazes, self.cols], axis = 1)\n",
    "        targets = self.create_consistent_targets()\n",
    "\n",
    "        return states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_return(output, full_goals, targets):\n",
    "    #shuffled_output = shuffle(output, targets)\n",
    "    shuffled_output = output\n",
    "    return -tf.reshape(tf.reduce_sum(tf.sqrt(tf.reduce_sum((shuffled_output - full_goals)**2, axis = 1)), axis = 0), [FLAGS.batch_size, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_nan(tensor):\n",
    "    nb_nan = np.sum(np.isnan(tensor))\n",
    "    if nb_nan == 0:\n",
    "        print(\"TRUETRUETRUETRUETRUETRUE\")\n",
    "        \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.policy = Policy()\n",
    "        self.env = Environment()\n",
    "        delete_history_files()\n",
    "        \n",
    "        self.get_placeholders()\n",
    "        self.definition_arrays()\n",
    "        self.write_arrays()\n",
    "        self.learning_rate = self.learning_rate_decay()\n",
    "        tf.summary.scalar('learning rate', self.learning_rate)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        self.loop()\n",
    "        self.output_to_run = [self.step, self.array_states_stack, self.array_utterances_stack, self.array_mem_com_stack, self.array_mem_last_stack, self.array_pred_stack,\n",
    "                                self.f_g , self.array_outputs_stack, self.t_fin, self.reward, self.phys_reward, self.voc_reward, self.pred_reward]\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "        self.reward_history = []\n",
    "        self.reward_batch_history = []\n",
    "        self.voc_reward_history = []\n",
    "        self.pred_reward_history = []\n",
    "        self.env_history = []\n",
    "        self.arrays_history = []\n",
    "        self.mean_act_count = []\n",
    "        \n",
    "        self.utt_hist = []\n",
    "        self.grads_history = []\n",
    "        self.vars_history = []\n",
    "        \n",
    "        self.array_utt = []\n",
    "        \n",
    "        \n",
    "    def learning_rate_decay(self):\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        if FLAGS.learning_rate_decay:\n",
    "            starter_learning_rate = FLAGS.learning_rate\n",
    "            boundaries = [1500] #3000] #, 10000]\n",
    "            values = [FLAGS.learning_rate, FLAGS.learning_rate/10] #, FLAGS.learning_rate/100]\n",
    "            return tf.train.piecewise_constant(self.global_step, boundaries, values, name=None)\n",
    "            #return tf.train.exponential_decay(starter_learning_rate, self.global_step, 150, 0.5, staircase = True)#0.05#150\n",
    "        else:\n",
    "            return FLAGS.learning_rate\n",
    "        \n",
    "    def definition_arrays(self):\n",
    "        # Create goals vectors \n",
    "        self.array_states = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_utterances = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_com = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_last = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_outputs = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_pred = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        \n",
    "    def get_placeholders(self):\n",
    "        [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets] = self.policy.get_placeholders()\n",
    "            \n",
    "            \n",
    "    def write_arrays(self):\n",
    "        self.array_states = self.array_states.write(0, self.states)\n",
    "        self.array_utterances = self.array_utterances.write(0, self.utterances)\n",
    "        self.array_mem_com = self.array_mem_com.write(0, self.mem_com)\n",
    "        self.array_mem_last = self.array_mem_last.write(0, self.mem_last)\n",
    "        self.array_outputs = self.array_outputs.write(0, np.zeros((FLAGS.number_agents, 4, FLAGS.batch_size), dtype = np.float32))\n",
    "        #self.array_outputs = self.array_outputs.write(0, np.zeros((FLAGS.number_agents, 2, FLAGS.batch_size), dtype = np.float32))\n",
    "        self.array_pred = self.array_pred.write(0, np.zeros((FLAGS.number_agents, FLAGS.number_goal_types + FLAGS.dim_env + 3, FLAGS.batch_size), dtype = np.float32))\n",
    "    \n",
    "    def loop(self):\n",
    "        t = tf.constant(0)\n",
    "        return_sofar = tf.zeros([FLAGS.batch_size, 1], tf.float32)\n",
    "        return_pred = tf.zeros([FLAGS.batch_size, 1], tf.float32)\n",
    "        #return_sofar = tf.zeros([2, FLAGS.batch_size], tf.float32)\n",
    "        args = [self.array_states, self.array_utterances, self.array_mem_com, self.array_mem_last, self.array_pred, self.goal_types, \n",
    "                self.goal_locations, self.full_goals, self.name_targets, self.array_outputs, t, return_sofar, return_pred]\n",
    "        \n",
    "        (array_states, array_utterances, array_mem_com, array_mem_last, array_pred, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t_fin, rewards_batch, return_pred) = tf.while_loop(self.condition, self.body, args, parallel_iterations=1)\n",
    "        \n",
    "        self.array_states_stack = array_states.stack()\n",
    "        self.array_utterances_stack = array_utterances.stack() \n",
    "        self.array_mem_com_stack = array_mem_com.stack() \n",
    "        self.array_mem_last_stack = array_mem_last.stack() \n",
    "        self.array_outputs_stack = array_outputs.stack()\n",
    "        self.array_pred_stack = array_pred.stack()\n",
    "        \n",
    "        self.phys_reward = tf.reshape(tf.reduce_mean(rewards_batch, axis = 0), [])\n",
    "        self.pred_reward = tf.reshape(tf.reduce_mean(return_pred, axis = 0), [])\n",
    "        #self.phys_reward = tf.reshape(tf.reduce_mean(self.reward_batch), [])\n",
    "        self.voc_reward = dirichlet_log_lik_end(tf.slice(self.array_utterances_stack, [1, 0, 0, 0], [FLAGS.time_horizon, FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size]))\n",
    "        self.f_g = full_goals\n",
    "        self.t_fin = t_fin, \n",
    "        self.reward = tf.Print(self.phys_reward +self.pred_reward + 0.5*self.voc_reward, [\"END\", self.phys_reward, self.voc_reward]) #+ self.voc_reward\n",
    "        \n",
    "        tf.summary.scalar('accuracy', -self.reward)\n",
    "        self.grads = self.optimizer.compute_gradients(-self.reward)\n",
    "            \n",
    "        #self.clipped_gradients = [(tf.clip_by_norm(grad, 0.0001), var) for grad, var in self.grads]\n",
    "        self.step = self.optimizer.apply_gradients(self.grads, global_step=self.global_step)\n",
    "        for index, grad in enumerate(self.grads):\n",
    "            tf.summary.histogram(\"{}-grad\".format(self.grads[index][1].name), self.grads[index]) \n",
    "    \n",
    "        \n",
    "    def body(self, array_states, array_utterances, array_mem_com, array_mem_last, array_pred, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar, return_pred_sofar):\n",
    "        \n",
    "        #Reading the last state of environment\n",
    "        states = array_states.read(t)\n",
    "        utterances = array_utterances.read(t)\n",
    "        mem_com = array_mem_com.read(t)\n",
    "        mem_last = array_mem_last.read(t)\n",
    "        \n",
    "        \n",
    "        phys_output, new_velocities, new_delta_gazes, new_utterances, delta_mem_com, delta_mem_last, pred = self.policy.forward_pass(states,\n",
    "                                                                    utterances, mem_com, mem_last, full_goals)\n",
    "        \n",
    "        #phys_output = self.policy.forward_pass(states, utterances, mem_com, mem_last, full_goals)\n",
    "\n",
    "        new_states, new_positions, new_gazes = compute_new_states(states, new_velocities, new_delta_gazes, new_utterances)\n",
    "        #new_utterances = tf.zeros([FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "        new_mem_com, new_mem_last = compute_new_memories(mem_com, mem_last, delta_mem_com, delta_mem_last)\n",
    "        \n",
    "        return_sofar += compute_reward(new_positions, new_gazes, phys_output, new_utterances, name_targets, goal_locations, \n",
    "                                        goal_types)\n",
    "        \n",
    "        return_pred_sofar = comp_return(pred, full_goals, name_targets)\n",
    "        \n",
    "        #return_sofar += comp_return(phys_output, goal_locations, name_targets)\n",
    "\n",
    "        #Writing the new state\n",
    "        \n",
    "        array_states = array_states.write((t+1), new_states)\n",
    "        array_utterances = array_utterances.write((t+1), new_utterances)\n",
    "        array_mem_com = array_mem_com.write((t+1), new_mem_com)\n",
    "        array_mem_last = array_mem_last.write((t+1), new_mem_last)\n",
    "        array_outputs = array_outputs.write((t+1), phys_output)\n",
    "        array_pred = array_pred.write((t+1), pred)\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "        return [array_states, array_utterances, array_mem_com, array_mem_last, array_pred, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar, return_pred_sofar]\n",
    "        \n",
    "        \n",
    "    def condition(self, array_states, array_utterances, array_mem_com, array_mem_last, array_pred, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar, return_pred_sofar):\n",
    "        return tf.less(t, FLAGS.time_horizon)\n",
    "    \n",
    "    \n",
    "    def create_feed_dict(self, states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks):\n",
    "        list_values = [states, utterances, memories_com, memories_last, goal_types, goal_locations, targets]#, which_landmarks]\n",
    "        list_placeholders = [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, \n",
    "                             self.goal_locations, self.name_targets]#, self.which_landmarks]\n",
    "        feed_dict = {a:b for a,b in zip(list_placeholders, list_values)} #.update({self.learning_rate:self.lr})\n",
    "        return feed_dict\n",
    "    \n",
    "    def train(self, sess):\n",
    "        self.train_writer = tf.summary.FileWriter('Summary', sess.graph)\n",
    "        print(\"Initializing variables\")\n",
    "        sess.run(self.init)\n",
    "        sess.graph.finalize()\n",
    "        print(\"Start training\")\n",
    "        start = datetime.now()\n",
    "        self.arrays_history = [0, 0, 0, 0, 0]\n",
    "        self.full_g = []\n",
    "        #states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks = self.env.random_generation()\n",
    "        for i in range(FLAGS.max_steps):            \n",
    "            states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks = self.env.random_generation()\n",
    "            generation_time = datetime.now() - start\n",
    "            feed_dict = self.create_feed_dict(states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks)\n",
    "            if (i+1) % FLAGS.tensorboard_freq == 0:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, array_pred, full_goals, array_outputs, t, reward, phys_reward, voc_reward, pred_reward, summary = sess.run(self.output_to_run + [self.merged], feed_dict)\n",
    "                self.train_writer.add_summary(summary, i)\n",
    "            else:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, array_pred, full_goals, array_outputs, t, reward, phys_reward, voc_reward, pred_reward = sess.run(self.output_to_run, feed_dict)\n",
    "            \n",
    "            \n",
    "            self.reward_history.append(reward)\n",
    "            self.pred_reward_history.append(pred_reward)\n",
    "            self.voc_reward_history.append(voc_reward)\n",
    "            self.arrays_history = [array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, array_pred]\n",
    "            with open('env_history.pkl', 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_landmarks])\n",
    "                \n",
    "            with open(\"arrays_history.pkl\", 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([array_states, array_utterances, array_mem_com, array_mem_last, array_outputs])\n",
    "                \n",
    "            if i % FLAGS.print_frequency == 0:\n",
    "                print(\"\\n\")\n",
    "                print(\"iteration \" + str(i))\n",
    "                print(\"physical reward: \" + str(phys_reward))\n",
    "                print(\"prediction reward: \" + str(pred_reward))\n",
    "                print(\"vocabulary reward: \" + str(voc_reward))\n",
    "                print(\"total reward: \" + str(reward))\n",
    "                final_states = array_states[-1, :, :, :]\n",
    "                print_stats_agent(final_states, goal_locations, goal_types, targets)\n",
    "    \n",
    "                print(\"computing time\")\n",
    "                print(datetime.now() - start)\n",
    "                print(\"generation time\")\n",
    "                print(generation_time)\n",
    "                print(\"memory usage\")\n",
    "                memory()\n",
    "\n",
    "                start = datetime.now()\n",
    "                \n",
    "            self.mean_act_count.append(print_stat_vocabulary(array_utterances[1:, :, :,:], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_0:0-grad is illegal; using phys_variable/weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_1:0-grad is illegal; using phys_variable/weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_2:0-grad is illegal; using phys_variable/weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_0:0-grad is illegal; using phys_variable/bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_1:0-grad is illegal; using phys_variable/bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_2:0-grad is illegal; using phys_variable/bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_memory_read_weight:0-grad is illegal; using com_memory_read_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_0:0-grad is illegal; using com_variable/com_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_1:0-grad is illegal; using com_variable/com_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_2:0-grad is illegal; using com_variable/com_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_0:0-grad is illegal; using com_variable/com_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_1:0-grad is illegal; using com_variable/com_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_2:0-grad is illegal; using com_variable/com_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_com:0-grad is illegal; using weight_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_com:0-grad is illegal; using bias_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_pred_com:0-grad is illegal; using weight_pred_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_pred_com:0-grad is illegal; using bias_pred_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name reading_last_mem_weight:0-grad is illegal; using reading_last_mem_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_0:0-grad is illegal; using last_variable/last_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_1:0-grad is illegal; using last_variable/last_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_2:0-grad is illegal; using last_variable/last_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_0:0-grad is illegal; using last_variable/last_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_1:0-grad is illegal; using last_variable/last_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_2:0-grad is illegal; using last_variable/last_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_last:0-grad is illegal; using weight_mem_last_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_last:0-grad is illegal; using bias_mem_last_0-grad instead.\n",
      "Initializing variables\n",
      "Start training\n",
      "\n",
      "\n",
      "iteration 0\n",
      "physical reward: -6893.8423\n",
      "prediction reward: -7.7743683\n",
      "vocabulary reward: -295.7598\n",
      "total reward: -7049.4966\n",
      "--- Agent 0\n",
      "------ Mean distance 9.86487193178527\n",
      "------ Median distance 9.251625586560085\n",
      "------ Third quartile 12.410221743959731\n",
      "------ Ninetieth percentile 15.555409145453964\n",
      "------ max distance 23.804229844507528\n",
      "------ argmax distance 75\n",
      "--- Agent 1\n",
      "------ Mean distance 11.96822004472267\n",
      "------ Median distance 12.117776090439152\n",
      "------ Third quartile 14.69719650886953\n",
      "------ Ninetieth percentile 17.08387563930503\n",
      "------ max distance 23.699608573354258\n",
      "------ argmax distance 96\n",
      "computing time\n",
      "0:00:02.264129\n",
      "generation time\n",
      "0:00:00.011997\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 18.095\n",
      "---- Median number of word activated: 18.0\n",
      "---- Total number of word activated: 20\n",
      "\n",
      "\n",
      "iteration 50\n",
      "physical reward: -1391.6189\n",
      "prediction reward: -7.0621095\n",
      "vocabulary reward: -291.61697\n",
      "total reward: -1544.4895\n",
      "--- Agent 0\n",
      "------ Mean distance 2.9094247559399156\n",
      "------ Median distance 2.714352718140021\n",
      "------ Third quartile 4.021610737486757\n",
      "------ Ninetieth percentile 4.240805327693023\n",
      "------ max distance 4.525822825971327\n",
      "------ argmax distance 38\n",
      "--- Agent 1\n",
      "------ Mean distance 3.060962953472826\n",
      "------ Median distance 2.8949501785036142\n",
      "------ Third quartile 3.9836397315254235\n",
      "------ Ninetieth percentile 4.250562041564754\n",
      "------ max distance 4.687902741572173\n",
      "------ argmax distance 28\n",
      "computing time\n",
      "0:00:48.075248\n",
      "generation time\n",
      "0:00:46.912147\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 17.63\n",
      "---- Median number of word activated: 18.0\n",
      "---- Total number of word activated: 20\n",
      "\n",
      "\n",
      "iteration 100\n",
      "physical reward: -743.40283\n",
      "prediction reward: -3.4847991\n",
      "vocabulary reward: -145.2868\n",
      "total reward: -819.531\n",
      "--- Agent 0\n",
      "------ Mean distance 1.1953889009036185\n",
      "------ Median distance 1.2812091592523727\n",
      "------ Third quartile 1.599658990130854\n",
      "------ Ninetieth percentile 1.8579430803703885\n",
      "------ max distance 2.2908641422540432\n",
      "------ argmax distance 12\n",
      "--- Agent 1\n",
      "------ Mean distance 1.123329743942684\n",
      "------ Median distance 1.267346807997796\n",
      "------ Third quartile 1.632080763932815\n",
      "------ Ninetieth percentile 1.8402578485061585\n",
      "------ max distance 2.2225823493564287\n",
      "------ argmax distance 26\n",
      "computing time\n",
      "0:01:30.973641\n",
      "generation time\n",
      "0:01:29.700748\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 6.01\n",
      "---- Median number of word activated: 7.0\n",
      "---- Total number of word activated: 20\n",
      "\n",
      "\n",
      "iteration 150\n",
      "physical reward: -733.3605\n",
      "prediction reward: -3.2750516\n",
      "vocabulary reward: -109.78591\n",
      "total reward: -791.52844\n",
      "--- Agent 0\n",
      "------ Mean distance 1.3379233449005838\n",
      "------ Median distance 1.1877517187924127\n",
      "------ Third quartile 1.6955442123486\n",
      "------ Ninetieth percentile 2.454382134976319\n",
      "------ max distance 2.6998622691563665\n",
      "------ argmax distance 62\n",
      "--- Agent 1\n",
      "------ Mean distance 1.5260521691511415\n",
      "------ Median distance 1.2657740088092448\n",
      "------ Third quartile 2.255620673551095\n",
      "------ Ninetieth percentile 2.656767372307728\n",
      "------ max distance 3.1512363797362597\n",
      "------ argmax distance 42\n",
      "computing time\n",
      "0:01:19.689361\n",
      "generation time\n",
      "0:01:17.857702\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.86\n",
      "---- Median number of word activated: 3.0\n",
      "---- Total number of word activated: 20\n",
      "\n",
      "\n",
      "iteration 200\n",
      "physical reward: -861.35986\n",
      "prediction reward: -3.0676577\n",
      "vocabulary reward: -109.638016\n",
      "total reward: -919.2466\n",
      "--- Agent 0\n",
      "------ Mean distance 1.8383535753723086\n",
      "------ Median distance 1.8705246980080394\n",
      "------ Third quartile 2.0873953141482353\n",
      "------ Ninetieth percentile 2.3166485034957085\n",
      "------ max distance 2.865902465374401\n",
      "------ argmax distance 5\n",
      "--- Agent 1\n",
      "------ Mean distance 1.8273925924002825\n",
      "------ Median distance 1.8418943053437915\n",
      "------ Third quartile 2.0983980841654972\n",
      "------ Ninetieth percentile 2.488488559730783\n",
      "------ max distance 2.8623424763517473\n",
      "------ argmax distance 73\n",
      "computing time\n",
      "0:01:39.138359\n",
      "generation time\n",
      "0:01:37.637395\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.04\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 16\n",
      "\n",
      "\n",
      "iteration 250\n",
      "physical reward: -650.594\n",
      "prediction reward: -2.527513\n",
      "vocabulary reward: -110.0012\n",
      "total reward: -708.12213\n",
      "--- Agent 0\n",
      "------ Mean distance 0.8260107657116481\n",
      "------ Median distance 0.7129431239440046\n",
      "------ Third quartile 1.2449047931255914\n",
      "------ Ninetieth percentile 1.664045066183605\n",
      "------ max distance 2.1279452825941707\n",
      "------ argmax distance 24\n",
      "--- Agent 1\n",
      "------ Mean distance 0.8294570229017598\n",
      "------ Median distance 0.7395595127251963\n",
      "------ Third quartile 1.2228428014435717\n",
      "------ Ninetieth percentile 1.6799848122843846\n",
      "------ max distance 2.3482466773648425\n",
      "------ argmax distance 82\n",
      "computing time\n",
      "0:01:35.219684\n",
      "generation time\n",
      "0:01:33.205031\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.29\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration 300\n",
      "physical reward: -585.1525\n",
      "prediction reward: -2.0394688\n",
      "vocabulary reward: -106.97032\n",
      "total reward: -640.6772\n",
      "--- Agent 0\n",
      "------ Mean distance 0.6661433066771028\n",
      "------ Median distance 0.6786709491192952\n",
      "------ Third quartile 0.8254589361417498\n",
      "------ Ninetieth percentile 0.9853412479919327\n",
      "------ max distance 1.3859485211842242\n",
      "------ argmax distance 28\n",
      "--- Agent 1\n",
      "------ Mean distance 0.6705919815463577\n",
      "------ Median distance 0.6786804809838227\n",
      "------ Third quartile 0.853103414138938\n",
      "------ Ninetieth percentile 1.0136173983773606\n",
      "------ max distance 1.5047105037302573\n",
      "------ argmax distance 86\n",
      "computing time\n",
      "0:01:42.145904\n",
      "generation time\n",
      "0:01:40.177368\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.125\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 13\n",
      "\n",
      "\n",
      "iteration 350\n",
      "physical reward: -546.80786\n",
      "prediction reward: -1.9438922\n",
      "vocabulary reward: -107.96665\n",
      "total reward: -602.7351\n",
      "--- Agent 0\n",
      "------ Mean distance 0.4191099967550447\n",
      "------ Median distance 0.39759902703394256\n",
      "------ Third quartile 0.5572763394199833\n",
      "------ Ninetieth percentile 0.6837463205376233\n",
      "------ max distance 0.9306613128838109\n",
      "------ argmax distance 91\n",
      "--- Agent 1\n",
      "------ Mean distance 0.45319212910933715\n",
      "------ Median distance 0.4469002810278792\n",
      "------ Third quartile 0.5953539245255846\n",
      "------ Ninetieth percentile 0.7313868359328771\n",
      "------ max distance 1.0808438929126412\n",
      "------ argmax distance 34\n",
      "computing time\n",
      "0:01:39.356123\n",
      "generation time\n",
      "0:01:37.388941\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.15\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 10\n",
      "\n",
      "\n",
      "iteration 400\n",
      "physical reward: -598.60297\n",
      "prediction reward: -2.2247558\n",
      "vocabulary reward: -107.94904\n",
      "total reward: -654.80225\n",
      "--- Agent 0\n",
      "------ Mean distance 1.0229014303381676\n",
      "------ Median distance 0.8491166920578546\n",
      "------ Third quartile 1.1266779907312885\n",
      "------ Ninetieth percentile 1.9062119316512796\n",
      "------ max distance 2.7648092873386165\n",
      "------ argmax distance 84\n",
      "--- Agent 1\n",
      "------ Mean distance 1.0067509301463138\n",
      "------ Median distance 0.925906416518645\n",
      "------ Third quartile 1.1577029189190875\n",
      "------ Ninetieth percentile 1.5264148576749572\n",
      "------ max distance 2.627876513335949\n",
      "------ argmax distance 15\n",
      "computing time\n",
      "0:01:42.420123\n",
      "generation time\n",
      "0:01:40.409568\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.13\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 12\n",
      "\n",
      "\n",
      "iteration 450\n",
      "physical reward: -521.1026\n",
      "prediction reward: -1.7207772\n",
      "vocabulary reward: -103.41116\n",
      "total reward: -574.52893\n",
      "--- Agent 0\n",
      "------ Mean distance 0.2777418586544424\n",
      "------ Median distance 0.2518132796559455\n",
      "------ Third quartile 0.3743936162080306\n",
      "------ Ninetieth percentile 0.48915581612971315\n",
      "------ max distance 0.8503065835125867\n",
      "------ argmax distance 40\n",
      "--- Agent 1\n",
      "------ Mean distance 0.29639064844957436\n",
      "------ Median distance 0.2492784963157995\n",
      "------ Third quartile 0.37163698049676314\n",
      "------ Ninetieth percentile 0.5071918929070525\n",
      "------ max distance 1.1770310070337586\n",
      "------ argmax distance 91\n",
      "computing time\n",
      "0:01:41.818735\n",
      "generation time\n",
      "0:01:39.658236\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.075\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 6\n",
      "\n",
      "\n",
      "iteration 500\n",
      "physical reward: -521.2068\n",
      "prediction reward: -1.7088928\n",
      "vocabulary reward: -108.80068\n",
      "total reward: -577.316\n",
      "--- Agent 0\n",
      "------ Mean distance 0.5195848920318017\n",
      "------ Median distance 0.5054079399267977\n",
      "------ Third quartile 0.6695025203872609\n",
      "------ Ninetieth percentile 0.820240251160774\n",
      "------ max distance 1.0330879038577607\n",
      "------ argmax distance 34\n",
      "--- Agent 1\n",
      "------ Mean distance 0.5363418565181831\n",
      "------ Median distance 0.5212067331368992\n",
      "------ Third quartile 0.7075627274309471\n",
      "------ Ninetieth percentile 0.8279672755288623\n",
      "------ max distance 1.2453882451795664\n",
      "------ argmax distance 22\n",
      "computing time\n",
      "0:01:41.170103\n",
      "generation time\n",
      "0:01:39.171590\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.07\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 5\n",
      "\n",
      "\n",
      "iteration 550\n",
      "physical reward: -577.53546\n",
      "prediction reward: -2.4268932\n",
      "vocabulary reward: -108.507385\n",
      "total reward: -634.21606\n",
      "--- Agent 0\n",
      "------ Mean distance 0.8368755687318702\n",
      "------ Median distance 0.42869591242742583\n",
      "------ Third quartile 0.6444610061535946\n",
      "------ Ninetieth percentile 2.933174964964352\n",
      "------ max distance 3.3083058355585093\n",
      "------ argmax distance 26\n",
      "--- Agent 1\n",
      "------ Mean distance 0.6802844725607753\n",
      "------ Median distance 0.425045791977239\n",
      "------ Third quartile 0.6003707506797473\n",
      "------ Ninetieth percentile 1.2318256668879366\n",
      "------ max distance 3.1328624886254945\n",
      "------ argmax distance 0\n",
      "computing time\n",
      "0:01:41.291443\n",
      "generation time\n",
      "0:01:39.223773\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.12\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 6\n",
      "\n",
      "\n",
      "iteration 600\n",
      "physical reward: -515.8261\n",
      "prediction reward: -1.5964841\n",
      "vocabulary reward: -104.86321\n",
      "total reward: -569.8542\n",
      "--- Agent 0\n",
      "------ Mean distance 0.2722575646890729\n",
      "------ Median distance 0.26320926604517514\n",
      "------ Third quartile 0.3846864905004693\n",
      "------ Ninetieth percentile 0.5026554792273459\n",
      "------ max distance 0.6653728365808258\n",
      "------ argmax distance 53\n",
      "--- Agent 1\n",
      "------ Mean distance 0.24431184636112144\n",
      "------ Median distance 0.200633641537383\n",
      "------ Third quartile 0.35619989981561334\n",
      "------ Ninetieth percentile 0.47345968928115517\n",
      "------ max distance 0.8001192723214883\n",
      "------ argmax distance 85\n",
      "computing time\n",
      "0:01:43.814977\n",
      "generation time\n",
      "0:01:41.798372\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.22\n",
      "---- Median number of word activated: 3.0\n",
      "---- Total number of word activated: 7\n",
      "\n",
      "\n",
      "iteration 650\n",
      "physical reward: -489.68417\n",
      "prediction reward: -1.5396761\n",
      "vocabulary reward: -106.00883\n",
      "total reward: -544.2283\n",
      "--- Agent 0\n",
      "------ Mean distance 0.30336185912837227\n",
      "------ Median distance 0.2819320737745141\n",
      "------ Third quartile 0.4490492504486939\n",
      "------ Ninetieth percentile 0.5353432692736345\n",
      "------ max distance 0.7925777090581029\n",
      "------ argmax distance 40\n",
      "--- Agent 1\n",
      "------ Mean distance 0.32184307406649604\n",
      "------ Median distance 0.3085948714076395\n",
      "------ Third quartile 0.4554362543880748\n",
      "------ Ninetieth percentile 0.562328609356979\n",
      "------ max distance 0.6804703499582014\n",
      "------ argmax distance 62\n",
      "computing time\n",
      "0:01:41.187948\n",
      "generation time\n",
      "0:01:39.164533\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.255\n",
      "---- Median number of word activated: 3.0\n",
      "---- Total number of word activated: 4\n",
      "\n",
      "\n",
      "iteration 700\n",
      "physical reward: -570.45386\n",
      "prediction reward: -1.6829442\n",
      "vocabulary reward: -90.58402\n",
      "total reward: -617.4288\n",
      "--- Agent 0\n",
      "------ Mean distance 0.6259554785579516\n",
      "------ Median distance 0.5192600214440778\n",
      "------ Third quartile 0.6774058737370164\n",
      "------ Ninetieth percentile 1.077037683881756\n",
      "------ max distance 4.3338902159907295\n",
      "------ argmax distance 44\n",
      "--- Agent 1\n",
      "------ Mean distance 0.5935839446963537\n",
      "------ Median distance 0.5459904508997303\n",
      "------ Third quartile 0.6664601831469882\n",
      "------ Ninetieth percentile 1.1492929198832893\n",
      "------ max distance 2.43536509395418\n",
      "------ argmax distance 24\n",
      "computing time\n",
      "0:01:41.860172\n",
      "generation time\n",
      "0:01:39.872957\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.085\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 6\n",
      "\n",
      "\n",
      "iteration 750\n",
      "physical reward: -507.7632\n",
      "prediction reward: -1.5764709\n",
      "vocabulary reward: -99.596306\n",
      "total reward: -559.1378\n",
      "--- Agent 0\n",
      "------ Mean distance 0.1694464282834043\n",
      "------ Median distance 0.14807180113811008\n",
      "------ Third quartile 0.22190936971355718\n",
      "------ Ninetieth percentile 0.29467106294097206\n",
      "------ max distance 0.512160555769222\n",
      "------ argmax distance 60\n",
      "--- Agent 1\n",
      "------ Mean distance 0.18334014495436463\n",
      "------ Median distance 0.14807966103923237\n",
      "------ Third quartile 0.24156229518508632\n",
      "------ Ninetieth percentile 0.372862597157459\n",
      "------ max distance 0.5092101302306816\n",
      "------ argmax distance 76\n",
      "computing time\n",
      "0:01:42.732925\n",
      "generation time\n",
      "0:01:40.752130\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.29\n",
      "---- Median number of word activated: 3.0\n",
      "---- Total number of word activated: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration 800\n",
      "physical reward: -478.64856\n",
      "prediction reward: -1.5659655\n",
      "vocabulary reward: -64.30611\n",
      "total reward: -512.3676\n",
      "--- Agent 0\n",
      "------ Mean distance 0.5122138208506972\n",
      "------ Median distance 0.2721895635028045\n",
      "------ Third quartile 1.0367663857633131\n",
      "------ Ninetieth percentile 1.299995218569398\n",
      "------ max distance 1.5302555336425911\n",
      "------ argmax distance 27\n",
      "--- Agent 1\n",
      "------ Mean distance 0.5677889414081172\n",
      "------ Median distance 0.23456792857857145\n",
      "------ Third quartile 1.1854816543728413\n",
      "------ Ninetieth percentile 1.3079748445147592\n",
      "------ max distance 1.5306170948518503\n",
      "------ argmax distance 46\n",
      "computing time\n",
      "0:01:41.508983\n",
      "generation time\n",
      "0:01:39.501700\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.195\n",
      "---- Median number of word activated: 3.0\n",
      "---- Total number of word activated: 6\n",
      "\n",
      "\n",
      "iteration 850\n",
      "physical reward: -585.69556\n",
      "prediction reward: -1.5689049\n",
      "vocabulary reward: -71.03595\n",
      "total reward: -622.7825\n",
      "--- Agent 0\n",
      "------ Mean distance 0.9642525217370143\n",
      "------ Median distance 0.516752994374885\n",
      "------ Third quartile 1.7717863251323163\n",
      "------ Ninetieth percentile 2.2661041545423464\n",
      "------ max distance 2.499176409315832\n",
      "------ argmax distance 66\n",
      "--- Agent 1\n",
      "------ Mean distance 1.0595911980428243\n",
      "------ Median distance 0.5732822347579811\n",
      "------ Third quartile 2.0743169738928398\n",
      "------ Ninetieth percentile 2.30034000038031\n",
      "------ max distance 2.485759343888675\n",
      "------ argmax distance 62\n",
      "computing time\n",
      "0:01:41.487598\n",
      "generation time\n",
      "0:01:39.513753\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.2\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 5\n",
      "\n",
      "\n",
      "iteration 900\n",
      "physical reward: -469.7727\n",
      "prediction reward: -1.561093\n",
      "vocabulary reward: -57.52286\n",
      "total reward: -500.09525\n",
      "--- Agent 0\n",
      "------ Mean distance 0.49911269549753223\n",
      "------ Median distance 0.47760138943884545\n",
      "------ Third quartile 0.616081293128595\n",
      "------ Ninetieth percentile 0.7459229305234659\n",
      "------ max distance 0.8626797671304275\n",
      "------ argmax distance 41\n",
      "--- Agent 1\n",
      "------ Mean distance 0.4708104814251378\n",
      "------ Median distance 0.43972336861046984\n",
      "------ Third quartile 0.5724863659514883\n",
      "------ Ninetieth percentile 0.6841350612629847\n",
      "------ max distance 0.8971397351988575\n",
      "------ argmax distance 68\n",
      "computing time\n",
      "0:01:42.207859\n",
      "generation time\n",
      "0:01:40.223928\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.035\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 4\n",
      "\n",
      "\n",
      "iteration 950\n",
      "physical reward: -470.44177\n",
      "prediction reward: -1.5215644\n",
      "vocabulary reward: -50.532608\n",
      "total reward: -497.22964\n",
      "--- Agent 0\n",
      "------ Mean distance 0.5362360684903831\n",
      "------ Median distance 0.30335078438834717\n",
      "------ Third quartile 0.9998902842716376\n",
      "------ Ninetieth percentile 1.1472405473498979\n",
      "------ max distance 3.1053765636438433\n",
      "------ argmax distance 63\n",
      "--- Agent 1\n",
      "------ Mean distance 0.401196961269932\n",
      "------ Median distance 0.21361609583369262\n",
      "------ Third quartile 0.3606257485773876\n",
      "------ Ninetieth percentile 1.1302654337336169\n",
      "------ max distance 3.061138103244561\n",
      "------ argmax distance 63\n",
      "computing time\n",
      "0:01:42.333009\n",
      "generation time\n",
      "0:01:40.169706\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.08\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1000\n",
      "physical reward: -488.3322\n",
      "prediction reward: -1.4932334\n",
      "vocabulary reward: -35.62234\n",
      "total reward: -507.6366\n",
      "--- Agent 0\n",
      "------ Mean distance 0.1730188284167125\n",
      "------ Median distance 0.17009913778229557\n",
      "------ Third quartile 0.22418841571811188\n",
      "------ Ninetieth percentile 0.29652011126956895\n",
      "------ max distance 0.5362447336261571\n",
      "------ argmax distance 67\n",
      "--- Agent 1\n",
      "------ Mean distance 0.18010815183257944\n",
      "------ Median distance 0.16817766246142837\n",
      "------ Third quartile 0.2361146413737409\n",
      "------ Ninetieth percentile 0.2871823112881963\n",
      "------ max distance 0.3913379082604112\n",
      "------ argmax distance 87\n",
      "computing time\n",
      "0:01:41.993290\n",
      "generation time\n",
      "0:01:39.986979\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.995\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1050\n",
      "physical reward: -486.66992\n",
      "prediction reward: -1.6677076\n",
      "vocabulary reward: -40.72039\n",
      "total reward: -508.6978\n",
      "--- Agent 0\n",
      "------ Mean distance 0.40237095432406755\n",
      "------ Median distance 0.20701648251918747\n",
      "------ Third quartile 0.2776177836270285\n",
      "------ Ninetieth percentile 0.3527616507341311\n",
      "------ max distance 5.7100211733512625\n",
      "------ argmax distance 45\n",
      "--- Agent 1\n",
      "------ Mean distance 0.2573692716737904\n",
      "------ Median distance 0.22438248525084487\n",
      "------ Third quartile 0.3037900471449975\n",
      "------ Ninetieth percentile 0.35338622387951485\n",
      "------ max distance 3.188574266491663\n",
      "------ argmax distance 96\n",
      "computing time\n",
      "0:01:41.363536\n",
      "generation time\n",
      "0:01:39.314539\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.045\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 5\n",
      "\n",
      "\n",
      "iteration 1100\n",
      "physical reward: -510.75558\n",
      "prediction reward: -1.4544405\n",
      "vocabulary reward: -22.425049\n",
      "total reward: -523.42255\n",
      "--- Agent 0\n",
      "------ Mean distance 0.2944931840964207\n",
      "------ Median distance 0.3036786783055722\n",
      "------ Third quartile 0.3851693684992413\n",
      "------ Ninetieth percentile 0.4551794098131771\n",
      "------ max distance 0.5950851674725656\n",
      "------ argmax distance 59\n",
      "--- Agent 1\n",
      "------ Mean distance 0.3185976413659215\n",
      "------ Median distance 0.32285387204090404\n",
      "------ Third quartile 0.4243862016318134\n",
      "------ Ninetieth percentile 0.5153636857758603\n",
      "------ max distance 0.6879112390813525\n",
      "------ argmax distance 29\n",
      "computing time\n",
      "0:01:41.378703\n",
      "generation time\n",
      "0:01:39.309684\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.915\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 4\n",
      "\n",
      "\n",
      "iteration 1150\n",
      "physical reward: -439.67743\n",
      "prediction reward: -1.4771609\n",
      "vocabulary reward: -20.554844\n",
      "total reward: -451.43204\n",
      "--- Agent 0\n",
      "------ Mean distance 0.398402831026022\n",
      "------ Median distance 0.3317644443849858\n",
      "------ Third quartile 0.5215382983466649\n",
      "------ Ninetieth percentile 0.7201587151472328\n",
      "------ max distance 0.8783245614802563\n",
      "------ argmax distance 88\n",
      "--- Agent 1\n",
      "------ Mean distance 0.40533031276443027\n",
      "------ Median distance 0.38268208264479364\n",
      "------ Third quartile 0.47384875076650623\n",
      "------ Ninetieth percentile 0.6482372741424002\n",
      "------ max distance 0.8737736875397056\n",
      "------ argmax distance 72\n",
      "computing time\n",
      "0:01:42.388091\n",
      "generation time\n",
      "0:01:40.381372\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 2.01\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1200\n",
      "physical reward: -464.87415\n",
      "prediction reward: -1.5854836\n",
      "vocabulary reward: -21.888412\n",
      "total reward: -477.40384\n",
      "--- Agent 0\n",
      "------ Mean distance 0.4046709804306041\n",
      "------ Median distance 0.26440571836468973\n",
      "------ Third quartile 0.38137322017165454\n",
      "------ Ninetieth percentile 0.5210272579317778\n",
      "------ max distance 6.078057208701129\n",
      "------ argmax distance 74\n",
      "--- Agent 1\n",
      "------ Mean distance 0.3434601381108427\n",
      "------ Median distance 0.26586315900885527\n",
      "------ Third quartile 0.36454024429987203\n",
      "------ Ninetieth percentile 0.4958880003210884\n",
      "------ max distance 6.033691102993371\n",
      "------ argmax distance 74\n",
      "computing time\n",
      "0:01:41.314125\n",
      "generation time\n",
      "0:01:39.269310\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.98\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1250\n",
      "physical reward: -443.96048\n",
      "prediction reward: -1.5015215\n",
      "vocabulary reward: -13.995239\n",
      "total reward: -452.45963\n",
      "--- Agent 0\n",
      "------ Mean distance 0.23716068747284466\n",
      "------ Median distance 0.22724945825911902\n",
      "------ Third quartile 0.29004401526953066\n",
      "------ Ninetieth percentile 0.3689641067639211\n",
      "------ max distance 0.46997070182024125\n",
      "------ argmax distance 55\n",
      "--- Agent 1\n",
      "------ Mean distance 0.2772590620318623\n",
      "------ Median distance 0.2757274496026142\n",
      "------ Third quartile 0.3322860673548413\n",
      "------ Ninetieth percentile 0.4018175951336195\n",
      "------ max distance 0.5557186226876765\n",
      "------ argmax distance 39\n",
      "computing time\n",
      "0:01:43.122894\n",
      "generation time\n",
      "0:01:41.086969\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.72\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration 1300\n",
      "physical reward: -418.13864\n",
      "prediction reward: -1.4930693\n",
      "vocabulary reward: -13.822192\n",
      "total reward: -426.54282\n",
      "--- Agent 0\n",
      "------ Mean distance 0.25272698641085334\n",
      "------ Median distance 0.22635540888090344\n",
      "------ Third quartile 0.31870122325851624\n",
      "------ Ninetieth percentile 0.45186522073030394\n",
      "------ max distance 0.7359387167286005\n",
      "------ argmax distance 41\n",
      "--- Agent 1\n",
      "------ Mean distance 0.23457586437690656\n",
      "------ Median distance 0.21353131304084338\n",
      "------ Third quartile 0.3022824033253607\n",
      "------ Ninetieth percentile 0.4125525259478311\n",
      "------ max distance 0.7349610082221437\n",
      "------ argmax distance 22\n",
      "computing time\n",
      "0:01:42.592411\n",
      "generation time\n",
      "0:01:40.844008\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.635\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1350\n",
      "physical reward: -519.1948\n",
      "prediction reward: -1.7123876\n",
      "vocabulary reward: -13.067562\n",
      "total reward: -527.441\n",
      "--- Agent 0\n",
      "------ Mean distance 0.7674610181564192\n",
      "------ Median distance 0.7562499849144921\n",
      "------ Third quartile 0.990702813975251\n",
      "------ Ninetieth percentile 1.1329016027203944\n",
      "------ max distance 2.6037502121831184\n",
      "------ argmax distance 18\n",
      "--- Agent 1\n",
      "------ Mean distance 0.8028334635960939\n",
      "------ Median distance 0.7594557516801126\n",
      "------ Third quartile 0.9741366136322034\n",
      "------ Ninetieth percentile 1.0920389634572758\n",
      "------ max distance 5.506281941677585\n",
      "------ argmax distance 67\n",
      "computing time\n",
      "0:01:29.691100\n",
      "generation time\n",
      "0:01:27.661532\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.8\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 4\n",
      "\n",
      "\n",
      "iteration 1400\n",
      "physical reward: -792.52716\n",
      "prediction reward: -2.5635016\n",
      "vocabulary reward: -14.048754\n",
      "total reward: -802.115\n",
      "--- Agent 0\n",
      "------ Mean distance 1.2836576300276163\n",
      "------ Median distance 0.671278469855307\n",
      "------ Third quartile 1.1824181694763172\n",
      "------ Ninetieth percentile 4.553060984573829\n",
      "------ max distance 6.2487237990004845\n",
      "------ argmax distance 34\n",
      "--- Agent 1\n",
      "------ Mean distance 1.2175287263915147\n",
      "------ Median distance 0.7174469031426338\n",
      "------ Third quartile 1.1303647893509323\n",
      "------ Ninetieth percentile 3.276283508375654\n",
      "------ max distance 5.533291066808586\n",
      "------ argmax distance 77\n",
      "computing time\n",
      "0:01:33.232050\n",
      "generation time\n",
      "0:01:31.718707\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.74\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1450\n",
      "physical reward: -468.86636\n",
      "prediction reward: -1.5327531\n",
      "vocabulary reward: -12.929204\n",
      "total reward: -476.8637\n",
      "--- Agent 0\n",
      "------ Mean distance 0.3863803111350389\n",
      "------ Median distance 0.28894339329158647\n",
      "------ Third quartile 0.44287970621312894\n",
      "------ Ninetieth percentile 0.568995747373787\n",
      "------ max distance 5.4275418553498485\n",
      "------ argmax distance 83\n",
      "--- Agent 1\n",
      "------ Mean distance 0.3623446652556793\n",
      "------ Median distance 0.23801347584409688\n",
      "------ Third quartile 0.4397851799092624\n",
      "------ Ninetieth percentile 0.5435828683679548\n",
      "------ max distance 5.378187098893801\n",
      "------ argmax distance 83\n",
      "computing time\n",
      "0:01:37.278786\n",
      "generation time\n",
      "0:01:35.563195\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.67\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 4\n",
      "\n",
      "\n",
      "iteration 1500\n",
      "physical reward: -471.50995\n",
      "prediction reward: -1.5022534\n",
      "vocabulary reward: -9.4555025\n",
      "total reward: -477.73996\n",
      "--- Agent 0\n",
      "------ Mean distance 0.23240400612472784\n",
      "------ Median distance 0.1969375621513878\n",
      "------ Third quartile 0.28132976666795056\n",
      "------ Ninetieth percentile 0.38602349041458967\n",
      "------ max distance 3.029191091883131\n",
      "------ argmax distance 1\n",
      "--- Agent 1\n",
      "------ Mean distance 0.24256632350744223\n",
      "------ Median distance 0.21344447018238316\n",
      "------ Third quartile 0.2922539910970072\n",
      "------ Ninetieth percentile 0.36463623123674616\n",
      "------ max distance 3.056401590244382\n",
      "------ argmax distance 1\n",
      "computing time\n",
      "0:01:30.459897\n",
      "generation time\n",
      "0:01:28.488474\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.705\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 4\n",
      "\n",
      "\n",
      "iteration 1550\n",
      "physical reward: -479.37225\n",
      "prediction reward: -1.5111208\n",
      "vocabulary reward: -8.277188\n",
      "total reward: -485.02194\n",
      "--- Agent 0\n",
      "------ Mean distance 0.19636442055517267\n",
      "------ Median distance 0.12127506052806457\n",
      "------ Third quartile 0.17867115966905578\n",
      "------ Ninetieth percentile 0.26595216976974606\n",
      "------ max distance 5.836016836024683\n",
      "------ argmax distance 72\n",
      "--- Agent 1\n",
      "------ Mean distance 0.1853121939051622\n",
      "------ Median distance 0.11439968718545285\n",
      "------ Third quartile 0.16771851331225832\n",
      "------ Ninetieth percentile 0.23950813939694\n",
      "------ max distance 5.937596476816279\n",
      "------ argmax distance 72\n",
      "computing time\n",
      "0:01:35.285302\n",
      "generation time\n",
      "0:01:33.318588\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.66\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1600\n",
      "physical reward: -462.31714\n",
      "prediction reward: -1.5152843\n",
      "vocabulary reward: -8.276325\n",
      "total reward: -467.97058\n",
      "--- Agent 0\n",
      "------ Mean distance 0.18969977482590983\n",
      "------ Median distance 0.10674435557849837\n",
      "------ Third quartile 0.1658323436769998\n",
      "------ Ninetieth percentile 0.25079406076672833\n",
      "------ max distance 6.758195817598974\n",
      "------ argmax distance 6\n",
      "--- Agent 1\n",
      "------ Mean distance 0.2094802664780567\n",
      "------ Median distance 0.11240683326367071\n",
      "------ Third quartile 0.1777620226742196\n",
      "------ Ninetieth percentile 0.29484584937975206\n",
      "------ max distance 6.876438878065484\n",
      "------ argmax distance 6\n",
      "computing time\n",
      "0:01:37.283670\n",
      "generation time\n",
      "0:01:35.186878\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.675\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1650\n",
      "physical reward: -468.1099\n",
      "prediction reward: -1.534716\n",
      "vocabulary reward: -8.671027\n",
      "total reward: -473.98013\n",
      "--- Agent 0\n",
      "------ Mean distance 0.15516029910974832\n",
      "------ Median distance 0.120020912026527\n",
      "------ Third quartile 0.16493162809641515\n",
      "------ Ninetieth percentile 0.2033454024389331\n",
      "------ max distance 3.115215238586464\n",
      "------ argmax distance 42\n",
      "--- Agent 1\n",
      "------ Mean distance 0.1866143459690887\n",
      "------ Median distance 0.11491314879727581\n",
      "------ Third quartile 0.16109324723789406\n",
      "------ Ninetieth percentile 0.20235158315864113\n",
      "------ max distance 5.880248873149536\n",
      "------ argmax distance 80\n",
      "computing time\n",
      "0:01:34.595545\n",
      "generation time\n",
      "0:01:33.013845\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.695\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n",
      "\n",
      "\n",
      "iteration 1700\n",
      "physical reward: -459.28485\n",
      "prediction reward: -1.4997001\n",
      "vocabulary reward: -8.42329\n",
      "total reward: -464.9962\n",
      "--- Agent 0\n",
      "------ Mean distance 0.17389343873409602\n",
      "------ Median distance 0.10385548865374163\n",
      "------ Third quartile 0.1555193962885319\n",
      "------ Ninetieth percentile 0.21625653471152773\n",
      "------ max distance 5.5507781481205845\n",
      "------ argmax distance 74\n",
      "--- Agent 1\n",
      "------ Mean distance 0.1832687299129841\n",
      "------ Median distance 0.10972874236058466\n",
      "------ Third quartile 0.17204896360749272\n",
      "------ Ninetieth percentile 0.22225296340368733\n",
      "------ max distance 5.790203547775982\n",
      "------ argmax distance 74\n",
      "computing time\n",
      "0:01:38.310680\n",
      "generation time\n",
      "0:01:36.388389\n",
      "memory usage\n",
      "memory use: 0.9050178527832031\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.685\n",
      "---- Median number of word activated: 2.0\n",
      "---- Total number of word activated: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-06409e79a080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-360d6eeb9bba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0marray_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_utterances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_com\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphys_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp = Experiment()\n",
    "sess = tf.Session()\n",
    "exp.train(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iteration 46000\n",
    "-253.03172\n",
    "--- Agent 0\n",
    "------ Mean distance 0.3349107071033829\n",
    "------ Median distance 0.29547300157924467\n",
    "------ Third quartile 0.4377302665174422\n",
    "------ Ninetieth percentile 0.638775063507328\n",
    "------ max distance 0.8557159604403306\n",
    "------ argmax distance 39\n",
    "--- Agent 1\n",
    "------ Mean distance 0.3412405142027863\n",
    "------ Median distance 0.31892391108436546\n",
    "------ Third quartile 0.45355292453441526\n",
    "------ Ninetieth percentile 0.6242127385438654\n",
    "------ max distance 0.9072062760757306\n",
    "------ argmax distance 16\n",
    "computing time\n",
    "0:11:42.544759\n",
    "generation time\n",
    "0:11:41.076586\n",
    "memory usage\n",
    "memory use: 0.8258514404296875\n",
    "-- Stats word count:\n",
    "---- Mean number of word activated: 19.28\n",
    "---- Median number of word activated: 19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"env_history.pkl\", \"rb\") as openfile:\n",
    "    states, utterances, memories_com, memories_last, goal_locations, goal_types, targets, which_ld = cPickle.load(openfile)\n",
    "\n",
    "    \n",
    "array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, pred = exp.arrays_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_stats_agent(array_states[-1, :, :, :], goal_locations, goal_types, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goal_locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dist_to_goal = compute_goal_dist(python_shuffle(array_states[-1, :, :, :],targets),  goal_locations, goal_types)\n",
    "#dist_to_goal = compute_goal_dist(python_shuffle(array_states[-1, :, :, :],targets),  v, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045466732914726"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 20, 21, 22, 23, 26, 27, 28, 29, 31, 33, 35, 37, 38, 40, 42, 44,\n",
       "        46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66,\n",
       "        68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 89, 90, 91, 92,\n",
       "        93, 95, 96, 99]),)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move = dist_to_goal[:, goal_types[0, 0, :] == 1]\n",
    "gaze = dist_to_goal[:, goal_types[0, 1, :] == 1]\n",
    "nothing = dist_to_goal[:, goal_types[0, 2, :] == 1]\n",
    "\n",
    "no_shuffle = dist_to_goal[:, targets[0, 0, :] == 0]\n",
    "shuffle = dist_to_goal[:, targets[1, 0, :] == 0]\n",
    "\n",
    "same_loc = dist_to_goal[:, (goal_locations[0, :, :] == goal_locations[1, :, :])[0, :]]\n",
    "diff_loc = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :]]\n",
    "\n",
    "diff_n_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]\n",
    "diff_not_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 1)]\n",
    "rest = dist_to_goal[:, ~(goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- rest:\n",
      "---- median:0.28894728041085926\n",
      "---- mean:0.3258696595982576\n",
      "---- max:0.8045466732914726\n",
      "---- third quartile:0.45485963684998665\n",
      "---- ninetieth percentile:0.6157374634030559\n",
      "\n",
      "\n",
      "- diff and shuffle:\n",
      "---- median:0.3432538725496517\n",
      "---- mean:0.35289259951391466\n",
      "---- max:0.8025584511627492\n",
      "---- third quartile:0.4681861486882135\n",
      "---- ninetieth percentile:0.5616923920176826\n",
      "\n",
      "\n",
      "- diff and not shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-01f18624306c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- median:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- mean:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- max:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- third quartile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- ninetieth percentile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_not_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "print(\"- rest:\")\n",
    "print(\"---- median:\" + str(np.median(rest)))\n",
    "print(\"---- mean:\" + str(np.mean(rest)))\n",
    "print(\"---- max:\" + str(np.max(rest)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(rest, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(rest, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_n_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_n_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_n_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_n_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_n_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and not shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_not_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_not_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_not_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_not_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_not_shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045466732914726"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- no_shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5c0e08e46e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- median:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- mean:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- max:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- third quartile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- ninetieth percentile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "print(\"- no_shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(no_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(no_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(no_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(no_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(no_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(shuffle)))\n",
    "print(\"---- max:\" + str(np.max(shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- move:\n",
      "---- median:0.33451158428247263\n",
      "---- mean:0.3453261763375307\n",
      "---- max:0.8045466732914726\n",
      "---- third quartile:0.4622149582380899\n",
      "---- ninetieth percentile:0.5934106536566446\n",
      "\n",
      "\n",
      "- gaze:\n",
      "---- median:nan\n",
      "---- mean:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5dc8361ef0c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- median:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- mean:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- max:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- third quartile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---- ninetieth percentile:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "print(\"- move:\")\n",
    "print(\"---- median:\" + str(np.median(move)))\n",
    "print(\"---- mean:\" + str(np.mean(move)))\n",
    "print(\"---- max:\" + str(np.max(move)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(move, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(move, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- gaze:\")\n",
    "print(\"---- median:\" + str(np.median(gaze)))\n",
    "print(\"---- mean:\" + str(np.mean(gaze)))\n",
    "print(\"---- max:\" + str(np.max(gaze)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(gaze, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(gaze, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- same loc:\n",
      "---- median:0.28894728041085926\n",
      "---- mean:0.3258696595982576\n",
      "---- max:0.8045466732914726\n",
      "---- third quartile:0.45485963684998665\n",
      "---- ninetieth percentile:0.6157374634030559\n",
      "\n",
      "\n",
      "- diff loc:\n",
      "---- median:0.3432538725496517\n",
      "---- mean:0.35289259951391466\n",
      "---- max:0.8025584511627492\n",
      "---- third quartile:0.4681861486882135\n",
      "---- ninetieth percentile:0.5616923920176826\n"
     ]
    }
   ],
   "source": [
    "print(\"- same loc:\")\n",
    "print(\"---- median:\" + str(np.median(same_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(same_loc)))\n",
    "print(\"---- max:\" + str(np.max(same_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(same_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(same_loc, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff loc:\")\n",
    "print(\"---- median:\" + str(np.median(diff_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_loc)))\n",
    "print(\"---- max:\" + str(np.max(diff_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_loc, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances[10, 0, :, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40567913, 0.56070427])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5934106536566446"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(dist_to_goal, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e58bbd5f5f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][-1, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-c5b16d5090f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][0, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:,:, 87].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1c1e03e4d0e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][:, 0, 0:2, 82].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-6df541d46d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "print_stats_agent(array_states[0][-1, :, :, :], goal_locations, goal_types)\n",
    "print_stats_agent(array_states[0][0, :, :, :], goal_locations, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-52c6ba3bf0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_array_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_goal_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "save_array_states = array_states\n",
    "save_goal_locations = goal_locations\n",
    "save_v = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21563244, 0.08816148])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-336f6c0b9b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "v[2, :, nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  [[1]\n",
      " [0]]\n",
      "first [0 1 0]\n",
      "second [0 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35e643f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: [ 2.5 -1. ]\n",
      "second: [1.5 2. ]\n",
      "[[2.  0.5]\n",
      " [2.  0.5]]\n"
     ]
    }
   ],
   "source": [
    "nb = 18\n",
    "print(\"target \", targets[:, :, nb])\n",
    "print(\"first\", goal_types[0, :, nb])\n",
    "print(\"second\", goal_types[1, :, nb])\n",
    "plot_trajectory(array_states[:,1,4:6,nb], goal_locations[0, :, nb], v[0, :, nb])\n",
    "print(\"first:\", goal_locations[0, :, nb])\n",
    "print(\"second:\", goal_locations[1, :, nb])\n",
    "print(v[:, :, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0196078431372549"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_mem_last == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_states[-1, 2:, 0:2, 1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_states[-1, 3:, 0:2, nb], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_types[0, 0, :] == 1) & (goal_types[1, 0, :] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.  , -0.75, -3.  , -0.75, -0.25,  2.5 , -0.75, -0.25,  2.  ,\n",
       "          2.5 ,  2.  ,  2.  , -0.25, -0.25, -0.25, -0.25,  2.5 , -0.25,\n",
       "         -0.75, -0.75,  2.5 ,  1.5 , -0.25,  2.  , -3.  ,  2.5 , -3.  ,\n",
       "         -0.75,  2.  , -0.25,  2.  ,  2.  ,  2.  , -3.  ,  2.  ,  1.5 ,\n",
       "         -0.75,  1.5 ,  1.5 ,  2.  , -0.75, -3.  , -0.25, -3.  , -0.25,\n",
       "         -0.25, -0.25,  2.  , -0.25,  2.  , -0.25,  2.5 , -0.75,  2.  ,\n",
       "          2.5 ,  2.5 , -0.25, -0.75, -0.25, -0.25,  2.5 , -0.75,  1.5 ,\n",
       "         -0.25,  2.5 , -3.  , -0.75, -3.  ,  2.  ,  2.  , -0.75,  2.5 ,\n",
       "         -0.75, -0.75, -0.25,  2.5 ,  1.5 , -3.  ,  1.5 , -0.25,  2.5 ,\n",
       "          2.  , -0.25, -0.25, -0.75,  1.5 ,  2.  , -0.25, -0.75,  2.  ,\n",
       "         -3.  , -0.25, -0.75,  2.  ,  2.  ,  2.  ,  2.  , -3.  ,  1.5 ,\n",
       "         -0.25],\n",
       "        [ 0.5 , -0.5 , -3.  , -0.5 , -2.  , -1.  , -0.5 , -2.  ,  0.5 ,\n",
       "         -1.  ,  0.5 ,  0.5 , -2.  , -2.  , -2.  , -2.  , -1.  , -2.  ,\n",
       "         -0.5 , -0.5 , -1.  ,  2.  , -2.  ,  0.5 , -3.  , -1.  , -3.  ,\n",
       "         -0.5 ,  0.5 , -2.  ,  0.5 ,  0.5 ,  0.5 , -3.  ,  0.5 ,  2.  ,\n",
       "         -0.5 ,  2.  ,  2.  ,  0.5 , -0.5 , -3.  , -2.  , -3.  , -2.  ,\n",
       "         -2.  , -2.  ,  0.5 , -2.  ,  0.5 , -2.  , -1.  , -0.5 ,  0.5 ,\n",
       "         -1.  , -1.  , -2.  , -0.5 , -2.  , -2.  , -1.  , -0.5 ,  2.  ,\n",
       "         -2.  , -1.  , -3.  , -0.5 , -3.  ,  0.5 ,  0.5 , -0.5 , -1.  ,\n",
       "         -0.5 , -0.5 , -2.  , -1.  ,  2.  , -3.  ,  2.  , -2.  , -1.  ,\n",
       "          0.5 , -2.  , -2.  , -0.5 ,  2.  ,  0.5 , -2.  , -0.5 ,  0.5 ,\n",
       "         -3.  , -2.  , -0.5 ,  0.5 ,  0.5 ,  0.5 ,  0.5 , -3.  ,  2.  ,\n",
       "         -2.  ]],\n",
       "\n",
       "       [[ 2.  , -0.75, -3.  , -0.75, -0.25,  2.5 , -0.75, -0.25,  2.  ,\n",
       "          2.5 ,  2.  ,  2.  , -0.25, -0.25, -0.25, -0.25,  2.5 , -0.25,\n",
       "         -0.75, -0.75,  2.5 ,  1.5 , -0.25,  2.  , -3.  ,  2.5 , -3.  ,\n",
       "         -0.75,  2.  , -0.25,  2.  ,  2.  ,  2.  , -3.  ,  2.  ,  1.5 ,\n",
       "         -0.75,  1.5 ,  1.5 ,  2.  , -0.75, -3.  , -0.25, -3.  , -0.25,\n",
       "         -0.25, -0.25,  2.  , -0.25,  2.  , -0.25,  2.5 , -0.75,  2.  ,\n",
       "          2.5 ,  2.5 , -0.25, -0.75, -0.25, -0.25,  2.5 , -0.75,  1.5 ,\n",
       "         -0.25,  2.5 , -3.  , -0.75, -3.  ,  2.  ,  2.  , -0.75,  2.5 ,\n",
       "         -0.75, -0.75, -0.25,  2.5 ,  1.5 , -3.  ,  1.5 , -0.25,  2.5 ,\n",
       "          2.  , -0.25, -0.25, -0.75,  1.5 ,  2.  , -0.25, -0.75,  2.  ,\n",
       "         -3.  , -0.25, -0.75,  2.  ,  2.  ,  2.  ,  2.  , -3.  ,  1.5 ,\n",
       "         -0.25],\n",
       "        [ 0.5 , -0.5 , -3.  , -0.5 , -2.  , -1.  , -0.5 , -2.  ,  0.5 ,\n",
       "         -1.  ,  0.5 ,  0.5 , -2.  , -2.  , -2.  , -2.  , -1.  , -2.  ,\n",
       "         -0.5 , -0.5 , -1.  ,  2.  , -2.  ,  0.5 , -3.  , -1.  , -3.  ,\n",
       "         -0.5 ,  0.5 , -2.  ,  0.5 ,  0.5 ,  0.5 , -3.  ,  0.5 ,  2.  ,\n",
       "         -0.5 ,  2.  ,  2.  ,  0.5 , -0.5 , -3.  , -2.  , -3.  , -2.  ,\n",
       "         -2.  , -2.  ,  0.5 , -2.  ,  0.5 , -2.  , -1.  , -0.5 ,  0.5 ,\n",
       "         -1.  , -1.  , -2.  , -0.5 , -2.  , -2.  , -1.  , -0.5 ,  2.  ,\n",
       "         -2.  , -1.  , -3.  , -0.5 , -3.  ,  0.5 ,  0.5 , -0.5 , -1.  ,\n",
       "         -0.5 , -0.5 , -2.  , -1.  ,  2.  , -3.  ,  2.  , -2.  , -1.  ,\n",
       "          0.5 , -2.  , -2.  , -0.5 ,  2.  ,  0.5 , -2.  , -0.5 ,  0.5 ,\n",
       "         -3.  , -2.  , -0.5 ,  0.5 ,  0.5 ,  0.5 ,  0.5 , -3.  ,  2.  ,\n",
       "         -2.  ]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = np.mean(goal_locations, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.tile(vv, (2, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25, -0.75], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_states[0, 3:, 0:2, 1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-166-2e5bb8609410>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-166-2e5bb8609410>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    array_states.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "array_states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.843392, -7.008334], dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[-1, 0,0:2,nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.58468604,  3.1692955 ,\n",
       "         0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  1.3187793 , -0.6615655 ,\n",
       "         1.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58468605,  3.16929552],\n",
       "       [ 1.31877935, -0.66156551]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58468604,  3.1692955 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 1.3187793 , -0.6615655 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [-0.98659277, -3.7688777 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[-1, 2:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 100)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 100)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]], [[4 for i in range(100)], [4 for i in range(100)]], [[-2 for i in range(100)], [0 for i in range(100)]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2,  0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_landmarks[2, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goal_types = np.array([[[1 for i in range(100)], [0 for i in range(100)], [0 for i in range(100)]], [[1 for i in range(100)], [0 for i in range(100)], [0 for i in range(100)]], [[1 for i in range(100)], [0 for i in range(100)], [0 for i in range(100)]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 100)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKgKSUZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fb445f080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.reward_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKAwEBER4P8DthKf4uukqVwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fb45348d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.voc_reward_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wfkzT1TD/nKNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35bc342208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.mean_act_count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.98"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.mean_act_count[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00478059, 0.02923876],\n",
       "       [4.41817   , 4.4507103 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_outputs[-1, :, :, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.029627  , -0.61482185], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.reward_batch_history[-1][:, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.029627  , 0.61482184])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((array_outputs[-1, [0, 1], :, 50] - goal_locations[[0, 1], :, 50])**2, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.7789516, 1.2834195],\n",
       "       [4.017225 , 1.3816243]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(array_outputs[-1, :, :, :], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.sum(np.sum(array_outputs[-1, :, :, :], axis = 2), axis = 0)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.406772 , 4.3033895],\n",
       "       [8.583255 , 4.4507103]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(array_outputs[-1, :, :, :], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05605835, -0.26878864],\n",
       "       [-0.06561816, -0.35824925]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(array_outputs[-1, :, :, :], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.209854 , 1.8657004],\n",
       "       [3.2325075, 1.9222469]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(array_outputs[-1, :, :, :], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((goal_locations[:, 1, :] == 0).sum(axis = 1))/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7380105721219263"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plx = np.ones((2, 1, 100))*4\n",
    "ply = np.ones((2, 1, 100))*2.28\n",
    "pl = np.concatenate([plx, ply], axis = 1)\n",
    "np.mean(np.sum(np.sqrt(np.sum((pl - goal_locations)**2, axis = 1)), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.75172211500846"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plx = np.ones((2, 1, 100))*4\n",
    "ply = np.ones((2, 1, 100))*1.33\n",
    "pl = np.concatenate([plx, ply], axis = 1)\n",
    "np.mean(np.sum(np.sqrt(np.sum((pl - goal_locations)**2, axis = 1)), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.642781347408684"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plx = np.ones((3, 1))*4\n",
    "ply = np.ones((3, 1))*2.28\n",
    "pl = np.concatenate([plx, ply], axis = 1)\n",
    "np.mean(np.sqrt(np.sum((pl - array_states[-1, 2:, 0:2, 14])**2, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.700211538103295"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plx = np.ones((3, 1))*4\n",
    "ply = np.ones((3, 1))*1.33\n",
    "pl = np.concatenate([plx, ply], axis = 1)\n",
    "np.mean(np.sqrt(np.sum((pl - array_states[-1, 2:, 0:2, 14])**2, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_5:0' shape=(3, 2, 100) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.goal_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_reward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-89624fec0195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_reward' is not defined"
     ]
    }
   ],
   "source": [
    "pred_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.6263475 , -0.17130268],\n",
       "       [ 3.2847695 ,  3.8299196 ]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[-1, :, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [8, 0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = []\n",
    "for i in range(100):\n",
    "    length.append(len(np.unique(np.argmax(array_utterances[:, 0, :, i], axis = 1))))\n",
    "    length.append(len(np.unique(np.argmax(array_utterances[:, 1, :, i], axis = 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 2, 20, 100)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.argmax(array_utterances[:, 0, :, 10], axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn/j/QpC/Zucyp6wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fb45c0f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.mean_act_count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [8, 0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [8, 0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  3, 17, 17,  0,  3,  0,  3,  0,  0,  9,  0,  3,  3,  3,\n",
       "       18,  3,  0,  3,  0,  0,  0,  0,  3,  3,  3,  3,  7,  0,  0,  9,  0,\n",
       "        0,  3,  3,  3,  3,  0,  3,  3,  3,  3, 10,  9,  7,  3,  3, 15,  0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 0, :, 0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10,  0,  0,  0,  0,  3,  3,  9,  0,  0,  3, 13,  3,  0,  3,  0,\n",
       "        0,  3,  3,  3,  9,  0,  3,  9,  7,  9,  0,  3,  4,  4,  0,  3,  9,\n",
       "       14,  0,  3,  0,  0,  0,  3,  0,  0,  9,  3,  0,  0,  0,  3,  3,  3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 0, :, 2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  3,  3,  0,  0,  3,  0,  0,  0,  8,  0,  0,\n",
       "        0,  6,  3,  0,  0,  0,  0,  3,  0,  4,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0, 10,  0,  0,  0,  3,  0,  0,  3,  3,  0,  0,  0,  3])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 1, :, 5], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.voc_reward_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  4,  6,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18, 19])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 15, 18])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, 0, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 15, 18])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, 1, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  9, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, 0, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  5,  9, 10, 18, 19])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2)[:, 1, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0, ...,  0,  0,  0],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]],\n",
       "\n",
       "       [[17,  5,  5, ..., 12,  6,  5],\n",
       "        [ 6,  5,  6, ...,  5,  6,  2]],\n",
       "\n",
       "       [[ 6,  5, 19, ..., 18,  2,  5],\n",
       "        [ 6,  5, 17, ...,  5,  6, 18]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[11,  9,  0, ...,  8,  6,  5],\n",
       "        [ 6,  5,  6, ...,  5,  6,  9]],\n",
       "\n",
       "       [[19, 19, 19, ...,  9, 19,  5],\n",
       "        [ 6,  7,  6, ...,  5,  6,  6]],\n",
       "\n",
       "       [[16,  5, 11, ..., 14,  6,  5],\n",
       "        [ 6,  5,  6, ...,  5,  2, 19]]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-319-33829bdaa630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'array_pred' is not defined"
     ]
    }
   ],
   "source": [
    "array_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.823529411764707"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "150/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.6868453e-04,  9.9153298e-01, -2.8760213e-02,  3.8191910e+00,\n",
       "        4.0793910e+00,  5.5776936e-01,  5.0881344e-01,  3.6988370e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[-1, 1, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 4., 4., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[1, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e-04,\n",
       "       0.000e+00, 0.000e+00, 3.940e-01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "       3.432e-01, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e-04, 2.626e-01,\n",
       "       0.000e+00, 0.000e+00], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(exp.array_utt[-1], axis = (0, 1, 3))/np.sum(exp.array_utt[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.00e+00, 3.00e+00, 2.00e+00, 8.00e+00, 4.00e+00, 7.00e+00,\n",
       "       2.00e+00, 6.20e+01, 3.00e+01, 1.00e+00, 9.81e+03, 1.10e+01,\n",
       "       0.00e+00, 1.00e+01, 1.20e+01, 4.00e+00, 1.20e+01, 6.00e+00,\n",
       "       5.00e+00, 4.00e+00], dtype=float32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(exp.array_utt[-23], axis = (0, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.24"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.mean_act_count[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-661.3527"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.reward_history[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.Variable(np.sum(exp.array_utt[-3], axis = (0, 1, 3)))\n",
    "u = tf.gather(v, tf.where(tf.not_equal(v, 0)))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    ee = sess.run(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.000e+00],\n",
       "       [8.000e+00],\n",
       "       [4.220e+03],\n",
       "       [5.000e+00],\n",
       "       [5.000e+00],\n",
       "       [4.000e+00],\n",
       "       [1.800e+01],\n",
       "       [5.000e+00],\n",
       "       [1.410e+03],\n",
       "       [6.000e+00],\n",
       "       [6.000e+00],\n",
       "       [2.000e+00],\n",
       "       [5.000e+00],\n",
       "       [3.000e+00],\n",
       "       [5.900e+01],\n",
       "       [7.000e+00],\n",
       "       [7.000e+00],\n",
       "       [2.117e+03],\n",
       "       [2.106e+03]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp.voc_reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.00000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  7,  7,  7,  8, 15,  8,  8,  8, 15,  8,  8,  7,  7, 15, 15, 15,\n",
       "        8,  7,  7,  7,  8, 15,  7,  7,  7,  8,  8,  8, 15,  8,  7,  8,  7,\n",
       "        7, 15,  7,  7,  8,  7, 15,  8, 15,  8,  8,  8,  7, 15,  7,  8,  7,\n",
       "        8,  7, 15,  8,  7,  7, 15,  8, 15,  8, 15,  8,  8,  7,  7,  8,  8,\n",
       "        7,  8, 15, 15,  8, 15,  8,  7,  7, 15,  7,  8,  8, 15, 15, 15,  7,\n",
       "       15,  7,  7, 15,  7, 15,  8,  8,  7, 15, 15, 15,  8,  7,  8,  8,  8,\n",
       "        8,  7, 15, 15, 15,  8,  7, 15,  7, 15,  7,  8,  8,  8,  7, 15,  7,\n",
       "       15, 15,  7,  8,  8,  8, 15, 15, 15, 15,  7,  7, 15,  7, 15,  8,  8,\n",
       "        8, 15,  8, 15, 15,  8,  8,  8,  7, 15,  7, 15,  7,  8,  8, 15,  7,\n",
       "        7,  8,  7,  7, 15,  7,  8,  8,  7,  7, 15,  7,  8,  8,  7,  7, 15,\n",
       "       15,  8, 15,  7,  7,  8,  7,  8, 15, 15,  7, 15,  7, 15,  8, 15,  8,\n",
       "       15,  8, 15,  8,  8,  8, 15,  7, 15,  7,  7,  7, 15,  8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances, axis = 2)[:, 0, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.57926386,  1.09727604],\n",
       "       [-1.57926386,  1.09727604]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.48238987, 0.9266134 ,\n",
       "        1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.45202035, 1.5437603 ,\n",
       "        0.        , 1.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.grads_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = tf.Variable(0.0)\n",
    "init = tf.global_variables_initializer()\n",
    "v = tf.log(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    ee = sess.run(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27.631021115928547"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 2 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-8d5de4502d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgoal_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 2 with size 100"
     ]
    }
   ],
   "source": [
    "goal_types[:, :, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 13, 16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances[1:, :, :, :], axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "landmark_nb = [np.random.choice(3, (2, 1), replace = True) for _ in range(FLAGS.batch_size)]\n",
    "landmark_nb_batch = np.stack(landmark_nb, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_nb[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, 3:6, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20028409, -0.96775521],\n",
       "       [ 0.86976883,  0.97217373]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10546685, -0.38599977,  0.        ,  0.        ,  1.4818624 ,\n",
       "        -0.6813463 ,  1.        ,  0.        ,  0.        ],\n",
       "       [-0.23637994,  0.06048546,  0.        ,  0.        ,  1.9055567 ,\n",
       "         1.469917  ,  0.        ,  1.        ,  0.        ],\n",
       "       [-0.2568565 , -0.13294637,  0.        ,  0.        , -1.2636497 ,\n",
       "        -0.06211003,  0.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0, 2:, :, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 17, 17,  5, 17,  5,  5,  5, 17, 17, 17, 17,  5, 17,  5,  5, 17,\n",
       "       17, 17,  5, 17,  5, 17, 17, 17, 17, 17,  5, 17, 17, 17,  5,  5,  5,\n",
       "        5,  5, 17,  5, 17,  5,  5,  5, 17, 17,  5, 17,  5,  5,  5,  5,  5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 1, :, 2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5, -0.5],\n",
       "       [-1. , -1. ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5, -0.5],\n",
       "       [-1. , -1. ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  1. ,  0. ,  1.5, -0.5,  0. ,  1. ,  0. ],\n",
       "       [ 0. ,  1. ,  0. , -1. , -1. ,  1. ,  0. ,  0. ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_goals[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, : ,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.0697347e-03,  1.0513390e+00,  2.2460965e-02,  2.4765704e+00,\n",
       "        -1.0961896e+00,  5.0263029e-01,  4.7486654e-01, -3.6538243e-03],\n",
       "       [-4.0758252e-03,  1.0102042e+00, -2.4224397e-02, -3.0727093e+00,\n",
       "        -3.0304856e+00,  5.5312365e-01,  4.2007229e-01,  2.5203116e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[-1, :, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ,  0. ,  0. ],\n",
       "       [-1. , -1. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ,  0. ],\n",
       "       [ 1.5, -0.5,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[-1, 2:, :, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[:, :, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3. , -3. ],\n",
       "       [ 2.5, -1. ]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:,:, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[:, 0, :, 12], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
