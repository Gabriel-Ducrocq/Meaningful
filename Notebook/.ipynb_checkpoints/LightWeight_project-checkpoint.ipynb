{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from datetime import datetime\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "#%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "#0.0008\n",
    "flags.DEFINE_float('learning_rate', 0.0008, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('max_steps', 50000, 'Number of iteration to train.')\n",
    "flags.DEFINE_integer('number_layers', 3, 'Number of layers in each network')\n",
    "flags.DEFINE_integer('layer_sizes', 256, 'Number of units in hidden layer.')\n",
    "flags.DEFINE_integer('batch_size', 100, 'Batch size.')\n",
    "flags.DEFINE_integer('dim_env', 2, 'dimension of the environment')\n",
    "flags.DEFINE_integer('number_goal_types', 3, 'number of different goal types')\n",
    "flags.DEFINE_integer('color_size', 3, 'number of components of the color: RGB as usual')\n",
    "flags.DEFINE_integer(\"output_size\", 256, \"number of units in the output layer\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.9, \"Dropouts rate of keeping\")\n",
    "flags.DEFINE_boolean(\"xav_init\", False,\"Distribution of initialization: False for normal, True for uniform\" )\n",
    "flags.DEFINE_integer(\"number_agents\", 2, \"Number of agents in the environment\")\n",
    "flags.DEFINE_integer(\"number_landmarks\", 3, \"Number of landmarks in the environment\")\n",
    "flags.DEFINE_integer(\"vocabulary_size\", 20, \"Size of the vocabulary\")\n",
    "flags.DEFINE_integer(\"mem_size\", 32, \"Size of the communication network's memory\")\n",
    "flags.DEFINE_integer(\"last_mem_size\", 32, \"Size of the last network's memory\")\n",
    "flags.DEFINE_float(\"gumbel_temperature\", 1, \"Temperature use for the gumbel softmax trick\")\n",
    "flags.DEFINE_float(\"sddev_phys_sampling\", 0.0001, \"Standard deviation used to sample the velocity and gaze output\")\n",
    "flags.DEFINE_float(\"delta_t\", 0.5, \"delta of time between timesteps\")\n",
    "flags.DEFINE_float(\"damping_coef\", 0.5, \"damping coefficient for the new velocity computation\")\n",
    "flags.DEFINE_float(\"stddev_memory\", 0.0001, \"standard deviation of the gaussian used to update memories\")\n",
    "flags.DEFINE_integer(\"bound\", 5, \"Bounds of generation of initial positions, centered in 0.\")#5 usually\n",
    "flags.DEFINE_integer(\"time_horizon\", 50, \"Number of timestep before the end of the experiment.\")\n",
    "flags.DEFINE_integer(\"print_frequency\", 500, \"Frequency at which we print the reward, in number of steps.\")#1\n",
    "flags.DEFINE_boolean(\"learning_rate_decay\", True, \"Wether to use a piecewise learning rate decay or no decay at all\")\n",
    "flags.DEFINE_integer(\"tensorboard_freq\", 500, \"Frequency at which we save the statistics in tensorflow\")\n",
    "flags.DEFINE_float(\"alpha_dirichlet\", 0.1, \"Probability of seeing an out of vocabulary word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire:\n",
    "\n",
    "- Checker que le softmax pooling est correct\n",
    "\n",
    "- Checker que le gumbel trick est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le sampling physique est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le calcul du nouvel état est correct, notamment sur les débuts et longueur de slicing et concaténation\n",
    "\n",
    "- Ajouter le calcul des forces dans le calcul du nouvel état\n",
    "\n",
    "- Vérifier que le shuffling est correct\n",
    "\n",
    "- Vérifier que le calcul du reward est correct\n",
    "\n",
    "- Vérifier que la backprop considère bien les variables broadcastées comme les mêmes.\n",
    "\n",
    "- Vérifier que le tenseur states est bien dans cet ordre sur le second axe: position, velocité, gaze, couleurs\n",
    "\n",
    "- RELIER LES LANDMARKS AUX POSITIONS DES GOALS, SINON CA N A PAS DE SENS !!!\n",
    "\n",
    "- Checker que les goals types sont bien distribués: une unique coordonnée doit être 1, les autres 0, et ce pour chaque agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory():\n",
    "    import os\n",
    "    import psutil\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "    print('memory use:', memoryUse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_trajectory(coordinates, target_point, middle_point):\n",
    "    x = coordinates[1:-1, 0]\n",
    "    y = coordinates[1:-1, 1]\n",
    "    \n",
    "    x_start = coordinates[0, 0]\n",
    "    y_start = coordinates[0, 1]\n",
    "    \n",
    "    x_final = coordinates[-1, 0]\n",
    "    y_final = coordinates[-1, 1]\n",
    "    \n",
    "    x_target, y_target = target_point\n",
    "    x_middle, y_middle = middle_point\n",
    "    \n",
    "    plt.plot(x,y, \"o\")\n",
    "    plt.plot(x_start, y_start, 'ro')\n",
    "    plt.plot(x_target, y_target, 'go')\n",
    "    plt.plot(x_final, y_final, 'yo')\n",
    "    plt.plot(x_middle, y_middle, 'mo')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-FLAGS.bound, FLAGS.bound])\n",
    "    axes.set_ylim([-FLAGS.bound, FLAGS.bound])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def python_shuffle(positions, shuffle_indexes):\n",
    "    shuffled_array = np.stack(\n",
    "    [positions[shuffle_indexes[: , 0, i], :, i] for i in range(FLAGS.batch_size)], axis = 2)\n",
    "    return shuffled_array\n",
    "    \n",
    "    \n",
    "def delete_history_files():\n",
    "    if os.path.isfile(\"env_history.pkl\"):\n",
    "        os.remove(\"env_history.pkl\")\n",
    "        \n",
    "    if os.path.isfile(\"arrays_history.pkl\"):\n",
    "        os.remove(\"arrays_history.pkl\")\n",
    "        \n",
    "    if Path(\"Summary\").is_dir():\n",
    "        shutil.rmtree(\"Summary\")\n",
    "\n",
    "\n",
    "def print_stat_vocabulary(utterances_array, l):\n",
    "    x = np.argmax(utterances_array, axis = 2)\n",
    "    r = []\n",
    "    for i in range(FLAGS.batch_size):\n",
    "        r.append(len(np.unique(x[:, :, i])))\n",
    "    \n",
    "    if l%FLAGS.print_frequency == 0:\n",
    "        print(\"-- Stats word count:\")\n",
    "        print(\"---- Mean number of word activated: \" + str(np.mean(r)))\n",
    "        print(\"---- Median number of word activated: \" + str(np.median(r)))\n",
    "        print(\"---- Total number of word activated: \" + str(len(np.unique(x))))\n",
    "        \n",
    "    return np.mean(r)\n",
    "    \n",
    "        \n",
    "def dirichlet_log_lik_end(utterances_array):\n",
    "    #Note: we don't take minus the log-likelihood as we minimize minus the entire reward then !\n",
    "    by_symbol = tf.reduce_sum(utterances_array, axis =[0, 1, 3])\n",
    "    total_nb_uttered = FLAGS.number_agents*FLAGS.time_horizon*FLAGS.batch_size\n",
    "    ratio = by_symbol/(FLAGS.alpha_dirichlet + total_nb_uttered - 1)\n",
    "    #ratio = by_symbol/(FLAGS.alpha_dirichlet + tf.reduce_sum(utterances_array) - 1)\n",
    "    terms = tf.gather(tf.log(ratio)*by_symbol, tf.where(tf.not_equal(by_symbol, 0)))\n",
    "    log_likelihood = tf.reduce_sum(terms)\n",
    "    log_likelihood = tf.Print(log_likelihood, [log_likelihood])\n",
    "    return log_likelihood\n",
    "    \n",
    "    \n",
    "# Param: x, stacking of the output of fully connected physical network for each agent. Shape = (256, batch_size, nb_agents)\n",
    "# return: pooling of input features.\n",
    "def softmax_pooling(x):\n",
    "    # pooling function. Softmax pooling is a compromise between max pooling and average pooling\n",
    "    coefs = tf.nn.softmax(x, dim = 0)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = 0)\n",
    "    return softmax_pool\n",
    "\n",
    "\n",
    "def activation_function(x):\n",
    "    return tf.nn.elu(x)\n",
    "\n",
    "\n",
    "def gumbel_max_trick(x, hard = True):\n",
    "    # Application of gumbel-softmax trick\n",
    "    # Input: output of the last network \n",
    "    u = -tf.log(-tf.log(tf.random_uniform(shape = [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size],\n",
    "                                          dtype=tf.float32)))\n",
    "    utterance_output = tf.slice(x, [0, 2*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "    gumbel = tf.exp((utterance_output + u)/FLAGS.gumbel_temperature)\n",
    "    denoms = tf.reshape(tf.reduce_sum(gumbel, axis = 1), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    utterance = gumbel/denoms\n",
    "    if hard:\n",
    "        idx_utt = tf.argmax(utterance, axis = 1)\n",
    "        utt_hard = tf.transpose(tf.one_hot(idx_utt, depth = FLAGS.vocabulary_size), [0, 2, 1])\n",
    "        utterance = tf.stop_gradient(utt_hard - utterance) + utterance\n",
    "        \n",
    "    return utterance \n",
    "\n",
    "\n",
    "def sample_phys(x):\n",
    "    #Input: output of the last network.\n",
    "    #Output: sampled values for new velocity and gaze\n",
    "    u = tf.random_normal(shape = [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size],dtype=tf.float32,\n",
    "                         stddev = FLAGS.sddev_phys_sampling)\n",
    "    o = tf.add(tf.slice(x, [0, 0, 0], [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size]), u)\n",
    "    sample_move = tf.slice(o, [0, 0, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    sample_gaze  = tf.slice(o, [0, FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    return sample_move, sample_gaze\n",
    "\n",
    "\n",
    "def compute_new_states(old_states, new_velocities, new_delta_gazes, new_utterances):\n",
    "    #Computes the new states according to the equations of the papers.\n",
    "    # Input: the old states of shape [number agents + nb_landmarks, 3*env dim + color size, batch size] because color is in state\n",
    "    # and of shape [number_agents, 2*env_dim, batch size]\n",
    "    # Adding the outputs of landmark, which are all zeros.\n",
    "    #new_velocities = tf.concat([new_velocities, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "\n",
    "    #new_delta_gazes = tf.concat([new_delta_gazes, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "    \n",
    "    #old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #new_pos = tf.slice(old_states, [0, 0, 0], \n",
    "    #                   [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    #new_gazes = old_gazes + new_delta_gazes*FLAGS.delta_t\n",
    "    \n",
    "    #new_velocity = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    \n",
    "    old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents , FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    new_pos_agents = tf.slice(old_states, [0, 0, 0], \n",
    "                       [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    new_pos_landmarks = tf.slice(old_states, [FLAGS.number_agents, 0, 0], \n",
    "                       [FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_pos = tf.concat([new_pos_agents, new_pos_landmarks], axis = 0)\n",
    "    \n",
    "    new_gazes_agents = old_gazes + new_delta_gazes*FLAGS.delta_t\n",
    "    new_gazes_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_gazes = tf.concat([new_gazes_agents, new_gazes_landmarks], axis = 0)\n",
    "    \n",
    "    new_velocity_agents = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    new_velocity_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_velocity = tf.concat([new_velocity_agents, new_velocity_landmarks], axis = 0)\n",
    "    \n",
    "    colors = tf.slice(old_states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                            FLAGS.color_size, FLAGS.batch_size])\n",
    "    new_states = tf.concat([new_pos, new_velocity, new_gazes, colors], axis = 1)\n",
    "\n",
    "    return new_states, new_pos, new_gazes\n",
    "\n",
    "\n",
    "\n",
    "def compute_new_memories(old_mem_com, old_mem_last, delta_mem_com, delta_mem_last):\n",
    "    new_memory_com = tf.tanh((2/3)*(old_mem_com + delta_mem_com + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    new_memory_last = tf.tanh((2/3)*(old_mem_last + delta_mem_last + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    \n",
    "    return new_memory_com,new_memory_last\n",
    "\n",
    "\n",
    "\n",
    "def shuffle(x, name_targets, colors = False):\n",
    "    slices_second_dim = []\n",
    "    ones = tf.ones([FLAGS.number_agents, 1, FLAGS.batch_size], tf.int32)\n",
    "    batch_num = tf.tile(tf.reshape(tf.range(0, FLAGS.batch_size, dtype = tf.int32), [1, 1, FLAGS.batch_size]), [FLAGS.number_agents,\n",
    "                                                                                                               1, 1])\n",
    "    if not colors:\n",
    "        for i in range(FLAGS.dim_env):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "    else:\n",
    "        for i in range(FLAGS.color_size):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "            \n",
    "    gathering_tensor = tf.transpose(tf.concat(slices_second_dim, axis = 1), perm = [0, 1, 3, 2])\n",
    "    shuffled_x = tf.gather_nd(x, gathering_tensor)\n",
    "    \n",
    "    return shuffled_x\n",
    "    \n",
    "    \n",
    "def compute_reward(positions, gazes, outputs, utterances, name_targets, goals_loc, goals_types):\n",
    "    shuffled_positions = shuffle(positions, name_targets)\n",
    "    shuffled_gazes = shuffle(gazes, name_targets)\n",
    "\n",
    "    pos_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_positions - goals_loc)), axis = 1), [FLAGS.number_agents, 1, \n",
    "                                                                                                     FLAGS.batch_size])\n",
    "\n",
    "    gaze_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_gazes - goals_loc)), axis = 1), [FLAGS.number_agents, 1,\n",
    "                                                                                                     FLAGS.batch_size])\n",
    "    zeros = tf.zeros([FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    x = tf.concat([pos_distances, gaze_distances, zeros], axis = 1)\n",
    "\n",
    "    dists_goal = -tf.reduce_sum(tf.multiply(x, goals_types), axis = 1)\n",
    "    \n",
    "    utterances_term = -tf.reduce_sum(tf.square(utterances), axis = 1)\n",
    "    output_term = -tf.reduce_sum(tf.square(outputs), axis = 1)\n",
    "    \n",
    "    reward_by_batch = tf.reshape(tf.reduce_sum(dists_goal + utterances_term + output_term, axis = 0), [FLAGS.batch_size, 1])\n",
    "\n",
    "    return reward_by_batch\n",
    "\n",
    "\n",
    "\n",
    "def compute_goal_dist(states, goal_location, goal_type):\n",
    "    dist_positions = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 0:2, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    dist_gazes = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 4:6, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    v = np.concatenate([dist_positions, dist_gazes, np.zeros((FLAGS.number_agents, 1, FLAGS.batch_size))], axis = 1)\n",
    "    goal_distances = np.sum(np.multiply(v, goal_type), axis = 1)\n",
    "    \n",
    "    return goal_distances\n",
    "\n",
    "\n",
    "def print_stats_agent(states, goal_location, goal_type, targets):\n",
    "    #Only considering non \"do nothing goals\"\n",
    "    shuffled_states = python_shuffle(states, targets)\n",
    "    goal_distances = compute_goal_dist(shuffled_states, goal_location, goal_type)\n",
    "    \n",
    "    for i in range(FLAGS.number_agents):\n",
    "        distances_agents = goal_distances[i, :]\n",
    "        goal_wo_zeros = distances_agents[distances_agents != 0]\n",
    "        mean = np.mean(goal_wo_zeros)\n",
    "        median = np.median(goal_wo_zeros)\n",
    "        third_quart = np.percentile(goal_wo_zeros, 75)\n",
    "        nine_pct = np.percentile(goal_wo_zeros, 90)\n",
    "        max_dist = np.max(distances_agents)\n",
    "        argmax = np.argmax(distances_agents)\n",
    "        print(\"--- Agent \" + str(i))\n",
    "        print(\"------ Mean distance \" + str(mean))\n",
    "        print(\"------ Median distance \" + str(median))\n",
    "        print(\"------ Third quartile \" + str(third_quart))\n",
    "        print(\"------ Ninetieth percentile \" + str(nine_pct))\n",
    "        print(\"------ max distance \" + str(max_dist))\n",
    "        print(\"------ argmax distance \" + str(argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the physical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 3*FLAGS.dim_env + FLAGS.color_size\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, number of inputs]\n",
    "        #This shape enables us to handle all the agents/landmarks states at once, instead of dealing with list of agents' states\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.layer_sizes, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.output_size, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): \n",
    "        # Compute a forward pass through the network\n",
    "        # Input: a tensor of shape [number of agents, size of input, batch _size]\n",
    "        # Output: a tensor of shape [number of agents, output_size, batch_size]\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "                else:\n",
    "                    x = activation_function(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the communication network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CommunicationNet: \n",
    "    \n",
    "    def __init__(self):    \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"com_memory_read_weight\", shape = [1, FLAGS.output_size, FLAGS.mem_size],\n",
    "                                               initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, vocabulary size]\n",
    "        #This shape enables us to handle all the agents utterances at once, instead of dealing with list of agents' states        \n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.vocabulary_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.output_size, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])  \n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        # Initialization of the weights and biases writing in the memory.\n",
    "        # Their shape are of the form [number of agents, memory_size, output size] and [number of agents, output size, 1]\n",
    "        # So that we can handle the memories of all agents at onces instead of dealing with list of memories.\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_com\" , shape=[1, FLAGS.mem_size,FLAGS.output_size],\n",
    "                            initializer=tf.orthogonal_initializer()), \n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_com\", shape = [1, FLAGS.mem_size, 1],\n",
    "                            initializer=tf.orthogonal_initializer()),\n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LastNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 2*FLAGS.output_size + FLAGS.color_size + FLAGS.number_goal_types + FLAGS.dim_env\n",
    "        self.output_size = 2*FLAGS.dim_env + FLAGS.vocabulary_size\n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"reading_last_mem_weight\", shape = [1, self.output_size, FLAGS.last_mem_size],\n",
    "                                              initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, self.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, self.output_size, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_last\", shape=[1, FLAGS.last_mem_size ,self.output_size],\n",
    "                                initializer=tf.orthogonal_initializer()),\n",
    "                                 [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_last\" ,shape = [1, FLAGS.last_mem_size, 1], \n",
    "                                    initializer=tf.orthogonal_initializer()),\n",
    "                                  [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "               \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the policy: putting all the networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.phys_network = PhysicalNet()\n",
    "        self.comm_network = CommunicationNet()\n",
    "        self.last_network = LastNet()\n",
    "        \n",
    "        self.define_placeholders()\n",
    "        self.define_full_goals()\n",
    "        \n",
    "        \n",
    "    def define_placeholders(self):\n",
    "        self.states = tf.placeholder(tf.float32, [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                  3*FLAGS.dim_env + FLAGS.color_size, FLAGS.batch_size])\n",
    "        self.utterances = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "        self.memories_com = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size])\n",
    "        self.memories_last = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size])\n",
    "        self.goal_types = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.number_goal_types, FLAGS.batch_size])\n",
    "        self.goal_locations = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        self.name_targets = tf.placeholder(tf.int32, [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "        #self.colors = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        \n",
    "        \n",
    "    def define_full_goals(self):\n",
    "        colors = tf.slice(self.states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        shuffled_colors = shuffle(colors, self.name_targets, colors = True)\n",
    "        self.full_goals = tf.concat([self.goal_types, self.goal_locations, shuffled_colors], axis = 1)\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.states, self.utterances, self.memories_com, self.memories_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets]\n",
    "        \n",
    "    def forward_pass(self, states, utterances, mem, mem_last, goals_last):\n",
    "        #Step 1: processing observed states and utterances\n",
    "        phys_output = self.phys_network.compute_output(states)\n",
    "        comm_output, delta_mem_com = self.comm_network.compute_output(utterances, mem)\n",
    "        \n",
    "        #Step 2: softmax pooling the results [num_agents, output size, batch_size] --> [1, output size, batch_size]\n",
    "        PhiX = softmax_pooling(phys_output)\n",
    "        PhiC = softmax_pooling(comm_output)\n",
    "        \n",
    "        #Step 3: feeding the last network      \n",
    "        PhiX_last = tf.tile(tf.reshape(PhiX, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        PhiC_last = tf.tile(tf.reshape(PhiC, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        input_last = tf.concat([PhiX_last, goals_last, PhiC_last], axis = 1)\n",
    "        \n",
    "        output_last, delta_mem_last = self.last_network.compute_output(input_last, mem_last)\n",
    "        \n",
    "        velocities_output, gazes_output = sample_phys(output_last)\n",
    "        utterances_output = gumbel_max_trick(output_last)\n",
    "        phys_output = tf.concat([velocities_output, gazes_output], axis = 1)\n",
    "        \n",
    "        return phys_output, velocities_output, gazes_output, utterances_output, delta_mem_com, delta_mem_last\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.enc = OneHotEncoder(n_values=FLAGS.number_goal_types, sparse=False)\n",
    "        self.colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)] \n",
    "        self.cols, self.cols_agents, self.cols_landmarks = self.create_colors()\n",
    "    \n",
    "    \n",
    "    def create_colors(self):\n",
    "        cols_agents = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_agents)], axis = 0)\n",
    "        cols_landmarks = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_landmarks)], axis = 0)\n",
    "        \n",
    "        cols = np.concatenate([cols_agents, cols_landmarks], axis = 0)\n",
    "            \n",
    "        return cols, cols_agents, cols_landmarks\n",
    "            \n",
    "        \n",
    "    def create_consistent_targets(self):\n",
    "        targets_by_exp = [np.random.choice(FLAGS.number_agents, (FLAGS.number_agents, 1), replace = False) for _ in range(FLAGS.batch_size)]\n",
    "        #targets_by_exp1 = np.stack([np.array([[1], [0]]) for _ in range(int(FLAGS.batch_size/2))], axis = 2)\n",
    "        #targets_by_exp2 = np.stack([np.array([[0], [1]]) for _ in range(int(FLAGS.batch_size/2.0))], axis = 2)\n",
    "        #targets_batch = np.concatenate([targets_by_exp1, targets_by_exp2], axis = 2)\n",
    "        targets_batch = np.stack(targets_by_exp, axis = 2)\n",
    "        return targets_batch\n",
    "    \n",
    "    def create_goal_locations(self, pos_landmarks):\n",
    "        landmark_nb = [np.random.choice(FLAGS.number_landmarks, (FLAGS.number_agents, 1), replace = True) for _ in range(FLAGS.batch_size)]\n",
    "        landmark_nb_batch = np.stack(landmark_nb, axis = 2)\n",
    "        \n",
    "        goal_loc = python_shuffle(pos_landmarks, landmark_nb_batch)\n",
    "        \n",
    "        return goal_loc\n",
    "        \n",
    "        \n",
    "    def random_generation(self):\n",
    "        positions_agents = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        #positions_agents = np.array([[[1 for i in range(100)], [1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        \n",
    "        positions_landmarks = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        #positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]], [[4 for i in range(100)], [4 for i in range(100)]]])\n",
    "        #positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]]])\n",
    "        #gazes_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]]])\n",
    "        positions = np.concatenate([positions_agents, positions_landmarks], axis = 0)\n",
    "        \n",
    "        gazes = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        #gazes_agents = np.array([[[1 for i in range(100)], [1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        #gazes = np.concatenate([gazes_agents, gazes_landmarks], axis = 0)\n",
    "        #velocities = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "        #                                                     FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        velocities = np.zeros([FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        \n",
    "        #goal_locations = np.random.uniform(-FLAGS.bound, FLAGS.bound, [FLAGS.number_agents, \n",
    "        #                                                          FLAGS.dim_env, FLAGS.batch_size])\n",
    " \n",
    "        goal_locations = self.create_goal_locations(positions_landmarks)\n",
    "        \n",
    "        goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "                        np.random.choice(FLAGS.number_goal_types, FLAGS.batch_size).reshape(-1,1))), \n",
    "                                  [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "        #goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "        #                np.random.choice([0,1], FLAGS.batch_size).reshape(-1,1))), \n",
    "        #                          [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "\n",
    "        #goal_types = np.array([[[1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]] for m in range(2)])\n",
    "        utterances = np.zeros((FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size))\n",
    "        memories_com = np.zeros((FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size))\n",
    "        memories_last = np.zeros((FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size))\n",
    "        \n",
    "        states = np.concatenate([positions, velocities, gazes, self.cols], axis = 1)\n",
    "        targets = self.create_consistent_targets()\n",
    "\n",
    "        return states, utterances, memories_com, memories_last, goal_locations, goal_types, targets\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.policy = Policy()\n",
    "        self.env = Environment()\n",
    "        delete_history_files()\n",
    "        \n",
    "        self.get_placeholders()\n",
    "        self.definition_arrays()\n",
    "        self.write_arrays()\n",
    "        self.learning_rate = self.learning_rate_decay()\n",
    "        tf.summary.scalar('learning rate', self.learning_rate)\n",
    "        #self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.loop()\n",
    "        self.output_to_run = [self.step, self.array_states_stack, self.array_utterances_stack, self.array_mem_com_stack, self.array_mem_last_stack, \n",
    "                                self.f_g , self.array_outputs_stack, self.t_fin, self.reward, self.phys_reward, self.voc_reward]\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "        self.reward_history = []\n",
    "        self.voc_reward_history = []\n",
    "        self.env_history = []\n",
    "        self.arrays_history = []\n",
    "        self.mean_act_count = []\n",
    "        \n",
    "        self.utt_hist = []\n",
    "        self.grads_history = []\n",
    "        self.vars_history = []\n",
    "        \n",
    "        \n",
    "    def learning_rate_decay(self):\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        if FLAGS.learning_rate_decay:\n",
    "            starter_learning_rate = FLAGS.learning_rate\n",
    "            boundaries = [3000] #, 10000]\n",
    "            values = [FLAGS.learning_rate, FLAGS.learning_rate/10] #, FLAGS.learning_rate/100]\n",
    "            return tf.train.piecewise_constant(self.global_step, boundaries, values, name=None)\n",
    "        else:\n",
    "            return FLAGS.learning_rate\n",
    "        \n",
    "    def definition_arrays(self):\n",
    "        # Create goals vectors \n",
    "        self.array_states = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_utterances = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_com = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_last = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_outputs = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        \n",
    "    def get_placeholders(self):\n",
    "        [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets] = self.policy.get_placeholders()\n",
    "            \n",
    "            \n",
    "    def write_arrays(self):\n",
    "        self.array_states = self.array_states.write(0, self.states)\n",
    "        self.array_utterances = self.array_utterances.write(0, self.utterances)\n",
    "        self.array_mem_com = self.array_mem_com.write(0, self.mem_com)\n",
    "        self.array_mem_last = self.array_mem_last.write(0, self.mem_last)\n",
    "        self.array_outputs = self.array_outputs.write(0, np.zeros((FLAGS.number_agents, 4, FLAGS.batch_size), dtype = np.float32))\n",
    "        \n",
    "    def loop(self):\n",
    "        t = tf.constant(0)\n",
    "        return_sofar = tf.zeros([FLAGS.batch_size, 1], tf.float32)\n",
    "        args = [self.array_states, self.array_utterances, self.array_mem_com, self.array_mem_last, self.goal_types, \n",
    "                self.goal_locations, self.full_goals, self.name_targets, self.array_outputs, t, return_sofar]\n",
    "        \n",
    "        (array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t_fin, rewards_batch) = tf.while_loop(self.condition, self.body, args, parallel_iterations=1)\n",
    "        \n",
    "        self.array_states_stack = array_states.stack()\n",
    "        self.array_utterances_stack = array_utterances.stack() \n",
    "        self.array_mem_com_stack = array_mem_com.stack() \n",
    "        self.array_mem_last_stack = array_mem_last.stack() \n",
    "        self.array_outputs_stack = array_outputs.stack()\n",
    "        \n",
    "        self.phys_reward = tf.reshape(tf.reduce_mean(rewards_batch, axis = 0), [])\n",
    "        self.voc_reward = dirichlet_log_lik_end(tf.slice(self.array_utterances_stack, [1, 0, 0, 0], [FLAGS.time_horizon, FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size]))\n",
    "        self.f_g = full_goals\n",
    "        self.t_fin = t_fin, \n",
    "        self.reward = self.phys_reward + self.voc_reward\n",
    "        \n",
    "        tf.summary.scalar('accuracy', -self.reward)\n",
    "        self.grads = self.optimizer.compute_gradients(-self.reward)\n",
    "        self.clipped_gradients = [(tf.clip_by_norm(grad, 0.0001), var) for grad, var in self.grads]\n",
    "        self.step = self.optimizer.apply_gradients(self.clipped_gradients, global_step=self.global_step)\n",
    "        for index, grad in enumerate(self.clipped_gradients):\n",
    "            tf.summary.histogram(\"{}-grad\".format(self.clipped_gradients[index][1].name), self.clipped_gradients[index]) \n",
    "    \n",
    "        \n",
    "    def body(self, array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar):\n",
    "        \n",
    "        #Reading the last state of environment\n",
    "        states = array_states.read(t)\n",
    "        utterances = array_utterances.read(t)\n",
    "        mem_com = array_mem_com.read(t)\n",
    "        mem_last = array_mem_last.read(t)\n",
    "        \n",
    "        phys_output, new_velocities, new_delta_gazes, new_utterances, delta_mem_com, delta_mem_last = self.policy.forward_pass(states,\n",
    "                                                                    utterances, mem_com, mem_last, full_goals)\n",
    "\n",
    "        new_states, new_positions, new_gazes = compute_new_states(states, new_velocities, new_delta_gazes, new_utterances)\n",
    "\n",
    "        new_mem_com, new_mem_last = compute_new_memories(mem_com, mem_last, delta_mem_com, delta_mem_last)\n",
    "        \n",
    "        return_sofar += compute_reward(new_positions, new_gazes, phys_output, new_utterances, name_targets, goal_locations, \n",
    "                                        goal_types)\n",
    "\n",
    "        #Writing the new state\n",
    "        array_states = array_states.write((t+1), new_states)\n",
    "        array_utterances = array_utterances.write((t+1), new_utterances)\n",
    "        array_mem_com = array_mem_com.write((t+1), new_mem_com)\n",
    "        array_mem_last = array_mem_last.write((t+1), new_mem_last)\n",
    "        array_outputs = array_outputs.write((t+1), phys_output)\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "        return [array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar]\n",
    "        \n",
    "        \n",
    "    def condition(self, array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar):\n",
    "        return tf.less(t, FLAGS.time_horizon)\n",
    "    \n",
    "    \n",
    "    def create_feed_dict(self, states, utterances, memories_com, memories_last, goal_locations, goal_types, targets):\n",
    "        list_values = [states, utterances, memories_com, memories_last, goal_types, goal_locations, targets]\n",
    "        list_placeholders = [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, \n",
    "                             self.goal_locations, self.name_targets]\n",
    "        feed_dict = {a:b for a,b in zip(list_placeholders, list_values)}\n",
    "        return feed_dict\n",
    "    \n",
    "    def train(self, sess):\n",
    "        self.train_writer = tf.summary.FileWriter('Summary', sess.graph)\n",
    "        print(\"Initializing variables\")\n",
    "        sess.run(self.init)\n",
    "        sess.graph.finalize()\n",
    "        print(\"Start training\")\n",
    "        start = datetime.now()\n",
    "        self.arrays_history = [0, 0, 0, 0, 0]\n",
    "        self.full_g = []\n",
    "        states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = self.env.random_generation()\n",
    "        for i in range(FLAGS.max_steps):\n",
    "            #states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = self.env.random_generation()\n",
    "            generation_time = datetime.now() - start\n",
    "            feed_dict = self.create_feed_dict(states, utterances, memories_com, memories_last, goal_locations, goal_types, targets)\n",
    "            if i % FLAGS.tensorboard_freq == 0:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, t, reward, phys_reward, voc_reward, summary, grads = sess.run(self.output_to_run + [self.merged] + [self.clipped_gradients], feed_dict)\n",
    "                self.train_writer.add_summary(summary, i)\n",
    "            else:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, t, reward, phys_reward, voc_reward, grads = sess.run(self.output_to_run + [self.clipped_gradients], feed_dict)\n",
    "            \n",
    "            \n",
    "            vrs = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "            self.vars_history.append(vrs)\n",
    "            self.reward_history.append(reward)\n",
    "            self.voc_reward_history.append(voc_reward)\n",
    "            #self.full_g.append(self.arrays_history[-1])\n",
    "            self.arrays_history = [array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs]\n",
    "            self.grads_history.append(grads)\n",
    "            with open('env_history.pkl', 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([states, utterances, memories_com, memories_last, goal_locations, goal_types, targets])\n",
    "                \n",
    "            with open(\"arrays_history.pkl\", 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([array_states, array_utterances, array_mem_com, array_mem_last, array_outputs])\n",
    "                \n",
    "            if i % FLAGS.print_frequency == 0:\n",
    "                print(\"\\n\")\n",
    "                print(\"iteration \" + str(i))\n",
    "                print(\"physical reward: \" + str(phys_reward))\n",
    "                print(\"vocabulary reward: \" + str(voc_reward))\n",
    "                print(\"total reward: \" + str(reward))\n",
    "                final_states = array_states[-1, :, :, :]\n",
    "                print_stats_agent(final_states, goal_locations, goal_types, targets)\n",
    "    \n",
    "                print(\"computing time\")\n",
    "                print(datetime.now() - start)\n",
    "                print(\"generation time\")\n",
    "                print(generation_time)\n",
    "                print(\"memory usage\")\n",
    "                memory()\n",
    "\n",
    "                start = datetime.now()\n",
    "                \n",
    "            self.mean_act_count.append(print_stat_vocabulary(array_utterances[1:, :, :,:], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_0:0-grad is illegal; using phys_variable/weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_1:0-grad is illegal; using phys_variable/weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_2:0-grad is illegal; using phys_variable/weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_0:0-grad is illegal; using phys_variable/bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_1:0-grad is illegal; using phys_variable/bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_2:0-grad is illegal; using phys_variable/bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_memory_read_weight:0-grad is illegal; using com_memory_read_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_0:0-grad is illegal; using com_variable/com_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_1:0-grad is illegal; using com_variable/com_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_2:0-grad is illegal; using com_variable/com_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_0:0-grad is illegal; using com_variable/com_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_1:0-grad is illegal; using com_variable/com_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_2:0-grad is illegal; using com_variable/com_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_com:0-grad is illegal; using weight_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_com:0-grad is illegal; using bias_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name reading_last_mem_weight:0-grad is illegal; using reading_last_mem_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_0:0-grad is illegal; using last_variable/last_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_1:0-grad is illegal; using last_variable/last_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_2:0-grad is illegal; using last_variable/last_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_0:0-grad is illegal; using last_variable/last_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_1:0-grad is illegal; using last_variable/last_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_2:0-grad is illegal; using last_variable/last_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_last:0-grad is illegal; using weight_mem_last_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_last:0-grad is illegal; using bias_mem_last_0-grad instead.\n",
      "Initializing variables\n",
      "Start training\n",
      "\n",
      "\n",
      "iteration 0\n",
      "physical reward: -4951.7515\n",
      "vocabulary reward: -29544.965\n",
      "total reward: -34496.715\n",
      "--- Agent 0\n",
      "------ Mean distance 10.001773239125917\n",
      "------ Median distance 9.760902420836974\n",
      "------ Third quartile 12.87426420128614\n",
      "------ Ninetieth percentile 16.135446199596604\n",
      "------ max distance 19.74379446520395\n",
      "------ argmax distance 69\n",
      "--- Agent 1\n",
      "------ Mean distance 10.912166192964472\n",
      "------ Median distance 10.416109862839086\n",
      "------ Third quartile 13.975754193940467\n",
      "------ Ninetieth percentile 17.95492133789969\n",
      "------ max distance 24.040214832502222\n",
      "------ argmax distance 73\n",
      "computing time\n",
      "0:00:01.627910\n",
      "generation time\n",
      "0:00:00.008421\n",
      "memory usage\n",
      "memory use: 0.799163818359375\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 19.75\n",
      "---- Median number of word activated: 20.0\n",
      "---- Total number of word activated: 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-06409e79a080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-8973ff2998e0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays_history.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_utterances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_com\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_frequency\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp = Experiment()\n",
    "sess = tf.Session()\n",
    "exp.train(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iteration 46000\n",
    "-253.03172\n",
    "--- Agent 0\n",
    "------ Mean distance 0.3349107071033829\n",
    "------ Median distance 0.29547300157924467\n",
    "------ Third quartile 0.4377302665174422\n",
    "------ Ninetieth percentile 0.638775063507328\n",
    "------ max distance 0.8557159604403306\n",
    "------ argmax distance 39\n",
    "--- Agent 1\n",
    "------ Mean distance 0.3412405142027863\n",
    "------ Median distance 0.31892391108436546\n",
    "------ Third quartile 0.45355292453441526\n",
    "------ Ninetieth percentile 0.6242127385438654\n",
    "------ max distance 0.9072062760757306\n",
    "------ argmax distance 16\n",
    "computing time\n",
    "0:11:42.544759\n",
    "generation time\n",
    "0:11:41.076586\n",
    "memory usage\n",
    "memory use: 0.8258514404296875\n",
    "-- Stats word count:\n",
    "---- Mean number of word activated: 19.28\n",
    "---- Median number of word activated: 19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"env_history.pkl\", \"rb\") as openfile:\n",
    "    states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = cPickle.load(openfile)\n",
    "\n",
    "    \n",
    "array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs = exp.arrays_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats_agent(array_states[-1, :, :, :], goal_locations, goal_types, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_types[:, :, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dist_to_goal = compute_goal_dist(python_shuffle(array_states[-1, :, :, :],targets),  goal_locations, goal_types)\n",
    "#dist_to_goal = compute_goal_dist(python_shuffle(array_states[-1, :, :, :],targets),  v, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  9, 10, 13, 14, 19, 20, 23, 25, 26, 27, 37, 39, 40, 42, 44, 58,\n",
       "        64, 66, 68, 69, 70, 71, 75, 79, 80, 85, 86, 90, 97]),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move = dist_to_goal[:, goal_types[0, 0, :] == 1]\n",
    "gaze = dist_to_goal[:, goal_types[0, 1, :] == 1]\n",
    "nothing = dist_to_goal[:, goal_types[0, 2, :] == 1]\n",
    "\n",
    "no_shuffle = dist_to_goal[:, targets[0, 0, :] == 0]\n",
    "shuffle = dist_to_goal[:, targets[1, 0, :] == 0]\n",
    "\n",
    "same_loc = dist_to_goal[:, (goal_locations[0, :, :] == goal_locations[1, :, :])[0, :]]\n",
    "diff_loc = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :]]\n",
    "\n",
    "diff_n_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]\n",
    "diff_not_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 1)]\n",
    "rest = dist_to_goal[:, ~(goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- rest:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- diff and shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- diff and not shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "print(\"- rest:\")\n",
    "print(\"---- median:\" + str(np.median(rest)))\n",
    "print(\"---- mean:\" + str(np.mean(rest)))\n",
    "print(\"---- max:\" + str(np.max(rest)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(rest, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(rest, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_n_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_n_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_n_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_n_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_n_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and not shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_not_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_not_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_not_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_not_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_not_shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- no_shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "print(\"- no_shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(no_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(no_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(no_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(no_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(no_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(shuffle)))\n",
    "print(\"---- max:\" + str(np.max(shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- move:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- gaze:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "print(\"- move:\")\n",
    "print(\"---- median:\" + str(np.median(move)))\n",
    "print(\"---- mean:\" + str(np.mean(move)))\n",
    "print(\"---- max:\" + str(np.max(move)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(move, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(move, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- gaze:\")\n",
    "print(\"---- median:\" + str(np.median(gaze)))\n",
    "print(\"---- mean:\" + str(np.mean(gaze)))\n",
    "print(\"---- max:\" + str(np.max(gaze)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(gaze, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(gaze, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- same loc:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- diff loc:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "print(\"- same loc:\")\n",
    "print(\"---- median:\" + str(np.median(same_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(same_loc)))\n",
    "print(\"---- max:\" + str(np.max(same_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(same_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(same_loc, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff loc:\")\n",
    "print(\"---- median:\" + str(np.median(diff_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_loc)))\n",
    "print(\"---- max:\" + str(np.max(diff_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_loc, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances[10, 0, :, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6617510755146957"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(dist_to_goal, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-480-e58bbd5f5f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][-1, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-481-c5b16d5090f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][0, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:,:, 87].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0][:, 0, 0:2, 82].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_stats_agent() missing 1 required positional argument: 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-6df541d46d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: print_stats_agent() missing 1 required positional argument: 'targets'"
     ]
    }
   ],
   "source": [
    "print_stats_agent(array_states[0][-1, :, :, :], goal_locations, goal_types)\n",
    "print_stats_agent(array_states[0][0, :, :, :], goal_locations, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array_states = array_states\n",
    "save_goal_locations = goal_locations\n",
    "save_v = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2834616 , 2.40743668])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6210312,  1.9584472],\n",
       "       [-5.182998 ,  2.837392 ]], dtype=float32)"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[-1, 0:2, 0:2, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  [[1]\n",
      " [0]]\n",
      "first [0. 0. 1.]\n",
      "second [0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCMz/A9QGT7xqzXMgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa904024128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: [1.01029085 1.03542092]\n",
      "second: [-2.13919796 -0.23145501]\n",
      "[[-3.54529727 -3.25900611]\n",
      " [-3.54529727 -3.25900611]]\n"
     ]
    }
   ],
   "source": [
    "nb = 9\n",
    "print(\"target \", targets[:, :, nb])\n",
    "print(\"first\", goal_types[0, :, nb])\n",
    "print(\"second\", goal_types[1, :, nb])\n",
    "plot_trajectory(array_states[:, 0,0:2,nb], goal_locations[1, :, nb], v[0, :, nb])\n",
    "print(\"first:\", goal_locations[0, :, nb])\n",
    "print(\"second:\", goal_locations[1, :, nb])\n",
    "print(v[:, :, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4, 24, 35, 36, 37, 39, 52, 57, 60, 83, 87, 90]),)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_types[0, 0, :] == 1) & (goal_types[1, 0, :] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 11, 14, 15, 20, 22, 26, 41, 43, 48, 64, 76, 80, 81, 84]),)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_types[0, 1, :] == 1) & (goal_types[1, 1, :] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = np.mean(goal_locations, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.tile(vv, (2, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bd9cbd390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.reward_history[:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.voc_reward_history[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-36759.89,\n",
       " -35472.78,\n",
       " -35246.125,\n",
       " -34447.223,\n",
       " -34233.406,\n",
       " -33149.5,\n",
       " -32961.883,\n",
       " -32837.62,\n",
       " -31997.611,\n",
       " -32390.621,\n",
       " -32259.693,\n",
       " -32621.5,\n",
       " -32446.652,\n",
       " -32306.844,\n",
       " -32415.9,\n",
       " -31741.262,\n",
       " -31984.79,\n",
       " -32168.473,\n",
       " -31939.707,\n",
       " -31691.338,\n",
       " -31686.127,\n",
       " -31661.066,\n",
       " -31706.723,\n",
       " -31352.3,\n",
       " -31732.865,\n",
       " -31725.918,\n",
       " -31311.006,\n",
       " -31186.959,\n",
       " -31498.795,\n",
       " -31141.416,\n",
       " -31096.9,\n",
       " -31194.25,\n",
       " -31093.254,\n",
       " -30759.34,\n",
       " -31020.504,\n",
       " -31054.305,\n",
       " -30397.27,\n",
       " -30621.646,\n",
       " -30178.924,\n",
       " -30253.168,\n",
       " -30005.627,\n",
       " -29694.396,\n",
       " -30027.549,\n",
       " -29104.74,\n",
       " -28759.693,\n",
       " -28408.965,\n",
       " -28398.738,\n",
       " -27510.744,\n",
       " -27107.95,\n",
       " -27050.146,\n",
       " -26399.521,\n",
       " -26260.756,\n",
       " -25143.348,\n",
       " -24329.432,\n",
       " -23683.238,\n",
       " -22643.582,\n",
       " -22147.232,\n",
       " -20406.537,\n",
       " -19691.584,\n",
       " -18909.598,\n",
       " -16927.646,\n",
       " -15821.308,\n",
       " -14982.525,\n",
       " -13118.685,\n",
       " -11497.555,\n",
       " -10265.631,\n",
       " -9443.973,\n",
       " -8269.414,\n",
       " -6984.357,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.reward_history[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dirichlet_log_lik_end(utterances_array):\n",
    "    #Note: we don't take minus the log-likelihood as we minimize minus the entire reward then !\n",
    "    tr = tf.argmax(utterances_array, axis = 2)\n",
    "    oh = tf.one_hot(tr, depth = FLAGS.vocabulary_size)\n",
    "    idx = tf.where(tf.equal(oh, 1))\n",
    "    new_utt = tf.transpose(utterances_array, [0, 1, 3, 2])\n",
    "    f = tf.gather_nd(new_utt, idx)\n",
    "    return f, idx, oh, new_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utt = tf.Variable(array_utterances[1:, :, :, :])\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    f, idx, oh, new_utt  = sess.run(dirichlet_log_lik_end(utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_utt[9, 1, 30, :] == array_utterances[10, 1, :, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances[1, 0, :, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8858.54"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.log(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances, axis = 2)[:, 0, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances, axis = 2)[:, 1, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5, 9, 100)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances[:, 0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.75,\n",
       " 19.68,\n",
       " 19.56,\n",
       " 19.66,\n",
       " 19.61,\n",
       " 19.4,\n",
       " 18.57,\n",
       " 17.65,\n",
       " 16.24,\n",
       " 13.66,\n",
       " 10.81,\n",
       " 8.2,\n",
       " 5.51,\n",
       " 3.41,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.mean_act_count[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 2, 20, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.argmax(array_utterances, axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.90214473, -0.02492837,  0.69262636, ...,  0.4822033 ,\n",
       "           0.93664926, -0.24296154],\n",
       "         [ 0.26845947,  0.7734412 ,  0.6918961 , ...,  0.798208  ,\n",
       "           0.7729982 ,  0.8183322 ],\n",
       "         [-0.25064966,  0.37380728,  0.756564  , ...,  0.8543203 ,\n",
       "           0.5675483 ,  0.9773596 ],\n",
       "         ...,\n",
       "         [ 0.19253038,  0.7801578 ,  0.3621901 , ...,  0.35031897,\n",
       "           0.83836186,  0.6319285 ],\n",
       "         [ 0.75467247,  0.86591345,  0.89849025, ...,  0.2595272 ,\n",
       "           0.45782265,  0.9442035 ],\n",
       "         [ 0.01018355, -0.28797892, -0.2541917 , ...,  0.15848953,\n",
       "           0.89569706,  0.5923873 ]],\n",
       "\n",
       "        [[ 0.17563468,  0.3883824 ,  0.61347055, ...,  0.3454827 ,\n",
       "           0.16330086, -0.07875846],\n",
       "         [ 0.9388037 ,  0.6552747 ,  0.59610367, ...,  0.86643285,\n",
       "           0.87721705,  0.28660408],\n",
       "         [-0.37511113,  0.6489185 , -0.19758937, ...,  0.25974217,\n",
       "           0.91853833,  0.41591322],\n",
       "         ...,\n",
       "         [ 0.915713  ,  0.8787165 ,  0.54584265, ...,  0.97189194,\n",
       "          -0.07849099,  0.3095042 ],\n",
       "         [ 0.4063569 ,  0.88899314,  0.9121799 , ...,  0.8777404 ,\n",
       "           0.72314304,  0.01354957],\n",
       "         [ 0.23285595,  0.03655528, -0.26537046, ..., -0.42120293,\n",
       "          -0.5419183 , -0.37164995]]],\n",
       "\n",
       "\n",
       "       [[[ 0.13926964,  0.1515674 ,  0.5833411 , ...,  0.8999164 ,\n",
       "           0.8356941 ,  0.14795819],\n",
       "         [ 0.4036145 ,  0.79291034,  0.69933885, ...,  0.94505185,\n",
       "           0.8762697 ,  0.38245282],\n",
       "         [-0.28580558,  0.94104844,  0.930815  , ...,  0.9546243 ,\n",
       "           0.97634226,  0.9868043 ],\n",
       "         ...,\n",
       "         [ 0.97358555,  0.9185597 ,  0.6195109 , ...,  0.94613194,\n",
       "           0.75795   ,  0.99518436],\n",
       "         [ 0.8944818 ,  0.84308624, -0.20034835, ...,  0.77897835,\n",
       "           0.90716493,  0.5867821 ],\n",
       "         [-0.36268175, -0.3365601 , -0.3394461 , ...,  0.8210714 ,\n",
       "           0.7281853 , -0.19595627]],\n",
       "\n",
       "        [[-0.39546475,  0.70041895,  0.61976516, ...,  0.06729787,\n",
       "           0.34237435, -0.48108616],\n",
       "         [ 0.76529604,  0.8310208 ,  0.9255794 , ...,  0.8745167 ,\n",
       "           0.8483038 ,  0.5404159 ],\n",
       "         [ 0.3099303 ,  0.71397114,  0.7208984 , ...,  0.9319201 ,\n",
       "           0.9636534 ,  0.7404093 ],\n",
       "         ...,\n",
       "         [ 0.9612122 ,  0.88110185,  0.9934584 , ...,  0.9428064 ,\n",
       "           0.78280306,  0.9875364 ],\n",
       "         [ 0.7360873 ,  0.98501843,  0.42803198, ...,  0.84735715,\n",
       "           0.55609965,  0.266956  ],\n",
       "         [ 0.7600033 , -0.6487167 , -0.18465558, ..., -0.5402506 ,\n",
       "           0.04486344, -0.8545941 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.6280733 ,  0.6149653 ,  0.7179694 , ..., -0.59900796,\n",
       "           0.83783615,  0.6251023 ],\n",
       "         [ 0.9964942 ,  0.88150656,  0.9820913 , ...,  0.7221304 ,\n",
       "           0.985947  ,  0.96121776],\n",
       "         [ 0.84066576,  0.7065505 ,  0.9994694 , ...,  0.8356804 ,\n",
       "           0.9913429 ,  0.99780715],\n",
       "         ...,\n",
       "         [ 0.82152504,  0.9190174 ,  0.9936897 , ...,  0.95134455,\n",
       "           0.68597025,  0.9662606 ],\n",
       "         [ 0.5142717 ,  0.59894115,  0.8453604 , ...,  0.96751577,\n",
       "           0.8593849 ,  0.21739334],\n",
       "         [-0.66114724, -0.2968915 ,  0.46794763, ...,  0.93223536,\n",
       "           0.5384058 ,  0.9831667 ]],\n",
       "\n",
       "        [[ 0.9222068 ,  0.91822   ,  0.79456437, ..., -0.74446726,\n",
       "          -0.04493701,  0.9691149 ],\n",
       "         [ 0.9330666 ,  0.9784325 ,  0.7968762 , ...,  0.83610713,\n",
       "           0.9732633 ,  0.8874775 ],\n",
       "         [ 0.9799954 ,  0.90658563,  0.7998481 , ...,  0.9609186 ,\n",
       "           0.99032974,  0.97862875],\n",
       "         ...,\n",
       "         [ 0.90654135,  0.893563  ,  0.80557126, ...,  0.9882027 ,\n",
       "           0.94275063,  0.9872748 ],\n",
       "         [-0.28119144,  0.9518721 ,  0.9317404 , ...,  0.9652607 ,\n",
       "           0.9583771 ,  0.7307962 ],\n",
       "         [-0.403055  , -0.05881811, -0.8388951 , ...,  0.3606935 ,\n",
       "          -0.5635445 ,  0.12182814]]],\n",
       "\n",
       "\n",
       "       [[[ 0.75150096,  0.9531103 ,  0.79301244, ..., -0.78053385,\n",
       "           0.9309232 ,  0.7844168 ],\n",
       "         [ 0.9478786 ,  0.9919871 ,  0.9905338 , ...,  0.9672046 ,\n",
       "           0.97748435,  0.9672617 ],\n",
       "         [ 0.8409407 ,  0.99818164,  0.99209946, ...,  0.9894264 ,\n",
       "           0.98171556,  0.96229357],\n",
       "         ...,\n",
       "         [ 0.9414475 ,  0.98475957,  0.9572442 , ...,  0.8400691 ,\n",
       "           0.2722478 ,  0.7880898 ],\n",
       "         [ 0.9920731 ,  0.79188466,  0.573068  , ...,  0.994672  ,\n",
       "           0.75693506,  0.7225848 ],\n",
       "         [-0.03888461, -0.8612571 , -0.86190784, ...,  0.84628433,\n",
       "          -0.3455402 , -0.8553337 ]],\n",
       "\n",
       "        [[ 0.7897272 ,  0.9635388 ,  0.907636  , ..., -0.0437943 ,\n",
       "           0.5815003 ,  0.8840401 ],\n",
       "         [ 0.9578519 ,  0.8553281 ,  0.9112984 , ...,  0.79970753,\n",
       "           0.99171853,  0.97623616],\n",
       "         [ 0.9707401 ,  0.9839101 ,  0.9391105 , ...,  0.93463176,\n",
       "           0.9936004 ,  0.9933166 ],\n",
       "         ...,\n",
       "         [ 0.74065506,  0.9853123 ,  0.76303345, ...,  0.8516506 ,\n",
       "           0.9645116 ,  0.9014583 ],\n",
       "         [-0.59762144,  0.9807273 ,  0.44680935, ...,  0.9860817 ,\n",
       "           0.4324025 ,  0.51276386],\n",
       "         [-0.625304  , -0.299842  , -0.9354894 , ..., -0.26195994,\n",
       "          -0.5931479 ,  0.50695443]]],\n",
       "\n",
       "\n",
       "       [[[ 0.9470147 ,  0.92538035,  0.9390261 , ..., -0.21659102,\n",
       "           0.72185194,  0.58635736],\n",
       "         [ 0.92699796,  0.9805852 ,  0.990956  , ...,  0.91624296,\n",
       "           0.5676905 ,  0.8369119 ],\n",
       "         [ 0.9491387 ,  0.861452  ,  0.99619424, ...,  0.85538065,\n",
       "           0.97585005,  0.96567625],\n",
       "         ...,\n",
       "         [ 0.9753018 ,  0.92005664,  0.9047772 , ...,  0.85887855,\n",
       "           0.6660135 ,  0.9441075 ],\n",
       "         [ 0.9026806 ,  0.9099809 ,  0.98032814, ...,  0.97272974,\n",
       "           0.9644606 ,  0.79485416],\n",
       "         [-0.6543789 ,  0.62809813, -0.8417858 , ...,  0.6769973 ,\n",
       "          -0.81458795, -0.6593337 ]],\n",
       "\n",
       "        [[ 0.734053  ,  0.9266132 ,  0.933535  , ...,  0.69917023,\n",
       "           0.7155208 ,  0.55064833],\n",
       "         [ 0.9874307 ,  0.9873579 ,  0.98150253, ...,  0.9369473 ,\n",
       "           0.9675833 ,  0.99680346],\n",
       "         [ 0.94477093,  0.8890884 ,  0.9283231 , ...,  0.9418098 ,\n",
       "           0.99783576,  0.98842394],\n",
       "         ...,\n",
       "         [ 0.9644622 ,  0.9842916 ,  0.9984343 , ...,  0.9876371 ,\n",
       "           0.94618964,  0.98888326],\n",
       "         [ 0.29029807,  0.9348022 ,  0.9657703 , ...,  0.6920501 ,\n",
       "           0.9672351 ,  0.9603885 ],\n",
       "         [-0.8580839 , -0.87163687, -0.96947986, ..., -0.12436386,\n",
       "          -0.14357434,  0.62786126]]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_mem_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_stat_vocabulary(array_utterances[1:, :, :,:], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances[1:, :, :,:], axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32),\n",
       "  array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          ...,\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan],\n",
       "          [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32)),\n",
       " (array([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
       "        dtype=float32),\n",
       "  array([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
       "        dtype=float32)),\n",
       " (array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32), array([[[nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan],\n",
       "          [nan]]], dtype=float32))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.grads_history[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9983.063"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.reward_history[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6170.1216"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.voc_reward_history[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.61715e-05\n",
      "0.22163895\n",
      "\n",
      "\n",
      "2.9666974e-06\n",
      "0.24555673\n",
      "\n",
      "\n",
      "2.2269928e-06\n",
      "0.28883353\n",
      "\n",
      "\n",
      "1.682774e-05\n",
      "0.15423635\n",
      "\n",
      "\n",
      "1.5685111e-05\n",
      "0.19052815\n",
      "\n",
      "\n",
      "1.1652887e-05\n",
      "0.1605566\n",
      "\n",
      "\n",
      "4.712848e-06\n",
      "0.24773143\n",
      "\n",
      "\n",
      "1.6925656e-05\n",
      "0.22685881\n",
      "\n",
      "\n",
      "3.3652843e-06\n",
      "0.28806388\n",
      "\n",
      "\n",
      "2.7090211e-06\n",
      "0.25765133\n",
      "\n",
      "\n",
      "1.8683391e-05\n",
      "0.17334466\n",
      "\n",
      "\n",
      "1.4814767e-05\n",
      "0.20281266\n",
      "\n",
      "\n",
      "1.3037498e-05\n",
      "0.14888006\n",
      "\n",
      "\n",
      "5.7179786e-06\n",
      "0.21408801\n",
      "\n",
      "\n",
      "2.8353546e-05\n",
      "0.3178793\n",
      "\n",
      "\n",
      "1.4615507e-05\n",
      "0.476041\n",
      "\n",
      "\n",
      "3.9012343e-06\n",
      "0.1805435\n",
      "\n",
      "\n",
      "2.349448e-06\n",
      "0.2804724\n",
      "\n",
      "\n",
      "6.505205e-06\n",
      "0.25090548\n",
      "\n",
      "\n",
      "1.2403094e-05\n",
      "0.18160903\n",
      "\n",
      "\n",
      "1.1517024e-05\n",
      "0.20956805\n",
      "\n",
      "\n",
      "1.9989799e-05\n",
      "0.26430783\n",
      "\n",
      "\n",
      "2.5663461e-05\n",
      "0.5400905\n",
      "\n",
      "\n",
      "4.018739e-05\n",
      "0.27789274\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, j in exp.grads_history[-5]:\n",
    "    print(np.max(i))\n",
    "    print(np.max(j))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
