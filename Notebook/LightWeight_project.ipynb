{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from datetime import datetime \n",
    "%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float('learning_rate', 0.0001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('max_steps', 50000, 'Number of iteration to train.')\n",
    "flags.DEFINE_integer('number_layers', 3, 'Number of layers in each network')\n",
    "flags.DEFINE_integer('layer_sizes', 256, 'Number of units in hidden layer.')\n",
    "flags.DEFINE_integer('batch_size', 500, 'Batch size.')\n",
    "flags.DEFINE_integer('dim_env', 2, 'dimension of the environment')\n",
    "flags.DEFINE_integer('number_goal_types', 3, 'number of different goal types')\n",
    "flags.DEFINE_integer('color_size', 3, 'number of components of the color: RGB as usual')\n",
    "flags.DEFINE_integer(\"output_size\", 256, \"number of units in the output layer\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.9, \"Dropouts rate of keeping\")\n",
    "flags.DEFINE_boolean(\"xav_init\", False,\"Distribution of initialization: False for normal, True for uniform\" )\n",
    "flags.DEFINE_integer(\"number_agents\", 1, \"Number of agents in the environment\")\n",
    "flags.DEFINE_integer(\"number_landmarks\", 1, \"Number of landmarks in the environment\")\n",
    "flags.DEFINE_integer(\"vocabulary_size\", 20, \"Size of the vocabulary\")\n",
    "flags.DEFINE_integer(\"mem_size\", 32, \"Size of the communication network's memory\")\n",
    "flags.DEFINE_integer(\"last_mem_size\", 32, \"Size of the last network's memory\")\n",
    "flags.DEFINE_float(\"gumbel_temperature\", 1, \"Temperature use for the gumbel softmax trick\")\n",
    "flags.DEFINE_float(\"sddev_phys_sampling\", 0.0001, \"Standard deviation used to sample the velocity and gaze output\")\n",
    "flags.DEFINE_float(\"delta_t\", 0.1, \"delta of time between timesteps\")\n",
    "flags.DEFINE_float(\"damping_coef\", 0.5, \"damping coefficient for the new velocity computation\")\n",
    "flags.DEFINE_float(\"stddev_memory\", 0.0001, \"standard deviation of the gaussian used to update memories\")\n",
    "flags.DEFINE_integer(\"bound\", 5, \"Bounds of generation of initial positions, centered in 0.\")\n",
    "flags.DEFINE_integer(\"time_horizon\", 50, \"Number of timestep before the end of the experiment.\")\n",
    "flags.DEFINE_integer(\"print_frequency\", 500, \"Frequency at which we print the reward, in number of steps.\")\n",
    "flags.DEFINE_boolean(\"learning_rate_decay\", True, \"Wether to use a piecewise learning rate decay or no decay at all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire:\n",
    "\n",
    "- Checker que le softmax pooling est correct\n",
    "\n",
    "- Checker que le gumbel trick est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le sampling physique est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le calcul du nouvel état est correct, notamment sur les débuts et longueur de slicing et concaténation\n",
    "\n",
    "- Ajouter le calcul des forces dans le calcul du nouvel état\n",
    "\n",
    "- Vérifier que le shuffling est correct\n",
    "\n",
    "- Vérifier que le calcul du reward est correct\n",
    "\n",
    "- Vérifier que la backprop considère bien les variables broadcastées comme les mêmes.\n",
    "\n",
    "- Vérifier que le tenseur states est bien dans cet ordre sur le second axe: position, velocité, gaze, couleurs\n",
    "\n",
    "- RELIER LES LANDMARKS AUX POSITIONS DES GOALS, SINON CA N A PAS DE SENS !!!\n",
    "\n",
    "- Checker que les goals types sont bien distribués: une unique coordonnée doit être 1, les autres 0, et ce pour chaque agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 306 ms\n"
     ]
    }
   ],
   "source": [
    "# Param: x, stacking of the output of fully connected physical network for each agent. Shape = (256, batch_size, nb_agents)\n",
    "# return: pooling of input features.\n",
    "def softmax_pooling(x):\n",
    "    # pooling function. Softmax pooling is a compromise between max pooling and average pooling\n",
    "    coefs = tf.nn.softmax(x, dim = 0)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = 0)\n",
    "    return softmax_pool\n",
    "\n",
    "\n",
    "def activation_function(x):\n",
    "    return tf.nn.elu(x)\n",
    "\n",
    "\n",
    "def gumbel_max_trick(x):\n",
    "    # Application of gumbel-softmax trick\n",
    "    # Input: output of the last network \n",
    "    u = -tf.log(-tf.log(tf.random_uniform(shape = [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size],\n",
    "                                          dtype=tf.float32)))\n",
    "    utterance_output = tf.slice(x, [0, 2*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "    gumbel = tf.exp((utterance_output + u)/FLAGS.gumbel_temperature)\n",
    "    denoms = tf.reshape(tf.reduce_sum(gumbel, axis = 1), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    utterance = gumbel/denoms\n",
    "    return utterance \n",
    "\n",
    "\n",
    "def sample_phys(x):\n",
    "    #Input output of the last network.\n",
    "    #Output: sampled values for new velocity and gaze\n",
    "    u = tf.random_normal(shape = [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size],dtype=tf.float32,\n",
    "                         stddev = FLAGS.sddev_phys_sampling)\n",
    "    o = tf.add(tf.slice(x, [0, 0, 0], [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size]), u)\n",
    "    sample_move = tf.slice(o, [0, 0, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    sample_gaze  = tf.slice(o, [0, FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    return sample_move, sample_gaze\n",
    "\n",
    "\n",
    "def compute_new_states(old_states, new_velocities, new_gazes, new_utterances):\n",
    "    #Computes the new states according to the equations of the papers.\n",
    "    # Input: the old states of shape [number agents + nb_landmarks, 3*env dim + color size, batch size] because color is in state\n",
    "    # and of shape [number_agents, 2*env_dim, batch size]\n",
    "    # Adding the outputs of landmark, which are all zeros.\n",
    "    new_velocities = tf.concat([new_velocities, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "                                           axis = 0)\n",
    "    new_gazes = tf.concat([new_gazes, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "                                           axis = 0)\n",
    "    \n",
    "    old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_pos = tf.slice(old_states, [0, 0, 0], \n",
    "                       [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity\n",
    "    \n",
    "    new_velocity = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    \n",
    "    colors = tf.slice(old_states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                            FLAGS.color_size, FLAGS.batch_size])\n",
    "    new_states = tf.concat([new_pos, new_velocity, new_gazes, colors], axis = 1)\n",
    "\n",
    "    return new_states, new_pos\n",
    "\n",
    "\n",
    "\n",
    "def compute_new_memories(old_mem_com, old_mem_last, delta_mem_com, delta_mem_last):\n",
    "    new_memory_com = tf.tanh(old_mem_com + delta_mem_com + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory))\n",
    "    new_memory_last = tf.tanh(old_mem_last + delta_mem_last + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory))\n",
    "    \n",
    "    return new_memory_com,new_memory_last\n",
    "\n",
    "\n",
    "\n",
    "def shuffle(x, name_targets, colors = False):\n",
    "    slices_second_dim = []\n",
    "    ones = tf.ones([FLAGS.number_agents, 1, FLAGS.batch_size], tf.int32)\n",
    "    batch_num = tf.tile(tf.reshape(tf.range(0, FLAGS.batch_size, dtype = tf.int32), [1, 1, FLAGS.batch_size]), [FLAGS.number_agents,\n",
    "                                                                                                               1, 1])\n",
    "    if not colors:\n",
    "        for i in range(FLAGS.dim_env):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "    else:\n",
    "        for i in range(FLAGS.color_size):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "            \n",
    "    gathering_tensor = tf.transpose(tf.concat(slices_second_dim, axis = 1), perm = [0, 1, 3, 2])\n",
    "    shuffled_x = tf.gather_nd(x, gathering_tensor)\n",
    "    \n",
    "    return shuffled_x\n",
    "    \n",
    "    \n",
    "def compute_reward(positions, gazes, outputs, utterances, name_targets, goals_loc, goals_types):\n",
    "    shuffled_positions = shuffle(positions, name_targets)\n",
    "    shuffled_gazes = shuffle(gazes, name_targets)\n",
    "    \n",
    "    pos_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_positions - goals_loc)), axis = 1), [FLAGS.number_agents, 1, \n",
    "                                                                                                     FLAGS.batch_size])\n",
    "    gaze_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_gazes - goals_loc)), axis = 1), [FLAGS.number_agents, 1,\n",
    "                                                                                                     FLAGS.batch_size])\n",
    "    zeros = tf.zeros([FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    x = tf.concat([pos_distances, gaze_distances, zeros], axis = 1)\n",
    "    dists_goal = -tf.reduce_sum(tf.multiply(x, goals_types), axis = 1)\n",
    "    \n",
    "    utterances_term = -tf.reduce_sum(tf.square(utterances), axis = 1)\n",
    "    output_term = -tf.reduce_sum(tf.square(outputs), axis = 1)\n",
    "    \n",
    "    reward_by_batch = tf.reshape(tf.reduce_sum(dists_goal + utterances_term + 0.1 * output_term, axis = 0), [FLAGS.batch_size, 1])\n",
    "\n",
    "    return reward_by_batch\n",
    "\n",
    "\n",
    "\n",
    "def compute_goal_dist(states, goal_location, goal_type):\n",
    "    dist_positions = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 0:2, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    dist_gazes = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 4:6, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    \n",
    "    v = np.concatenate([dist_positions, dist_gazes, np.zeros((FLAGS.number_agents, 1, FLAGS.batch_size))], axis = 1)\n",
    "    goal_distances = np.sum(np.multiply(v, goal_type), axis = 1)\n",
    "    \n",
    "    return goal_distances\n",
    "\n",
    "\n",
    "def print_stats_agent(states, goal_location, goal_type):\n",
    "    #Only considering non \"do nothing goals\"\n",
    "    goal_distances = compute_goal_dist(states, goal_location, goal_type)\n",
    "    \n",
    "    for i in range(FLAGS.number_agents):\n",
    "        distances_agents = goal_distances[i, :]\n",
    "        goal_wo_zeros = distances_agents[distances_agents != 0]\n",
    "        mean = np.mean(goal_wo_zeros)\n",
    "        median = np.median(goal_wo_zeros)\n",
    "        third_quart = np.percentile(goal_wo_zeros, 75)\n",
    "        nine_pct = np.percentile(goal_wo_zeros, 90)\n",
    "        max_dist = np.max(goal_wo_zeros)\n",
    "        print(\"--- Agent \" + str(i))\n",
    "        print(\"------ Mean distance \" + str(mean))\n",
    "        print(\"------ Median distance \" + str(median))\n",
    "        print(\"------ Third quartile \" + str(third_quart))\n",
    "        print(\"------ Ninetieth percentile \" + str(nine_pct))\n",
    "        print(\"------ max distance \" + str(max_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the physical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 287 ms\n"
     ]
    }
   ],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 3*FLAGS.dim_env + FLAGS.color_size\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, number of inputs]\n",
    "        #This shape enables us to handle all the agents/landmarks states at once, instead of dealing with list of agents' states\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)), \n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.layer_sizes, 1],\n",
    "                                            initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.output_size, 1],\n",
    "                                            initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): \n",
    "        # Compute a forward pass through the network\n",
    "        # Input: a tensor of shape [number of agents, size of input, batch _size]\n",
    "        # Output: a tensor of shape [number of agents, output_size, batch_size]\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "                else:\n",
    "                    x = activation_function(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the communication network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "class CommunicationNet: \n",
    "    \n",
    "    def __init__(self):    \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"com_memory_read_weight\", shape = [1, FLAGS.output_size, FLAGS.mem_size],\n",
    "                                               initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, vocabulary size]\n",
    "        #This shape enables us to handle all the agents utterances at once, instead of dealing with list of agents' states        \n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.vocabulary_size],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)), \n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                   initializer = tf.contrib.layers.xavier_initializer(FLAGS.xav_init)), \n",
    "                                    [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.output_size, 1], \n",
    "                                   initializer = tf.contrib.layers.xavier_initializer(FLAGS.xav_init)), \n",
    "                                    [FLAGS.number_agents, 1, 1])  \n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        # Initialization of the weights and biases writing in the memory.\n",
    "        # Their shape are of the form [number of agents, memory_size, output size] and [number of agents, output size, 1]\n",
    "        # So that we can handle the memories of all agents at onces instead of dealing with list of memories.\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_com\" , shape=[1, FLAGS.mem_size,FLAGS.output_size],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)), \n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_com\", shape = [1, FLAGS.mem_size, 1],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = tf.add(tf.matmul(self.W_mem, x),self.b_mem)\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 95.1 ms\n"
     ]
    }
   ],
   "source": [
    "class LastNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 2*FLAGS.output_size + FLAGS.color_size + FLAGS.number_goal_types + FLAGS.dim_env\n",
    "        self.output_size = 2*FLAGS.dim_env + FLAGS.vocabulary_size\n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"reading_last_mem_weight\", shape = [1, self.output_size, FLAGS.last_mem_size],\n",
    "                                              initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size ],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)), \n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, self.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, self.output_size, 1], \n",
    "                                        initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_last\", shape=[1, FLAGS.last_mem_size ,self.output_size],\n",
    "                                initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                 [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_last\" ,shape = [1, FLAGS.last_mem_size, 1], \n",
    "                                    initializer=tf.contrib.layers.xavier_initializer(FLAGS.xav_init)),\n",
    "                                  [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "               \n",
    "        delta_mem = tf.add(tf.matmul(self.W_mem, x),self.b_mem)\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the policy: putting all the networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 79.1 ms\n"
     ]
    }
   ],
   "source": [
    "class Policy:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.phys_network = PhysicalNet()\n",
    "        self.comm_network = CommunicationNet()\n",
    "        self.last_network = LastNet()\n",
    "        \n",
    "        self.define_placeholders()\n",
    "        self.define_full_goals()\n",
    "        \n",
    "        \n",
    "    def define_placeholders(self):\n",
    "        self.states = tf.placeholder(tf.float32, [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                  3*FLAGS.dim_env + FLAGS.color_size, FLAGS.batch_size])\n",
    "        self.utterances = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "        self.memories_com = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size])\n",
    "        self.memories_last = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size])\n",
    "        self.goal_types = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.number_goal_types, FLAGS.batch_size])\n",
    "        self.goal_locations = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        self.name_targets = tf.placeholder(tf.int32, [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "        #self.colors = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        \n",
    "        \n",
    "    def define_full_goals(self):\n",
    "        colors = tf.slice(self.states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        shuffled_colors = shuffle(colors, self.name_targets, colors = True)\n",
    "        self.full_goals = tf.concat([self.goal_types, self.goal_locations, shuffled_colors], axis = 1)\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.states, self.utterances, self.memories_com, self.memories_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets]\n",
    "        \n",
    "    def forward_pass(self, states, utterances, mem, mem_last, goals_last):\n",
    "        #Step 1: processing observed states and utterances\n",
    "        phys_output = self.phys_network.compute_output(states)\n",
    "        comm_output, delta_mem_com = self.comm_network.compute_output(utterances, mem)\n",
    "        \n",
    "        #Step 2: softmax pooling the results [num_agents, output size, batch_size] --> [1, output size, batch_size]\n",
    "        PhiX = softmax_pooling(phys_output)\n",
    "        PhiC = softmax_pooling(comm_output)\n",
    "        \n",
    "        #Step 3: feeding the last network      \n",
    "        PhiX_last = tf.tile(tf.reshape(PhiX, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        PhiC_last = tf.tile(tf.reshape(PhiC, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        input_last = tf.concat([PhiX_last, goals_last, PhiC_last], axis = 1)\n",
    "        \n",
    "        output_last, delta_mem_last = self.last_network.compute_output(input_last, mem_last)\n",
    "        \n",
    "        velocities_output, gazes_output = sample_phys(output_last)\n",
    "        utterances_output = gumbel_max_trick(output_last)\n",
    "        phys_output = tf.concat([velocities_output, gazes_output], axis = 1)\n",
    "        \n",
    "        return phys_output, velocities_output, gazes_output, utterances_output, delta_mem_com, delta_mem_last\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 84 ms\n"
     ]
    }
   ],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.enc = OneHotEncoder(n_values=FLAGS.number_goal_types, sparse=False)\n",
    "        self.colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)] \n",
    "        self.cols = self.create_colors()\n",
    "    \n",
    "    \n",
    "    def create_colors(self):\n",
    "        cols_agents = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_agents)], axis = 0)\n",
    "        cols_landmarks = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_landmarks)], axis = 0)\n",
    "        \n",
    "        cols = np.concatenate([cols_agents, cols_landmarks], axis = 0)\n",
    "            \n",
    "        return cols\n",
    "            \n",
    "        \n",
    "    def create_consistent_targets(self):\n",
    "        targets_by_exp = [np.random.choice(FLAGS.number_agents, (FLAGS.number_agents, 1), replace = False) for _ in range(FLAGS.batch_size)]\n",
    "        targets_batch = np.stack(targets_by_exp, axis = 2)\n",
    "        return targets_batch\n",
    "        \n",
    "    def random_generation(self):\n",
    "        positions = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        gazes = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        velocities = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        goal_locations = np.random.uniform(-FLAGS.bound, FLAGS.bound, [FLAGS.number_agents, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size])\n",
    "        \n",
    "        goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "                        np.random.choice(FLAGS.number_goal_types, FLAGS.batch_size).reshape(-1,1))), \n",
    "                                  [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "        \n",
    "        utterances = np.zeros((FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size))\n",
    "        memories_com = np.zeros((FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size))\n",
    "        memories_last = np.zeros((FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size))\n",
    "        \n",
    "        states = np.concatenate([positions, velocities, gazes, self.cols], axis = 1)\n",
    "        targets = self.create_consistent_targets()\n",
    "        \n",
    "        return states, utterances, memories_com, memories_last, goal_locations, goal_types, targets\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 397 ms\n"
     ]
    }
   ],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.policy = Policy()\n",
    "        self.env = Environment()\n",
    "        \n",
    "        self.get_placeholders()\n",
    "        self.definition_arrays()\n",
    "        self.write_arrays()\n",
    "        self.learning_rate = self.learning_rate_decay()\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        self.loop()\n",
    "        self.output_to_run = [self.step, self.array_states_stack, self.array_utterances_stack, self.array_mem_com_stack, self.array_mem_last_stack, \n",
    "                                self.t_fin, self.reward]\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "        self.reward_history = []\n",
    "        self.env_history = []\n",
    "        self.arrays_history = []\n",
    "        \n",
    "        \n",
    "    def learning_rate_decay(self):\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        if FLAGS.learning_rate_decay:\n",
    "            starter_learning_rate = FLAGS.learning_rate\n",
    "            boundaries = [1000]\n",
    "            values = [FLAGS.learning_rate, FLAGS.learning_rate/10]\n",
    "            return tf.train.piecewise_constant(self.global_step, boundaries, values, name=None)\n",
    "        else:\n",
    "            return FLAGS.learning_rate\n",
    "        \n",
    "    def definition_arrays(self):\n",
    "        # Create goals vectors \n",
    "        self.array_states = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_utterances = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_com = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_last = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        \n",
    "    def get_placeholders(self):\n",
    "        [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets] = self.policy.get_placeholders()\n",
    "            \n",
    "            \n",
    "    def write_arrays(self):\n",
    "        self.array_states = self.array_states.write(0, self.states)\n",
    "        self.array_utterances = self.array_utterances.write(0, self.utterances)\n",
    "        self.array_mem_com = self.array_mem_com.write(0, self.mem_com)\n",
    "        self.array_mem_last = self.array_mem_last.write(0, self.mem_last)\n",
    "       \n",
    "        \n",
    "    def loop(self):\n",
    "        t = tf.constant(0)\n",
    "        return_sofar = tf.zeros([FLAGS.batch_size, 1], tf.float32)\n",
    "        args = [self.array_states, self.array_utterances, self.array_mem_com, self.array_mem_last, self.goal_types, \n",
    "                self.goal_locations, self.full_goals, self.name_targets, t, return_sofar]\n",
    "        \n",
    "        (array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, t_fin, rewards_batch) = tf.while_loop(self.condition, self.body, args)\n",
    "            \n",
    "        reward = tf.reduce_mean(rewards_batch, axis = 0)\n",
    "        self.step = self.optimizer.minimize(-reward, global_step = self.global_step)\n",
    "        self.array_states_stack = array_states.stack(), \n",
    "        self.array_utterances_stack = array_utterances.stack(), \n",
    "        self.array_mem_com_stack = array_mem_com.stack(), \n",
    "        self.array_mem_last_stack = array_mem_last.stack(), \n",
    "        self.t_fin = t_fin, \n",
    "        self.reward = reward\n",
    "        \n",
    "        #return step, array_states.stack(), array_utterances.stack(), array_mem_com.stack(), array_mem_last.stack(), t, reward\n",
    "            \n",
    "            \n",
    "    def body(self, array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, t, return_sofar):\n",
    "        \n",
    "        #Reading the last state of environment\n",
    "        states = array_states.read(t)\n",
    "        utterances = array_utterances.read(t)\n",
    "        mem_com = array_mem_com.read(t)\n",
    "        mem_last = array_mem_last.read(t)\n",
    "        \n",
    "        #new_states = states\n",
    "        #new_utterances = utterances\n",
    "        #new_mem_com = mem_com\n",
    "        #new_mem_last = mem_last\n",
    "        \n",
    "        #new_positions = tf.slice(new_states, [0, 0, 0], [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        #new_velocities = tf.slice(new_states, [0, 2, 0], [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        #new_gazes = tf.slice(new_states, [0, 4, 0], [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        #phys_output = tf.zeros([1, 4, FLAGS.batch_size])\n",
    "        #new_states = tf.zeros(shape = [FLAGS.number_agents + FLAGS.number_landmarks, 9, FLAGS.batch_size])\n",
    "        #new_utterances = tf.zeros(shape = [FLAGS.number_agents, 20, FLAGS.batch_size])\n",
    "        #new_mem_com = tf.zeros(shape = [FLAGS.number_agents, 32, FLAGS.batch_size])\n",
    "        #new_mem_last = tf.zeros(shape = [FLAGS.number_agents, 32, FLAGS.batch_size])\n",
    "        \n",
    "        phys_output, new_velocities, new_gazes, new_utterances, delta_mem_com, delta_mem_last = self.policy.forward_pass(states,\n",
    "                                                                    utterances, mem_com, mem_last, full_goals)\n",
    "        new_states, new_positions = compute_new_states(states, new_velocities, new_gazes, new_utterances)\n",
    "        new_mem_com, new_mem_last = compute_new_memories(mem_com, mem_last, delta_mem_com, delta_mem_last)\n",
    "        return_sofar += compute_reward(new_positions, new_gazes, phys_output, new_utterances, name_targets, goal_locations, \n",
    "                                        goal_types)\n",
    "        \n",
    "        #Writing the new state\n",
    "        array_states = array_states.write((t+1), new_states)\n",
    "        array_utterances = array_utterances.write((t+1), new_utterances)\n",
    "        array_mem_com = array_mem_com.write((t+1), new_mem_com)\n",
    "        array_mem_last = array_mem_last.write((t+1), new_mem_last)\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "        return [array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, t, return_sofar]\n",
    "        \n",
    "        \n",
    "    def condition(self, array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, t, return_sofar):\n",
    "        return tf.less(t, FLAGS.time_horizon)\n",
    "    \n",
    "    \n",
    "    def create_feed_dict(self, states, utterances, memories_com, memories_last, goal_locations, goal_types, targets):\n",
    "        list_values = [states, utterances, memories_com, memories_last, goal_types, goal_locations, targets]\n",
    "        list_placeholders = [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, \n",
    "                             self.goal_locations, self.name_targets]\n",
    "        feed_dict = {a:b for a,b in zip(list_placeholders, list_values)}\n",
    "        return feed_dict\n",
    "    \n",
    "    def train(self, sess):\n",
    "        print(\"Initializing variables\")\n",
    "        sess.run(self.init)\n",
    "        sess.graph.finalize()\n",
    "        print(\"Start training\")\n",
    "        start = datetime.now()\n",
    "        for i in range(FLAGS.max_steps):\n",
    "            states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = self.env.random_generation()\n",
    "            generation_time = datetime.now() - start\n",
    "            feed_dict = self.create_feed_dict(states, utterances, memories_com, memories_last, goal_locations, goal_types, targets)\n",
    "            _ , array_states, array_utterances, array_mem_com, array_mem_last, t, reward = sess.run(self.output_to_run, feed_dict)\n",
    "            self.reward_history.append(reward)\n",
    "            #self.env_history.append([states, utterances, memories_com, memories_last, goal_locations, goal_types, targets])\n",
    "            #self.arrays_history.append([array_states, array_utterances, array_mem_com, array_mem_last])\n",
    "            \n",
    "            if i % FLAGS.print_frequency == 0:\n",
    "                print(\"\\n\")\n",
    "                print(\"iteration \" + str(i))\n",
    "                print(reward)\n",
    "                states = array_states[0][-1, :, :, :]\n",
    "                print_stats_agent(states, goal_locations, goal_types)\n",
    "                print(\"computing time\")\n",
    "                print(datetime.now() - start)\n",
    "                print(\"generation time\")\n",
    "                print(generation_time)\n",
    "                print(\"memory usage\")\n",
    "                memory()\n",
    "\n",
    "                start = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "def memory():\n",
    "    import os\n",
    "    import psutil\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "    print('memory use:', memoryUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6d31372105b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 218 ms\n"
     ]
    }
   ],
   "source": [
    "exp.arrays_history[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing variables\n",
      "Start training\n",
      "\n",
      "\n",
      "iteration 0\n",
      "[-2660.40258789]\n",
      "--- Agent 0\n",
      "------ Mean distance 8.35277821184\n",
      "------ Median distance 5.93922252597\n",
      "------ Third quartile 12.7761400463\n",
      "------ Ninetieth percentile 17.8094842\n",
      "------ max distance 28.142024243\n",
      "computing time\n",
      "0:00:04.799920\n",
      "generation time\n",
      "0:00:00.017030\n",
      "memory usage\n",
      "memory use: 1.3709678649902344\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment()\n",
    "with tf.Session() as sess:\n",
    "    exp.train(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e13fa98ffdf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "exp.arrays_history[1][4].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem at iteration 1550, could not read from TensorArray, already read (during gradient computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: pd.rolling_mean is deprecated for DataFrame and will be removed in a future version, replace with \n",
      "\tDataFrame.rolling(center=False,window=400).mean()\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAFkCAYAAADoo9t2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIbwAAICaQngBAAA1hfACAABqyv8HC3bnweiSVPgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7192d7ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 353 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "history_reward = exp.reward_history\n",
    "d= pd.rolling_mean(pd.DataFrame(history_reward),400)\n",
    "d.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x4a9083da58>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.01 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'MatMul_2': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_2 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_2, b_2)]]\n\nCaused by op 'MatMul_2', defined at:\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 653, in launch_instance\n    app.start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-fa9d44ee79a4>\", line 5, in <module>\n    c = tf.matmul(a, b)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1217, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul_2': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_2 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_2, b_2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1116\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1166\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'MatMul_2': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_2 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_2, b_2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fa9d44ee79a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m# Runs the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'MatMul_2': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_2 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_2, b_2)]]\n\nCaused by op 'MatMul_2', defined at:\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 653, in launch_instance\n    app.start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-fa9d44ee79a4>\", line 5, in <module>\n    c = tf.matmul(a, b)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1816, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1217, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul_2': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/cpu:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_2 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a_2, b_2)]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 907 ms\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "    \n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "ee = get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "zeros1 = tf.zeros([3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
