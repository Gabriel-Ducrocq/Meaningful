{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from datetime import datetime\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "#%load_ext autotime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "#0.0008\n",
    "flags.DEFINE_float('learning_rate', 0.0008, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('max_steps', 50000, 'Number of iteration to train.')\n",
    "flags.DEFINE_integer('number_layers', 3, 'Number of layers in each network')\n",
    "flags.DEFINE_integer('layer_sizes', 256, 'Number of units in hidden layer.')\n",
    "flags.DEFINE_integer('batch_size', 100, 'Batch size.')\n",
    "flags.DEFINE_integer('dim_env', 2, 'dimension of the environment')\n",
    "flags.DEFINE_integer('number_goal_types', 3, 'number of different goal types')\n",
    "flags.DEFINE_integer('color_size', 3, 'number of components of the color: RGB as usual')\n",
    "flags.DEFINE_integer(\"output_size\", 256, \"number of units in the output layer\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.9, \"Dropouts rate of keeping\")\n",
    "flags.DEFINE_boolean(\"xav_init\", False,\"Distribution of initialization: False for normal, True for uniform\" )\n",
    "flags.DEFINE_integer(\"number_agents\", 2, \"Number of agents in the environment\")\n",
    "flags.DEFINE_integer(\"number_landmarks\", 3, \"Number of landmarks in the environment\")\n",
    "flags.DEFINE_integer(\"vocabulary_size\", 20, \"Size of the vocabulary\")\n",
    "flags.DEFINE_integer(\"mem_size\", 32, \"Size of the communication network's memory\")\n",
    "flags.DEFINE_integer(\"last_mem_size\", 32, \"Size of the last network's memory\")\n",
    "flags.DEFINE_float(\"gumbel_temperature\", 1, \"Temperature use for the gumbel softmax trick\")\n",
    "flags.DEFINE_float(\"sddev_phys_sampling\", 0.0001, \"Standard deviation used to sample the velocity and gaze output\")\n",
    "flags.DEFINE_float(\"delta_t\", 0.5, \"delta of time between timesteps\")\n",
    "flags.DEFINE_float(\"damping_coef\", 0.5, \"damping coefficient for the new velocity computation\")\n",
    "flags.DEFINE_float(\"stddev_memory\", 0.0001, \"standard deviation of the gaussian used to update memories\")\n",
    "flags.DEFINE_integer(\"bound\", 5, \"Bounds of generation of initial positions, centered in 0.\")#5 usually\n",
    "flags.DEFINE_integer(\"time_horizon\", 50, \"Number of timestep before the end of the experiment.\")\n",
    "flags.DEFINE_integer(\"print_frequency\", 500, \"Frequency at which we print the reward, in number of steps.\")\n",
    "flags.DEFINE_boolean(\"learning_rate_decay\", True, \"Wether to use a piecewise learning rate decay or no decay at all\")\n",
    "flags.DEFINE_integer(\"tensorboard_freq\", 10000, \"Frequency at which we save the statistics in tensorflow\")\n",
    "flags.DEFINE_float(\"alpha_dirichlet\", 0.7, \"Probability of seeing an out of vocabulary word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire:\n",
    "\n",
    "- Checker que le softmax pooling est correct\n",
    "\n",
    "- Checker que le gumbel trick est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le sampling physique est okay, notamment sur les début et longueur de slicing\n",
    "\n",
    "- Checker que le calcul du nouvel état est correct, notamment sur les débuts et longueur de slicing et concaténation\n",
    "\n",
    "- Ajouter le calcul des forces dans le calcul du nouvel état\n",
    "\n",
    "- Vérifier que le shuffling est correct\n",
    "\n",
    "- Vérifier que le calcul du reward est correct\n",
    "\n",
    "- Vérifier que la backprop considère bien les variables broadcastées comme les mêmes.\n",
    "\n",
    "- Vérifier que le tenseur states est bien dans cet ordre sur le second axe: position, velocité, gaze, couleurs\n",
    "\n",
    "- RELIER LES LANDMARKS AUX POSITIONS DES GOALS, SINON CA N A PAS DE SENS !!!\n",
    "\n",
    "- Checker que les goals types sont bien distribués: une unique coordonnée doit être 1, les autres 0, et ce pour chaque agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory():\n",
    "    import os\n",
    "    import psutil\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "    print('memory use:', memoryUse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_trajectory(coordinates, target_point, middle_point):\n",
    "    x = coordinates[1:-1, 0]\n",
    "    y = coordinates[1:-1, 1]\n",
    "    \n",
    "    x_start = coordinates[0, 0]\n",
    "    y_start = coordinates[0, 1]\n",
    "    \n",
    "    x_final = coordinates[-1, 0]\n",
    "    y_final = coordinates[-1, 1]\n",
    "    \n",
    "    x_target, y_target = target_point\n",
    "    x_middle, y_middle = middle_point\n",
    "    \n",
    "    plt.plot(x,y, \"o\")\n",
    "    plt.plot(x_start, y_start, 'ro')\n",
    "    plt.plot(x_target, y_target, 'go')\n",
    "    plt.plot(x_final, y_final, 'yo')\n",
    "    plt.plot(x_middle, y_middle, 'mo')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-FLAGS.bound, FLAGS.bound])\n",
    "    axes.set_ylim([-FLAGS.bound, FLAGS.bound])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def python_shuffle(positions, shuffle_indexes):\n",
    "    shuffled_array = np.stack(\n",
    "    [positions[shuffle_indexes[: , 0, i], :, i] for i in range(FLAGS.batch_size)], axis = 2)\n",
    "    return shuffled_array\n",
    "    \n",
    "    \n",
    "def delete_history_files():\n",
    "    if os.path.isfile(\"env_history.pkl\"):\n",
    "        os.remove(\"env_history.pkl\")\n",
    "        \n",
    "    if os.path.isfile(\"arrays_history.pkl\"):\n",
    "        os.remove(\"arrays_history.pkl\")\n",
    "        \n",
    "    if Path(\"Summary\").is_dir():\n",
    "        shutil.rmtree(\"Summary\")\n",
    "\n",
    "\n",
    "def print_stat_vocabulary(utterances_array, l):\n",
    "    x = np.argmax(utterances_array, axis = 2)\n",
    "    r = []\n",
    "    for i in range(FLAGS.batch_size):\n",
    "        r.append(len(np.unique(x[:, :, i])))\n",
    "    \n",
    "    if l%FLAGS.print_frequency == 0:\n",
    "        print(\"-- Stats word count:\")\n",
    "        print(\"---- Mean number of word activated: \" + str(np.mean(r)))\n",
    "        print(\"---- Median number of word activated: \" + str(np.median(r)))\n",
    "        \n",
    "    return np.mean(r)\n",
    "    \n",
    "        \n",
    "def dirichlet_log_lik_end(utterances_array):\n",
    "    #Note: we don't take minus the log-likelihood as we minimize minus the entire reward then !\n",
    "    by_symbol = tf.reduce_sum(utterances_array, axis =[0, 1, 3])\n",
    "    total_nb_uttered = FLAGS.number_agents*FLAGS.time_horizon*FLAGS.batch_size\n",
    "    ratio = by_symbol/(FLAGS.alpha_dirichlet + total_nb_uttered - 1)\n",
    "    log_likelihood = tf.reduce_sum(tf.log(ratio)*by_symbol)\n",
    "    return log_likelihood\n",
    "    \n",
    "    \n",
    "# Param: x, stacking of the output of fully connected physical network for each agent. Shape = (256, batch_size, nb_agents)\n",
    "# return: pooling of input features.\n",
    "def softmax_pooling(x):\n",
    "    # pooling function. Softmax pooling is a compromise between max pooling and average pooling\n",
    "    coefs = tf.nn.softmax(x, dim = 0)\n",
    "    softmax_pool = tf.reduce_sum(tf.multiply(coefs, x), axis = 0)\n",
    "    return softmax_pool\n",
    "\n",
    "\n",
    "def activation_function(x):\n",
    "    return tf.nn.elu(x)\n",
    "\n",
    "\n",
    "def gumbel_max_trick(x, hard = True):\n",
    "    # Application of gumbel-softmax trick\n",
    "    # Input: output of the last network \n",
    "    u = -tf.log(-tf.log(tf.random_uniform(shape = [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size],\n",
    "                                          dtype=tf.float32)))\n",
    "    utterance_output = tf.slice(x, [0, 2*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "    gumbel = tf.exp((utterance_output + u)/FLAGS.gumbel_temperature)\n",
    "    denoms = tf.reshape(tf.reduce_sum(gumbel, axis = 1), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    utterance = gumbel/denoms\n",
    "    \n",
    "    if hard:\n",
    "        idx_utt = tf.argmax(utterance, axis = 1)\n",
    "        utt_hard = tf.transpose(tf.one_hot(idx_utt, depth = FLAGS.vocabulary_size), [0, 2, 1])\n",
    "        utterance = tf.stop_gradient(utt_hard - utterance) + utterance\n",
    "        \n",
    "    return utterance \n",
    "\n",
    "\n",
    "def sample_phys(x):\n",
    "    #Input: output of the last network.\n",
    "    #Output: sampled values for new velocity and gaze\n",
    "    u = tf.random_normal(shape = [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size],dtype=tf.float32,\n",
    "                         stddev = FLAGS.sddev_phys_sampling)\n",
    "    o = tf.add(tf.slice(x, [0, 0, 0], [FLAGS.number_agents, 2*FLAGS.dim_env, FLAGS.batch_size]), u)\n",
    "    sample_move = tf.slice(o, [0, 0, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    sample_gaze  = tf.slice(o, [0, FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    return sample_move, sample_gaze\n",
    "\n",
    "\n",
    "def compute_new_states(old_states, new_velocities, new_delta_gazes, new_utterances):\n",
    "    #Computes the new states according to the equations of the papers.\n",
    "    # Input: the old states of shape [number agents + nb_landmarks, 3*env dim + color size, batch size] because color is in state\n",
    "    # and of shape [number_agents, 2*env_dim, batch size]\n",
    "    # Adding the outputs of landmark, which are all zeros.\n",
    "    #new_velocities = tf.concat([new_velocities, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "\n",
    "    #new_delta_gazes = tf.concat([new_delta_gazes, tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])],\n",
    "    #                                       axis = 0)\n",
    "    \n",
    "    #old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "    #                        [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    #new_pos = tf.slice(old_states, [0, 0, 0], \n",
    "    #                   [FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    #new_gazes = old_gazes + new_delta_gazes*FLAGS.delta_t\n",
    "    \n",
    "    #new_velocity = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    \n",
    "    old_velocity = tf.slice(old_states, [0, FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    old_gazes = tf.slice(old_states, [0, 2*FLAGS.dim_env, 0], \n",
    "                            [FLAGS.number_agents , FLAGS.dim_env, FLAGS.batch_size])\n",
    "    \n",
    "    new_pos_agents = tf.slice(old_states, [0, 0, 0], \n",
    "                       [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size]) + old_velocity*FLAGS.delta_t\n",
    "    \n",
    "    new_pos_landmarks = tf.slice(old_states, [FLAGS.number_agents, 0, 0], \n",
    "                       [FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_pos = tf.concat([new_pos_agents, new_pos_landmarks], axis = 0)\n",
    "    \n",
    "    new_gazes_agents = old_gazes + new_delta_gazes*FLAGS.delta_t\n",
    "    new_gazes_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_gazes = tf.concat([new_gazes_agents, new_gazes_landmarks], axis = 0)\n",
    "    \n",
    "    new_velocity_agents = (1 - FLAGS.damping_coef)*old_velocity + new_velocities*FLAGS.delta_t\n",
    "    new_velocity_landmarks = tf.zeros([FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "    new_velocity = tf.concat([new_velocity_agents, new_velocity_landmarks], axis = 0)\n",
    "    \n",
    "    colors = tf.slice(old_states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                            FLAGS.color_size, FLAGS.batch_size])\n",
    "    new_states = tf.concat([new_pos, new_velocity, new_gazes, colors], axis = 1)\n",
    "\n",
    "    return new_states, new_pos, new_gazes\n",
    "\n",
    "\n",
    "\n",
    "def compute_new_memories(old_mem_com, old_mem_last, delta_mem_com, delta_mem_last):\n",
    "    new_memory_com = tf.tanh((2/3)*(old_mem_com + delta_mem_com + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    new_memory_last = tf.tanh((2/3)*(old_mem_last + delta_mem_last + tf.random_normal([FLAGS.number_agents, FLAGS.mem_size,\n",
    "                                                                             FLAGS.batch_size], FLAGS.stddev_memory)))\n",
    "    \n",
    "    return new_memory_com,new_memory_last\n",
    "\n",
    "\n",
    "\n",
    "def shuffle(x, name_targets, colors = False):\n",
    "    slices_second_dim = []\n",
    "    ones = tf.ones([FLAGS.number_agents, 1, FLAGS.batch_size], tf.int32)\n",
    "    batch_num = tf.tile(tf.reshape(tf.range(0, FLAGS.batch_size, dtype = tf.int32), [1, 1, FLAGS.batch_size]), [FLAGS.number_agents,\n",
    "                                                                                                               1, 1])\n",
    "    if not colors:\n",
    "        for i in range(FLAGS.dim_env):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "    else:\n",
    "        for i in range(FLAGS.color_size):\n",
    "            slices_second_dim.append(tf.reshape(tf.concat([name_targets, ones*i, batch_num], axis = 1), \n",
    "                                            [FLAGS.number_agents, 1, 3, FLAGS.batch_size]))\n",
    "            \n",
    "    gathering_tensor = tf.transpose(tf.concat(slices_second_dim, axis = 1), perm = [0, 1, 3, 2])\n",
    "    shuffled_x = tf.gather_nd(x, gathering_tensor)\n",
    "    \n",
    "    return shuffled_x\n",
    "    \n",
    "    \n",
    "def compute_reward(positions, gazes, outputs, utterances, name_targets, goals_loc, goals_types):\n",
    "    shuffled_positions = shuffle(positions, name_targets)\n",
    "    shuffled_gazes = shuffle(gazes, name_targets)\n",
    "\n",
    "    pos_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_positions - goals_loc)), axis = 1), [FLAGS.number_agents, 1, \n",
    "                                                                                                     FLAGS.batch_size])\n",
    "\n",
    "    gaze_distances = tf.reshape(tf.reduce_sum(tf.square((shuffled_gazes - goals_loc)), axis = 1), [FLAGS.number_agents, 1,\n",
    "                                                                                                     FLAGS.batch_size])\n",
    "    zeros = tf.zeros([FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    x = tf.concat([pos_distances, gaze_distances, zeros], axis = 1)\n",
    "    print(\"X\")\n",
    "    print(x)\n",
    "    print(goals_types)\n",
    "    print(tf.multiply(x, goals_types))\n",
    "    dists_goal = -tf.reduce_sum(tf.multiply(x, goals_types), axis = 1)\n",
    "    print(dists_goal)\n",
    "    \n",
    "    utterances_term = -tf.reduce_sum(tf.square(utterances), axis = 1)\n",
    "    output_term = -tf.reduce_sum(tf.square(outputs), axis = 1)\n",
    "    \n",
    "    reward_by_batch = tf.reshape(tf.reduce_sum(dists_goal + utterances_term + output_term, axis = 0), [FLAGS.batch_size, 1])\n",
    "\n",
    "    return reward_by_batch\n",
    "\n",
    "\n",
    "\n",
    "def compute_goal_dist(states, goal_location, goal_type):\n",
    "    dist_positions = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 0:2, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    dist_gazes = np.reshape(np.sqrt(np.sum((states[0:FLAGS.number_agents, 4:6, :] - goal_location)**2, axis = 1)), [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "    v = np.concatenate([dist_positions, dist_gazes, np.zeros((FLAGS.number_agents, 1, FLAGS.batch_size))], axis = 1)\n",
    "    goal_distances = np.sum(np.multiply(v, goal_type), axis = 1)\n",
    "    \n",
    "    return goal_distances\n",
    "\n",
    "\n",
    "def print_stats_agent(states, goal_location, goal_type, targets):\n",
    "    #Only considering non \"do nothing goals\"\n",
    "    shuffled_states = python_shuffle(states, targets)\n",
    "    goal_distances = compute_goal_dist(shuffled_states, goal_location, goal_type)\n",
    "    \n",
    "    for i in range(FLAGS.number_agents):\n",
    "        distances_agents = goal_distances[i, :]\n",
    "        goal_wo_zeros = distances_agents[distances_agents != 0]\n",
    "        mean = np.mean(goal_wo_zeros)\n",
    "        median = np.median(goal_wo_zeros)\n",
    "        third_quart = np.percentile(goal_wo_zeros, 75)\n",
    "        nine_pct = np.percentile(goal_wo_zeros, 90)\n",
    "        max_dist = np.max(distances_agents)\n",
    "        argmax = np.argmax(distances_agents)\n",
    "        print(\"--- Agent \" + str(i))\n",
    "        print(\"------ Mean distance \" + str(mean))\n",
    "        print(\"------ Median distance \" + str(median))\n",
    "        print(\"------ Third quartile \" + str(third_quart))\n",
    "        print(\"------ Ninetieth percentile \" + str(nine_pct))\n",
    "        print(\"------ max distance \" + str(max_dist))\n",
    "        print(\"------ argmax distance \" + str(argmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the physical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhysicalNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 3*FLAGS.dim_env + FLAGS.color_size\n",
    "        \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        \n",
    "        self.init_weights()\n",
    "        self.init_biases()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, number of inputs]\n",
    "        #This shape enables us to handle all the agents/landmarks states at once, instead of dealing with list of agents' states\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"phys_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.layer_sizes, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    tf.summary.histogram('phys_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"bias_\" + str(i), shape=[1, FLAGS.output_size, 1],\n",
    "                                            initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents + FLAGS.number_landmarks, 1, 1])\n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "            \n",
    "            \n",
    "    def compute_output(self, x): \n",
    "        # Compute a forward pass through the network\n",
    "        # Input: a tensor of shape [number of agents, size of input, batch _size]\n",
    "        # Output: a tensor of shape [number of agents, output_size, batch_size]\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                W = self.Weights[i]\n",
    "                b = self.Biases[i]\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "                else:\n",
    "                    x = activation_function(tf.matmul(W, x) + b)\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the communication network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CommunicationNet: \n",
    "    \n",
    "    def __init__(self):    \n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"com_memory_read_weight\", shape = [1, FLAGS.output_size, FLAGS.mem_size],\n",
    "                                               initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        #Initialization of the weights of all the networks' layers\n",
    "        #Weights are 3 dimensional arrays: [number of agents, number of units, vocabulary size]\n",
    "        #This shape enables us to handle all the agents utterances at once, instead of dealing with list of agents' states        \n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.vocabulary_size],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"com_net_weight_\" + str(i), shape=[1, FLAGS.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                        [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "                    tf.summary.histogram('com_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "       \n",
    "    \n",
    "    def init_biases(self):\n",
    "        #Initialization of the weights of all the networks' biases.\n",
    "        # Same remark as the weights concerning the shapes of the biases.\n",
    "        with tf.variable_scope(\"com_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i < (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('com_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"com_net_bias_\" + str(i), shape = [1, FLAGS.output_size, 1], \n",
    "                                   initializer = tf.orthogonal_initializer()), \n",
    "                                    [FLAGS.number_agents, 1, 1])  \n",
    "                    \n",
    "                self.Biases.append(B)\n",
    "       \n",
    "    \n",
    "    def def_delta_mem(self):\n",
    "        # Initialization of the weights and biases writing in the memory.\n",
    "        # Their shape are of the form [number of agents, memory_size, output size] and [number of agents, output size, 1]\n",
    "        # So that we can handle the memories of all agents at onces instead of dealing with list of memories.\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_com\" , shape=[1, FLAGS.mem_size,FLAGS.output_size],\n",
    "                            initializer=tf.orthogonal_initializer()), \n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_com\", shape = [1, FLAGS.mem_size, 1],\n",
    "                            initializer=tf.orthogonal_initializer()),\n",
    "                             [FLAGS.number_agents, 1, 1])\n",
    "\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "                \n",
    "            \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LastNet: \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_size = 2*FLAGS.output_size + FLAGS.color_size + FLAGS.number_goal_types + FLAGS.dim_env\n",
    "        self.output_size = 2*FLAGS.dim_env + FLAGS.vocabulary_size\n",
    "        self.Weights = []\n",
    "        self.Biases = []\n",
    "        self.Weight_read_mem = tf.tile(tf.get_variable(\"reading_last_mem_weight\", shape = [1, self.output_size, FLAGS.last_mem_size],\n",
    "                                              initializer=tf.orthogonal_initializer()),\n",
    "                                               [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        self.init_weights()    \n",
    "        self.init_biases()\n",
    "        self.def_delta_mem()\n",
    "        \n",
    "        \n",
    "    def init_weights(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i == 0:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, self.input_size],\n",
    "                                        initializer=tf.orthogonal_initializer()), \n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                elif i != (FLAGS.number_layers - 1):\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, FLAGS.layer_sizes, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "                else:\n",
    "                    W = tf.tile(tf.get_variable(\"last_net_weight_\" + str(i), shape=[1, self.output_size, FLAGS.layer_sizes],\n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_weight_'+ str(i), W)\n",
    "\n",
    "                self.Weights.append(W)\n",
    "            \n",
    "    def init_biases(self):\n",
    "        with tf.variable_scope(\"last_variable\") as scope:\n",
    "            for i in range(FLAGS.number_layers):\n",
    "                if i != (FLAGS.number_layers - 1):\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, FLAGS.layer_sizes, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "                else:\n",
    "                    B = tf.tile(tf.get_variable(\"last_net_bias_\" + str(i), shape = [1, self.output_size, 1], \n",
    "                                        initializer=tf.orthogonal_initializer()),\n",
    "                                [FLAGS.number_agents, 1, 1])\n",
    "                    tf.summary.histogram('last_net_bias_'+ str(i), B)\n",
    "\n",
    "                self.Biases.append(B)\n",
    "\n",
    "        \n",
    "    def def_delta_mem(self):\n",
    "        self.W_mem = tf.tile(tf.get_variable(\"weight_mem_last\", shape=[1, FLAGS.last_mem_size ,self.output_size],\n",
    "                                initializer=tf.orthogonal_initializer()),\n",
    "                                 [FLAGS.number_agents, 1, 1])\n",
    "        self.b_mem = tf.tile(tf.get_variable(\"bias_mem_last\" ,shape = [1, FLAGS.last_mem_size, 1], \n",
    "                                    initializer=tf.orthogonal_initializer()),\n",
    "                                  [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "    def compute_output(self, x, memory):\n",
    "        for i in range(FLAGS.number_layers):\n",
    "            W = self.Weights[i]\n",
    "            b = self.Biases[i]\n",
    "            if i != (FLAGS.number_layers - 1):\n",
    "                x = tf.nn.dropout(activation_function(tf.matmul(W, x) + b), keep_prob = FLAGS.keep_prob)\n",
    "            else:\n",
    "                x = activation_function(tf.matmul(W, x) + tf.matmul(self.Weight_read_mem, memory) + b)\n",
    "               \n",
    "        delta_mem = activation_function(tf.add(tf.matmul(self.W_mem, x),self.b_mem))\n",
    "        return x, delta_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the policy: putting all the networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Policy:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.phys_network = PhysicalNet()\n",
    "        self.comm_network = CommunicationNet()\n",
    "        self.last_network = LastNet()\n",
    "        \n",
    "        self.define_placeholders()\n",
    "        self.define_full_goals()\n",
    "        \n",
    "        \n",
    "    def define_placeholders(self):\n",
    "        self.states = tf.placeholder(tf.float32, [FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                  3*FLAGS.dim_env + FLAGS.color_size, FLAGS.batch_size])\n",
    "        self.utterances = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size])\n",
    "        self.memories_com = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size])\n",
    "        self.memories_last = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size])\n",
    "        self.goal_types = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.number_goal_types, FLAGS.batch_size])\n",
    "        self.goal_locations = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        self.name_targets = tf.placeholder(tf.int32, [FLAGS.number_agents, 1, FLAGS.batch_size])\n",
    "        #self.colors = tf.placeholder(tf.float32, [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        \n",
    "        \n",
    "    def define_full_goals(self):\n",
    "        colors = tf.slice(self.states, [0, 3*FLAGS.dim_env, 0], [FLAGS.number_agents, FLAGS.color_size, FLAGS.batch_size])\n",
    "        shuffled_colors = shuffle(colors, self.name_targets, colors = True)\n",
    "        self.full_goals = tf.concat([self.goal_types, self.goal_locations, shuffled_colors], axis = 1)\n",
    "    \n",
    "    def get_placeholders(self):\n",
    "        return [self.states, self.utterances, self.memories_com, self.memories_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets]\n",
    "        \n",
    "    def forward_pass(self, states, utterances, mem, mem_last, goals_last):\n",
    "        #Step 1: processing observed states and utterances\n",
    "        phys_output = self.phys_network.compute_output(states)\n",
    "        comm_output, delta_mem_com = self.comm_network.compute_output(utterances, mem)\n",
    "        \n",
    "        #Step 2: softmax pooling the results [num_agents, output size, batch_size] --> [1, output size, batch_size]\n",
    "        PhiX = softmax_pooling(phys_output)\n",
    "        PhiC = softmax_pooling(comm_output)\n",
    "        \n",
    "        #Step 3: feeding the last network      \n",
    "        PhiX_last = tf.tile(tf.reshape(PhiX, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        PhiC_last = tf.tile(tf.reshape(PhiC, [1, FLAGS.output_size, FLAGS.batch_size]), [FLAGS.number_agents, 1, 1])\n",
    "        \n",
    "        input_last = tf.concat([PhiX_last, goals_last, PhiC_last], axis = 1)\n",
    "        \n",
    "        output_last, delta_mem_last = self.last_network.compute_output(input_last, mem_last)\n",
    "        \n",
    "        velocities_output, gazes_output = sample_phys(output_last)\n",
    "        utterances_output = gumbel_max_trick(output_last)\n",
    "        phys_output = tf.concat([velocities_output, gazes_output], axis = 1)\n",
    "        \n",
    "        return phys_output, velocities_output, gazes_output, utterances_output, delta_mem_com, delta_mem_last\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.enc = OneHotEncoder(n_values=FLAGS.number_goal_types, sparse=False)\n",
    "        self.colors = [(1, 0, 0), (0, 1, 0), (0, 0, 1)] \n",
    "        self.cols, self.cols_agents, self.cols_landmarks = self.create_colors()\n",
    "    \n",
    "    \n",
    "    def create_colors(self):\n",
    "        cols_agents = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_agents)], axis = 0)\n",
    "        cols_landmarks = np.concatenate([np.tile(np.reshape(self.colors[i], [1, FLAGS.color_size, 1]), [1, 1, FLAGS.batch_size]) \n",
    "                               for i in range(FLAGS.number_landmarks)], axis = 0)\n",
    "        \n",
    "        cols = np.concatenate([cols_agents, cols_landmarks], axis = 0)\n",
    "            \n",
    "        return cols, cols_agents, cols_landmarks\n",
    "            \n",
    "        \n",
    "    def create_consistent_targets(self):\n",
    "        targets_by_exp = [np.random.choice(FLAGS.number_agents, (FLAGS.number_agents, 1), replace = False) for _ in range(FLAGS.batch_size)]\n",
    "        #targets_by_exp1 = np.stack([np.array([[1], [0]]) for _ in range(int(FLAGS.batch_size/2))], axis = 2)\n",
    "        #targets_by_exp2 = np.stack([np.array([[0], [1]]) for _ in range(int(FLAGS.batch_size/2.0))], axis = 2)\n",
    "        #targets_batch = np.concatenate([targets_by_exp1, targets_by_exp2], axis = 2)\n",
    "        targets_batch = np.stack(targets_by_exp, axis = 2)\n",
    "        return targets_batch\n",
    "    \n",
    "    def create_goal_locations(self, pos_landmarks):\n",
    "        landmark_nb = [np.random.choice(FLAGS.number_landmarks, (FLAGS.number_agents, 1), replace = True) for _ in range(FLAGS.batch_size)]\n",
    "        landmark_nb_batch = np.stack(landmark_nb, axis = 2)\n",
    "        \n",
    "        goal_loc = python_shuffle(pos_landmarks, landmark_nb_batch)\n",
    "        \n",
    "        return goal_loc\n",
    "        \n",
    "        \n",
    "    def random_generation(self):\n",
    "        positions_agents = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        #positions_agents = np.array([[[1 for i in range(100)], [1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        \n",
    "        positions_landmarks = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        #positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]], [[4 for i in range(100)], [4 for i in range(100)]]])\n",
    "        #positions_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]]])\n",
    "        #gazes_landmarks = np.array([[[-4 for i in range(100)], [-4 for i in range(100)]]])\n",
    "        positions = np.concatenate([positions_agents, positions_landmarks], axis = 0)\n",
    "        \n",
    "        gazes = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "                                                                  FLAGS.dim_env, FLAGS.batch_size))\n",
    "        #gazes_agents = np.array([[[1 for i in range(100)], [1 for i in range(100)]], [[1 for i in range(100)], [1 for i in range(100)]]])\n",
    "        #gazes = np.concatenate([gazes_agents, gazes_landmarks], axis = 0)\n",
    "        #velocities = np.random.uniform(-FLAGS.bound, FLAGS.bound, (FLAGS.number_agents + FLAGS.number_landmarks, \n",
    "        #                                                     FLAGS.dim_env, FLAGS.batch_size))\n",
    "        \n",
    "        velocities = np.zeros([FLAGS.number_agents + FLAGS.number_landmarks, FLAGS.dim_env, FLAGS.batch_size])\n",
    "        \n",
    "        #goal_locations = np.random.uniform(-FLAGS.bound, FLAGS.bound, [FLAGS.number_agents, \n",
    "        #                                                          FLAGS.dim_env, FLAGS.batch_size])\n",
    " \n",
    "        goal_locations = self.create_goal_locations(positions_landmarks)\n",
    "        \n",
    "        goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "                        np.random.choice(FLAGS.number_goal_types, FLAGS.batch_size).reshape(-1,1))), \n",
    "                                  [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "        #goal_types = np.concatenate([np.reshape(np.transpose(self.enc.fit_transform(\n",
    "        #                np.random.choice([0,1], FLAGS.batch_size).reshape(-1,1))), \n",
    "        #                          [1, FLAGS.number_goal_types, FLAGS.batch_size]) for _ in range(FLAGS.number_agents)], axis = 0)\n",
    "\n",
    "\n",
    "        #goal_types = np.array([[[1 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)], [0 for i in range(FLAGS.batch_size)]] for m in range(2)])\n",
    "        utterances = np.zeros((FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size))\n",
    "        memories_com = np.zeros((FLAGS.number_agents, FLAGS.mem_size, FLAGS.batch_size))\n",
    "        memories_last = np.zeros((FLAGS.number_agents, FLAGS.last_mem_size, FLAGS.batch_size))\n",
    "        \n",
    "        states = np.concatenate([positions, velocities, gazes, self.cols], axis = 1)\n",
    "        targets = self.create_consistent_targets()\n",
    "\n",
    "        return states, utterances, memories_com, memories_last, goal_locations, goal_types, targets\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.policy = Policy()\n",
    "        self.env = Environment()\n",
    "        delete_history_files()\n",
    "        \n",
    "        self.get_placeholders()\n",
    "        self.definition_arrays()\n",
    "        self.write_arrays()\n",
    "        self.learning_rate = self.learning_rate_decay()\n",
    "        tf.summary.scalar('learning rate', self.learning_rate)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        self.loop()\n",
    "        self.output_to_run = [self.step, self.array_states_stack, self.array_utterances_stack, self.array_mem_com_stack, self.array_mem_last_stack, \n",
    "                                self.f_g , self.array_outputs_stack, self.t_fin, self.reward, self.phys_reward, self.voc_reward]\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "        self.reward_history = []\n",
    "        self.voc_reward_history = []\n",
    "        self.env_history = []\n",
    "        self.arrays_history = []\n",
    "        self.mean_act_count = []\n",
    "        \n",
    "        \n",
    "    def learning_rate_decay(self):\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        if FLAGS.learning_rate_decay:\n",
    "            starter_learning_rate = FLAGS.learning_rate\n",
    "            boundaries = [3000] #, 10000]\n",
    "            values = [FLAGS.learning_rate, FLAGS.learning_rate/10] #, FLAGS.learning_rate/100]\n",
    "            return tf.train.piecewise_constant(self.global_step, boundaries, values, name=None)\n",
    "        else:\n",
    "            return FLAGS.learning_rate\n",
    "        \n",
    "    def definition_arrays(self):\n",
    "        # Create goals vectors \n",
    "        self.array_states = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_utterances = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_com = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_mem_last = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        self.array_outputs = tf.TensorArray(dtype = tf.float32, size = (FLAGS.time_horizon+1), clear_after_read = False)\n",
    "        \n",
    "    def get_placeholders(self):\n",
    "        [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, self.goal_locations, \n",
    "                self.full_goals, self.name_targets] = self.policy.get_placeholders()\n",
    "            \n",
    "            \n",
    "    def write_arrays(self):\n",
    "        self.array_states = self.array_states.write(0, self.states)\n",
    "        self.array_utterances = self.array_utterances.write(0, self.utterances)\n",
    "        self.array_mem_com = self.array_mem_com.write(0, self.mem_com)\n",
    "        self.array_mem_last = self.array_mem_last.write(0, self.mem_last)\n",
    "        self.array_outputs = self.array_outputs.write(0, np.zeros((FLAGS.number_agents, 4, FLAGS.batch_size), dtype = np.float32))\n",
    "        \n",
    "    def loop(self):\n",
    "        t = tf.constant(0)\n",
    "        return_sofar = tf.zeros([FLAGS.batch_size, 1], tf.float32)\n",
    "        args = [self.array_states, self.array_utterances, self.array_mem_com, self.array_mem_last, self.goal_types, \n",
    "                self.goal_locations, self.full_goals, self.name_targets, self.array_outputs, t, return_sofar]\n",
    "        \n",
    "        (array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t_fin, rewards_batch) = tf.while_loop(self.condition, self.body, args, parallel_iterations=1)\n",
    "        \n",
    "        self.array_states_stack = array_states.stack()\n",
    "        self.array_utterances_stack = array_utterances.stack() \n",
    "        self.array_mem_com_stack = array_mem_com.stack() \n",
    "        self.array_mem_last_stack = array_mem_last.stack() \n",
    "        self.array_outputs_stack = array_outputs.stack()\n",
    "        \n",
    "        self.phys_reward = tf.reshape(tf.reduce_mean(rewards_batch, axis = 0), [])\n",
    "        self.voc_reward = dirichlet_log_lik_end(tf.slice(self.array_utterances_stack, [1, 0, 0, 0], [FLAGS.time_horizon, FLAGS.number_agents, FLAGS.vocabulary_size, FLAGS.batch_size]))\n",
    "        self.f_g = full_goals\n",
    "        self.t_fin = t_fin, \n",
    "        self.reward = self.phys_reward + self.voc_reward\n",
    "        \n",
    "        tf.summary.scalar('accuracy', -self.reward)\n",
    "        grads = self.optimizer.compute_gradients(-self.reward)\n",
    "        self.step = self.optimizer.apply_gradients(grads, global_step=self.global_step)\n",
    "        for index, grad in enumerate(grads):\n",
    "            tf.summary.histogram(\"{}-grad\".format(grads[index][1].name), grads[index]) \n",
    "    \n",
    "        \n",
    "    def body(self, array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar):\n",
    "        \n",
    "        #Reading the last state of environment\n",
    "        states = array_states.read(t)\n",
    "        utterances = array_utterances.read(t)\n",
    "        mem_com = array_mem_com.read(t)\n",
    "        mem_last = array_mem_last.read(t)\n",
    "        \n",
    "        phys_output, new_velocities, new_delta_gazes, new_utterances, delta_mem_com, delta_mem_last = self.policy.forward_pass(states,\n",
    "                                                                    utterances, mem_com, mem_last, full_goals)\n",
    "\n",
    "        new_states, new_positions, new_gazes = compute_new_states(states, new_velocities, new_delta_gazes, new_utterances)\n",
    "\n",
    "        new_mem_com, new_mem_last = compute_new_memories(mem_com, mem_last, delta_mem_com, delta_mem_last)\n",
    "        \n",
    "        return_sofar += compute_reward(new_positions, new_gazes, phys_output, new_utterances, name_targets, goal_locations, \n",
    "                                        goal_types)\n",
    "\n",
    "        #Writing the new state\n",
    "        array_states = array_states.write((t+1), new_states)\n",
    "        array_utterances = array_utterances.write((t+1), new_utterances)\n",
    "        array_mem_com = array_mem_com.write((t+1), new_mem_com)\n",
    "        array_mem_last = array_mem_last.write((t+1), new_mem_last)\n",
    "        array_outputs = array_outputs.write((t+1), phys_output)\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "        return [array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar]\n",
    "        \n",
    "        \n",
    "    def condition(self, array_states, array_utterances, array_mem_com, array_mem_last, goal_types, goal_locations, full_goals, \n",
    "             name_targets, array_outputs, t, return_sofar):\n",
    "        return tf.less(t, FLAGS.time_horizon)\n",
    "    \n",
    "    \n",
    "    def create_feed_dict(self, states, utterances, memories_com, memories_last, goal_locations, goal_types, targets):\n",
    "        list_values = [states, utterances, memories_com, memories_last, goal_types, goal_locations, targets]\n",
    "        list_placeholders = [self.states, self.utterances, self.mem_com, self.mem_last, self.goal_types, \n",
    "                             self.goal_locations, self.name_targets]\n",
    "        feed_dict = {a:b for a,b in zip(list_placeholders, list_values)}\n",
    "        return feed_dict\n",
    "    \n",
    "    def train(self, sess):\n",
    "        self.train_writer = tf.summary.FileWriter('Summary', sess.graph)\n",
    "        print(\"Initializing variables\")\n",
    "        sess.run(self.init)\n",
    "        sess.graph.finalize()\n",
    "        print(\"Start training\")\n",
    "        start = datetime.now()\n",
    "        self.arrays_history = [0, 0, 0, 0, 0]\n",
    "        self.full_g = []\n",
    "        #states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = self.env.random_generation()\n",
    "        for i in range(FLAGS.max_steps):\n",
    "            states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = self.env.random_generation()\n",
    "            generation_time = datetime.now() - start\n",
    "            feed_dict = self.create_feed_dict(states, utterances, memories_com, memories_last, goal_locations, goal_types, targets)\n",
    "            if i % FLAGS.tensorboard_freq == 0:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, t, reward, phys_reward, voc_reward, summary = sess.run(self.output_to_run + [self.merged], feed_dict)\n",
    "                self.train_writer.add_summary(summary, i)\n",
    "            else:\n",
    "                _ , array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs, t, reward, phys_reward, voc_reward = sess.run(self.output_to_run, feed_dict)\n",
    "            \n",
    "            self.reward_history.append(reward)\n",
    "            self.voc_reward_history.append(voc_reward)\n",
    "            #self.full_g.append(self.arrays_history[-1])\n",
    "            self.arrays_history = [array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs]\n",
    "            \n",
    "            with open('env_history.pkl', 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([states, utterances, memories_com, memories_last, goal_locations, goal_types, targets])\n",
    "                \n",
    "            with open(\"arrays_history.pkl\", 'wb') as f:\n",
    "                pickler = cPickle.Pickler(f)\n",
    "                pickler.dump([array_states, array_utterances, array_mem_com, array_mem_last, array_outputs])\n",
    "                \n",
    "            if i % FLAGS.print_frequency == 0:\n",
    "                print(\"\\n\")\n",
    "                print(\"iteration \" + str(i))\n",
    "                print(\"physical reward: \" + str(phys_reward))\n",
    "                print(\"vocabulary reward: \" + str(voc_reward))\n",
    "                print(\"total reward: \" + str(reward))\n",
    "                final_states = array_states[-1, :, :, :]\n",
    "                print_stats_agent(final_states, goal_locations, goal_types, targets)\n",
    "    \n",
    "                print(\"computing time\")\n",
    "                print(datetime.now() - start)\n",
    "                print(\"generation time\")\n",
    "                print(generation_time)\n",
    "                print(\"memory usage\")\n",
    "                memory()\n",
    "\n",
    "                start = datetime.now()\n",
    "                \n",
    "            self.mean_act_count.append(print_stat_vocabulary(array_utterances, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name learning rate is illegal; using learning_rate instead.\n",
      "X\n",
      "Tensor(\"while/concat_18:0\", shape=(2, 3, 100), dtype=float32)\n",
      "Tensor(\"while/Identity_4:0\", shape=(2, 3, 100), dtype=float32)\n",
      "Tensor(\"while/Mul_2:0\", shape=(2, 3, 100), dtype=float32)\n",
      "Tensor(\"while/Neg_2:0\", shape=(2, 100), dtype=float32)\n",
      "INFO:tensorflow:Summary name phys_variable/weight_0:0-grad is illegal; using phys_variable/weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_1:0-grad is illegal; using phys_variable/weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/weight_2:0-grad is illegal; using phys_variable/weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_0:0-grad is illegal; using phys_variable/bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_1:0-grad is illegal; using phys_variable/bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name phys_variable/bias_2:0-grad is illegal; using phys_variable/bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_memory_read_weight:0-grad is illegal; using com_memory_read_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_0:0-grad is illegal; using com_variable/com_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_1:0-grad is illegal; using com_variable/com_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_weight_2:0-grad is illegal; using com_variable/com_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_0:0-grad is illegal; using com_variable/com_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_1:0-grad is illegal; using com_variable/com_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name com_variable/com_net_bias_2:0-grad is illegal; using com_variable/com_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_com:0-grad is illegal; using weight_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_com:0-grad is illegal; using bias_mem_com_0-grad instead.\n",
      "INFO:tensorflow:Summary name reading_last_mem_weight:0-grad is illegal; using reading_last_mem_weight_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_0:0-grad is illegal; using last_variable/last_net_weight_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_1:0-grad is illegal; using last_variable/last_net_weight_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_weight_2:0-grad is illegal; using last_variable/last_net_weight_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_0:0-grad is illegal; using last_variable/last_net_bias_0_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_1:0-grad is illegal; using last_variable/last_net_bias_1_0-grad instead.\n",
      "INFO:tensorflow:Summary name last_variable/last_net_bias_2:0-grad is illegal; using last_variable/last_net_bias_2_0-grad instead.\n",
      "INFO:tensorflow:Summary name weight_mem_last:0-grad is illegal; using weight_mem_last_0-grad instead.\n",
      "INFO:tensorflow:Summary name bias_mem_last:0-grad is illegal; using bias_mem_last_0-grad instead.\n",
      "Initializing variables\n",
      "Start training\n",
      "\n",
      "\n",
      "iteration 0\n",
      "physical reward: -5817.3555\n",
      "vocabulary reward: -29702.871\n",
      "total reward: -35520.227\n",
      "--- Agent 0\n",
      "------ Mean distance 10.743343589315659\n",
      "------ Median distance 9.963108131503095\n",
      "------ Third quartile 14.432259237805356\n",
      "------ Ninetieth percentile 18.944710627202202\n",
      "------ max distance 28.700939749822457\n",
      "------ argmax distance 15\n",
      "--- Agent 1\n",
      "------ Mean distance 10.288918452510032\n",
      "------ Median distance 8.75612187761455\n",
      "------ Third quartile 13.39909121281321\n",
      "------ Ninetieth percentile 18.354160106556133\n",
      "------ max distance 32.233900481182296\n",
      "------ argmax distance 46\n",
      "computing time\n",
      "0:00:01.700793\n",
      "generation time\n",
      "0:00:00.041664\n",
      "memory usage\n",
      "memory use: 0.7517242431640625\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 19.84\n",
      "---- Median number of word activated: 20.0\n",
      "\n",
      "\n",
      "iteration 500\n",
      "physical reward: nan\n",
      "vocabulary reward: nan\n",
      "total reward: nan\n",
      "--- Agent 0\n",
      "------ Mean distance nan\n",
      "------ Median distance nan\n",
      "------ Third quartile nan\n",
      "------ Ninetieth percentile nan\n",
      "------ max distance nan\n",
      "------ argmax distance 0\n",
      "--- Agent 1\n",
      "------ Mean distance nan\n",
      "------ Median distance nan\n",
      "------ Third quartile nan\n",
      "------ Ninetieth percentile nan\n",
      "------ max distance nan\n",
      "------ argmax distance 0\n",
      "computing time\n",
      "0:08:17.038476\n",
      "generation time\n",
      "0:08:16.196889\n",
      "memory usage\n",
      "memory use: 0.7647476196289062\n",
      "-- Stats word count:\n",
      "---- Mean number of word activated: 1.0\n",
      "---- Median number of word activated: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-06409e79a080>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3612455ca7de>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0marray_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_utterances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_com\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_mem_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphys_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp = Experiment()\n",
    "sess = tf.Session()\n",
    "exp.train(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iteration 46000\n",
    "-253.03172\n",
    "--- Agent 0\n",
    "------ Mean distance 0.3349107071033829\n",
    "------ Median distance 0.29547300157924467\n",
    "------ Third quartile 0.4377302665174422\n",
    "------ Ninetieth percentile 0.638775063507328\n",
    "------ max distance 0.8557159604403306\n",
    "------ argmax distance 39\n",
    "--- Agent 1\n",
    "------ Mean distance 0.3412405142027863\n",
    "------ Median distance 0.31892391108436546\n",
    "------ Third quartile 0.45355292453441526\n",
    "------ Ninetieth percentile 0.6242127385438654\n",
    "------ max distance 0.9072062760757306\n",
    "------ argmax distance 16\n",
    "computing time\n",
    "0:11:42.544759\n",
    "generation time\n",
    "0:11:41.076586\n",
    "memory usage\n",
    "memory use: 0.8258514404296875\n",
    "-- Stats word count:\n",
    "---- Mean number of word activated: 19.28\n",
    "---- Median number of word activated: 19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"env_history.pkl\", \"rb\") as openfile:\n",
    "    states, utterances, memories_com, memories_last, goal_locations, goal_types, targets = cPickle.load(openfile)\n",
    "\n",
    "    \n",
    "array_states, array_utterances, array_mem_com, array_mem_last, full_goals, array_outputs = exp.arrays_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent 0\n",
      "------ Mean distance nan\n",
      "------ Median distance nan\n",
      "------ Third quartile nan\n",
      "------ Ninetieth percentile nan\n",
      "------ max distance nan\n",
      "------ argmax distance 0\n",
      "--- Agent 1\n",
      "------ Mean distance nan\n",
      "------ Median distance nan\n",
      "------ Third quartile nan\n",
      "------ Ninetieth percentile nan\n",
      "------ max distance nan\n",
      "------ argmax distance 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    }
   ],
   "source": [
    "print_stats_agent(array_states[-1, :, :, :], goal_locations, goal_types, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[:, :, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dist_to_goal = compute_goal_dist(python_shuffle(array_states[-1, :, :, :],targets),  goal_locations, goal_types)\n",
    "#dist_to_goal = compute_goal_dist(python_shuffle(array_states[-1, :, :, :],targets),  v, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  9, 10, 13, 14, 19, 20, 23, 25, 26, 27, 37, 39, 40, 42, 44, 58,\n",
       "        64, 66, 68, 69, 70, 71, 75, 79, 80, 85, 86, 90, 97]),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move = dist_to_goal[:, goal_types[0, 0, :] == 1]\n",
    "gaze = dist_to_goal[:, goal_types[0, 1, :] == 1]\n",
    "nothing = dist_to_goal[:, goal_types[0, 2, :] == 1]\n",
    "\n",
    "no_shuffle = dist_to_goal[:, targets[0, 0, :] == 0]\n",
    "shuffle = dist_to_goal[:, targets[1, 0, :] == 0]\n",
    "\n",
    "same_loc = dist_to_goal[:, (goal_locations[0, :, :] == goal_locations[1, :, :])[0, :]]\n",
    "diff_loc = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :]]\n",
    "\n",
    "diff_n_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]\n",
    "diff_not_shuffle = dist_to_goal[:, (goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 1)]\n",
    "rest = dist_to_goal[:, ~(goal_locations[0, :, :] != goal_locations[1, :, :])[0, :] & (targets[1, 0, :] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- rest:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- diff and shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- diff and not shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "print(\"- rest:\")\n",
    "print(\"---- median:\" + str(np.median(rest)))\n",
    "print(\"---- mean:\" + str(np.mean(rest)))\n",
    "print(\"---- max:\" + str(np.max(rest)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(rest, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(rest, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_n_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_n_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_n_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_n_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_n_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff and not shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(diff_not_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_not_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(diff_not_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_not_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_not_shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dist_to_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- no_shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- shuffle:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "print(\"- no_shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(no_shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(no_shuffle)))\n",
    "print(\"---- max:\" + str(np.max(no_shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(no_shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(no_shuffle, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- shuffle:\")\n",
    "print(\"---- median:\" + str(np.median(shuffle)))\n",
    "print(\"---- mean:\" + str(np.mean(shuffle)))\n",
    "print(\"---- max:\" + str(np.max(shuffle)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(shuffle, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(shuffle, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- move:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- gaze:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "print(\"- move:\")\n",
    "print(\"---- median:\" + str(np.median(move)))\n",
    "print(\"---- mean:\" + str(np.mean(move)))\n",
    "print(\"---- max:\" + str(np.max(move)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(move, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(move, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- gaze:\")\n",
    "print(\"---- median:\" + str(np.median(gaze)))\n",
    "print(\"---- mean:\" + str(np.mean(gaze)))\n",
    "print(\"---- max:\" + str(np.max(gaze)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(gaze, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(gaze, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- same loc:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n",
      "\n",
      "\n",
      "- diff loc:\n",
      "---- median:nan\n",
      "---- mean:nan\n",
      "---- max:nan\n",
      "---- third quartile:nan\n",
      "---- ninetieth percentile:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4033: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/gabriel/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "print(\"- same loc:\")\n",
    "print(\"---- median:\" + str(np.median(same_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(same_loc)))\n",
    "print(\"---- max:\" + str(np.max(same_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(same_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(same_loc, 90)))\n",
    "print(\"\\n\")\n",
    "print(\"- diff loc:\")\n",
    "print(\"---- median:\" + str(np.median(diff_loc)))\n",
    "print(\"---- mean:\" + str(np.mean(diff_loc)))\n",
    "print(\"---- max:\" + str(np.max(diff_loc)))\n",
    "print(\"---- third quartile:\" + str(np.percentile(diff_loc, 75)))\n",
    "print(\"---- ninetieth percentile:\" + str(np.percentile(diff_loc, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances[10, 0, :, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6617510755146957"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(dist_to_goal, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-480-e58bbd5f5f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][-1, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-481-c5b16d5090f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "array_states[0][0, :, 4:6, 82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_locations[:,:, 87].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[0][:, 0, 0:2, 82].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_stats_agent() missing 1 required positional argument: 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-6df541d46d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_stats_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: print_stats_agent() missing 1 required positional argument: 'targets'"
     ]
    }
   ],
   "source": [
    "print_stats_agent(array_states[0][-1, :, :, :], goal_locations, goal_types)\n",
    "print_stats_agent(array_states[0][0, :, :, :], goal_locations, goal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array_states = array_states\n",
    "save_goal_locations = goal_locations\n",
    "save_v = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2834616 , 2.40743668])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_goal[:, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6210312,  1.9584472],\n",
       "       [-5.182998 ,  2.837392 ]], dtype=float32)"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states[-1, 0:2, 0:2, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  [[1]\n",
      " [0]]\n",
      "first [0. 0. 1.]\n",
      "second [0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCMz/A9QGT7xqzXMgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa904024128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: [1.01029085 1.03542092]\n",
      "second: [-2.13919796 -0.23145501]\n",
      "[[-3.54529727 -3.25900611]\n",
      " [-3.54529727 -3.25900611]]\n"
     ]
    }
   ],
   "source": [
    "nb = 9\n",
    "print(\"target \", targets[:, :, nb])\n",
    "print(\"first\", goal_types[0, :, nb])\n",
    "print(\"second\", goal_types[1, :, nb])\n",
    "plot_trajectory(array_states[:, 0,0:2,nb], goal_locations[1, :, nb], v[0, :, nb])\n",
    "print(\"first:\", goal_locations[0, :, nb])\n",
    "print(\"second:\", goal_locations[1, :, nb])\n",
    "print(v[:, :, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4, 24, 35, 36, 37, 39, 52, 57, 60, 83, 87, 90]),)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_types[0, 0, :] == 1) & (goal_types[1, 0, :] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 11, 14, 15, 20, 22, 26, 41, 43, 48, 64, 76, 80, 81, 84]),)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((goal_types[0, 1, :] == 1) & (goal_types[1, 1, :] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vv = np.mean(goal_locations, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.tile(vv, (2, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_types[:, :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2b038b128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(exp.reward_history[:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-29702.871,\n",
       " -27925.586,\n",
       " -29286.057,\n",
       " -29169.541,\n",
       " -28971.984,\n",
       " -28690.703,\n",
       " -28135.004,\n",
       " -27367.47,\n",
       " -26088.96,\n",
       " -21023.395,\n",
       " -5087.388,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.voc_reward_history[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-35520.227,\n",
       " -57863.363,\n",
       " -38755.758,\n",
       " -34352.69,\n",
       " -31719.928,\n",
       " -31754.889,\n",
       " -30730.996,\n",
       " -30094.379,\n",
       " -28751.416,\n",
       " -23690.557,\n",
       " -12007.234,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.reward_history[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dirichlet_log_lik_end(utterances_array):\n",
    "    #Note: we don't take minus the log-likelihood as we minimize minus the entire reward then !\n",
    "    tr = tf.argmax(utterances_array, axis = 2)\n",
    "    oh = tf.one_hot(tr, depth = FLAGS.vocabulary_size)\n",
    "    idx = tf.where(tf.equal(oh, 1))\n",
    "    new_utt = tf.transpose(utterances_array, [0, 1, 3, 2])\n",
    "    f = tf.gather_nd(new_utt, idx)\n",
    "    return f, idx, oh, new_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt = tf.Variable(array_utterances[1:, :, :, :])\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    f, idx, oh, new_utt  = sess.run(dirichlet_log_lik_end(utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_utt[9, 1, 30, :] == array_utterances[10, 1, :, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.54993559e-05, 2.29775469e-05, 1.55317339e-05, 1.07052983e-05,\n",
       "       1.93080741e-05, 9.75096107e-01, 2.02358342e-06, 5.50499644e-05,\n",
       "       1.59106401e-06, 7.98685127e-04, 3.58977850e-05, 1.11183996e-04,\n",
       "       6.73774002e-06, 2.33666688e-05, 7.03339756e-04, 1.16257661e-03,\n",
       "       1.64146095e-05, 1.97302074e-06, 2.17355490e-02, 9.54532370e-05],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances[1, 0, :, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8858.54"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.log(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances, axis = 2)[:, 0, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_utterances, axis = 2)[:, 1, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5, 9, 100)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_utterances[:, 0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.84,\n",
       " 19.01,\n",
       " 19.61,\n",
       " 19.61,\n",
       " 19.49,\n",
       " 19.5,\n",
       " 19.08,\n",
       " 18.91,\n",
       " 18.15,\n",
       " 15.5,\n",
       " 6.25,\n",
       " 3.19,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.mean_act_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
